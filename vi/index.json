[{"uri":"https://veljg.github.io/AWS-Worklog/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"AWS Partner Network (APN) Blog Đạt Được Sự Xuất Sắc trong Dịch Vụ Hậu Mãi với Syncron và AWS bởi Ankit Gupta, Angelo Malatacca, Taj Abdulahi, và Marc Cervera Castro vào ngày 10 tháng 7 năm 2025 trong Amazon Athena, Amazon EMR, Analytics, AWS Glue, Industries, Manufacturing, Partner solutions | Permalink | Bình luận | Chia sẻ\nBởi: Taj Abdulahi, Sr. Manager Product – Syncron\nBởi: Ankit Gupta, Sr. Solutions Architect – AWS\nBởi: Marc Cervera Castro, Sr. Account Manager – AWS\nBởi: Angelo Malatacca, Partner Solutions Architect – AWS\nCác nhà sản xuất thiết bị khi quản lý dịch vụ hậu mãi của họ một cách hiệu quả có thể kiếm được nhiều doanh thu hơn từ việc bán phụ tùng, tăng lợi nhuận, cải thiện kết quả dịch vụ và củng cố lòng trung thành từ cả khách hàng và các đại lý. Các nhà sản xuất chưa phát triển dịch vụ hậu mãi của mình có nguy cơ gặp phải các kết quả khách hàng kém, cạnh tranh với các đại lý về thị phần dịch vụ và tăng nguy cơ bị các nhà cung cấp chợ đen thay thế.\nCác nhà sản xuất phải đối mặt với các rào cản vận hành trong việc điều phối dịch vụ hậu mãi của họ. Sau khi bán hàng, họ phải huy động nhiều đội ngũ để hỗ trợ chức năng của thiết bị trong suốt vòng đời của nó, và đảm bảo có sẵn phụ tùng thay thế để hoàn thành bất kỳ công việc sửa chữa nào. Sự phức tạp của các hoạt động này bộc lộ những thách thức trong môi trường sản xuất ngày nay. Hoạt động cô lập xuất hiện khi các phòng ban khác nhau, đội ngũ phụ tùng, dịch vụ và bảo hành, làm việc riêng lẻ. Sự tách biệt này tạo ra rào cản cho sự cộng tác hiệu quả và dẫn đến dữ liệu bị phân mảnh trên nhiều hệ thống, gây khó khăn trong việc duy trì cái nhìn toàn diện về hoạt động dịch vụ. Các hoạt động cô lập này trực tiếp góp phần làm tăng chi phí vận hành. Khi các đội ngũ hoạt động độc lập, các quy trình trở nên trùng lặp và việc phối hợp trở nên tốn thời gian. Sự kém hiệu quả này dẫn đến việc phân bổ nguồn lực không tối ưu và hạn chế khả năng hiển thị trên chuỗi dịch vụ, cuối cùng làm tăng chi phí vận hành và ảnh hưởng đến lợi nhuận của nhà sản xuất.\nĐể giải quyết những thách thức này, Syncron cung cấp một nền tảng Service Lifecycle Management (SLM) giúp chuyển đổi cách các nhà sản xuất quản lý các hoạt động hậu mãi và tổ chức dịch vụ của họ.\nTrong bài blog này, bạn sẽ tìm hiểu cách Service Lifecycle Management (SLM) của Syncron có thể hiện đại hóa các dịch vụ hậu mãi của bạn trên AWS.\nNền tảng SLM của Syncron củng cố các hoạt động hậu mãi Syncron được thành lập 35 năm trước với mục tiêu giúp việc lưu kho và bán phụ tùng trở nên dễ dàng hơn. Hiện tại, họ có hơn 200+ khách hàng doanh nghiệp hàng đầu trên toàn cầu. Các giải pháp hậu mãi của Syncron bao gồm Giá phụ tùng, Giá hợp đồng, Lập kế hoạch kho hàng và Bảo hành.\nGần đây, họ đã thêm SLM Data Platform vào dịch vụ này, được lưu trữ trên AWS. Công cụ tập trung mới này tích hợp dữ liệu trên các hoạt động dịch vụ, phụ tùng và bảo hành (từ cả các giải pháp của Syncron và các nguồn dữ liệu bên ngoài), tạo ra một hệ sinh thái kinh doanh được kết nối hoàn toàn.\nCách tiếp cận toàn diện này điều chỉnh việc ra quyết định giữa các phòng ban, thay thế các hệ thống bị phân mảnh bằng một giải pháp thống nhất, dựa trên dữ liệu và tăng cường sự linh hoạt, cho phép các doanh nghiệp nhanh chóng phản ứng với sự thay đổi của thị trường. Hình 1 minh họa cách SLM Data Platform tích hợp dữ liệu trên giải pháp của Syncron và các nguồn dữ liệu.\nHình 1 – Service Lifecycle Management (SLM) của Syncron\nCách tiếp cận mới này trao quyền cho các đội ngũ tại hiện trường để truy cập dữ liệu ngay lập tức nhằm đưa ra các quyết định tốt hơn tại chỗ với thời gian ngừng hoạt động và sự phối hợp thấp hơn. Ở cấp độ thứ hai, nó hỗ trợ các nhà khoa học dữ liệu khám phá dữ liệu, thu thập thông tin chi tiết và xây dựng các sản phẩm dữ liệu như bảng điều khiển phân tích và mô hình AI. Điều này mở ra các trường hợp sử dụng trước đây không thể thực hiện được. Cuối cùng, các nhà quản lý và giám đốc điều hành có quyền truy cập vào các công cụ phân tích và bảng điều khiển, đảm bảo các quyết định được căn chỉnh với các mục tiêu kinh doanh dài hạn.\nCác Trường hợp Sử dụng của Khách hàng Truy cập dữ liệu hậu mãi tức thì\nVới SLM Data Platform, khách hàng có thể nhận được gấp 10 lần dữ liệu từ các ứng dụng Service Lifecycle của họ. Các nhà sản xuất truy cập ngay lập tức vào dữ liệu sạch, đã được tinh chỉnh và sẵn sàng hành động từ tất cả các hoạt động hậu mãi của họ trong một trong một giao diện quản lý thống nhất. Điều này cho phép truy cập dữ liệu có thể mở rộng và an toàn, tuân theo các hướng dẫn quản trị được thiết lập sẵn, để nhiều đội ngũ có thể xây dựng các thông tin chi tiết và mô hình học máy (ML) của riêng họ. Việc bỏ qua các bước trích xuất và điều chỉnh dữ liệu giúp tăng tốc quá trình vận hành dữ liệu, mang lại thông tin chi tiết kinh doanh nhanh hơn.\nTrung tâm Phân tích cho nhà phân tích dữ liệu\nNhờ vào việc sử dụng SLM Data Platform, khách hàng có thể định vị, kết hợp và truy vấn các bộ dữ liệu để xây dựng các data stories có thể chia sẻ. Họ có thể cung cấp những dữ liệu này làm nguồn cho các công cụ trực quan hóa dữ liệu hiện có, để thông tin được phân phối đến các đội ngũ khác nhau.\nTạo ra các sản phẩm dữ liệu\nCuối cùng, các nhà sản xuất có thể xây dựng các sản phẩm dữ liệu của riêng họ (ví dụ: mô hình ML tùy chỉnh về định giá phụ tùng hoặc tối ưu hóa kho hàng) từ tất cả dữ liệu và cung cấp chúng từ SLM Data Platform của Syncron. Tận dụng kinh nghiệm của Syncron, họ đã xác định được hơn 30 trường hợp sử dụng được xác định trước (một số được khách hàng cuối định giá hơn 1 triệu đô la Mỹ) có thể được kích hoạt và tích hợp với quy trình sản xuất hiện có.\nSolution Architecture Cốt lõi của SLM Data Platform của Syncron là một hệ sinh thái dữ liệu mạnh mẽ, hợp nhất nhiều nguồn—dữ liệu định giá, hợp đồng, lập kế hoạch phụ tùng và bảo hành—thành một khung thông minh, duy nhất. Sự hợp nhất này cho phép các doanh nghiệp biến dữ liệu thô thành thông tin chi tiết có ý nghĩa, thúc đẩy hiệu suất và lợi nhuận. Nền tảng được xây dựng trên AWS bao gồm các thành phần chính sau:\nData Landing Zone\nMột nền tảng an toàn, có khả năng mở rộng để tiếp nhận dữ liệu đa đối tượng thuê từ nhiều nguồn, được xây dựng trên Amazon Simple Storage Service (Amazon S3). Data Landing Zone chứa cả dữ liệu có cấu trúc và phi cấu trúc. Data Product Framework\nMột cách tiếp cận có cấu trúc để tinh chỉnh và triển khai các bộ dữ liệu được điều chỉnh theo mô hình vận hành OEM của Syncron, tận dụng AWS Glue. Multi-Tenant Data.all Setup\nĐảm bảo cô lập và quản trị dữ liệu khách hàng trong khi duy trì hiệu suất vận hành bằng cách áp dụng data.all, khung phát triển mã nguồn mở của AWS giúp xây dựng một thị trường dữ liệu trên AWS. Unified Data Access\nCung cấp quyền truy cập dữ liệu theo thời gian thực, cho phép khách hàng đưa ra các quyết định có thông tin đầy đủ. Nền tảng này có các tính năng: Hình ảnh hóa dữ liệu trực quan giúp đơn giản hóa dữ liệu phức tạp, xuất dữ liệu liền mạch để tích hợp với các hệ thống bên ngoài và khả năng sử dụng AI cùng phân tích nâng cao cho thông tin chi tiết dự đoán. Hình 2 làm nổi bật kiến trúc cấp cao của SLM Data Platform của Syncron.\nHình 2 – Kiến trúc SLM Data Platform của Syncron\nKết luận Các giải pháp của Syncron trên AWS cung cấp một nền tảng mạnh mẽ để khai thác dữ liệu, thúc đẩy việc ra quyết định thông minh hơn và phối hợp giữa các phòng ban. Dù là tối ưu hóa kho hàng, định giá, hay thực hiện dịch vụ, SLM Data Platform đều cung cấp một nền tảng dữ liệu mạnh mẽ cho các trường hợp sử dụng phân tích và AI.\nĐể tìm hiểu thêm về cách nền tảng SLM của Syncron có thể phù hợp với quy trình hậu mãi của bạn, hãy nói chuyện với đội ngũ quản lý tài khoản của chúng tôi.\nSyncron – AWS Partner Spotlight Syncron là Đối tác Công nghệ Nâng cao của AWS, giúp các nhà sản xuất hàng đầu thế giới tối đa hóa thời gian hoạt động của sản phẩm và mang lại trải nghiệm dịch vụ hậu mãi vượt trội.\nLiên hệ với Syncron | Tổng quan về Đối tác | AWS Marketplace\nTAGS: AI for Data Analytics, Industries, Manufacturing, Syncron\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Huỳnh An Khương\nSố điện thoại: 0964440342\nEmail: huynhankhuong0511@gmail.com\nTrường: Trường Đại học FPT Thành Phố Hồ Chí Minh\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 12/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tuần 1: Hoàn thành Module 1 \u0026amp; 2, bảo mật tài khoản AWS, và thực hiện các bài lab thực hành về VPC và EC2 networking\nTuần 2: Triển khai các dịch vụ cơ sở dữ liệu (RDS) và Load Balancing, đạt tiến bộ đáng kể ở Module 3 \u0026amp; 4, và nghiên cứu về AWS Well-Architected Framework\nTuần 3: Hoàn thành Module 5 (lý thuyết và lab), nắm vững các thực hành bảo mật nâng cao (IAM, KMS, Security Hub) và các bài lab lưu trữ/di chuyển phức tạp\nTuần 4: Ôn tập các khái niệm cơ sở dữ liệu cốt lõi, thử nghiệm di chuyển cơ sở dữ liệu (DMS/SCT), và bắt đầu xây dựng đề xuất workshop của nhóm\nTuần 5: Phát triển sơ đồ kiến trúc workshop và đạt được kinh nghiệm thực hành với Kinesis, Glue, và Athena cho data streaming và analytics\nTuần 6: Hoàn thiện đề xuất workshop, tích hợp GuardDuty và EventBridge vào kiến trúc, và triển khai tài liệu lên GitHub Pages\nTuần 7: Kiểm thử chuyên sâu GuardDuty và cấu hình tự động hóa EventBridge để gửi cảnh báo qua SNS và Lambda, tích hợp AWS Detective cho forensics\nTuần 8: Hoàn thành ôn tập chuyên sâu và tham gia FCJ Midterm Exam, đồng thời nghiên cứu về AWS Step Functions để điều phối quy trình IR (Incident Response)\nTuần 9: Hoàn thiện kiến trúc Ứng phó Sự cố (Incident Response) bằng cách sử dụng Step Functions và xây dựng thành công custom ETL pipeline cho CloudTrail logs\nTuần 10: Hoàn thành tất cả các custom ETL pipelines (CloudWatch, GuardDuty), tích hợp security logs với KMS, và thiết lập nhiều hệ thống thông báo mối đe dọa khác nhau\nTuần 11: Tinh chỉnh kiến trúc bằng cách loại bỏ Glue Crawler, thêm SQS để tăng độ tin cậy, và bắt đầu nghiên cứu toàn diện về AWS CDK\nTuần 12: Triển khai thành công core ETL pipeline và cơ sở hạ tầng ghi nhật ký bằng AWS CDK, và tối ưu hóa ghi nhật ký CloudTrail với nén gzip\nTuần 13: Hoàn thiện kiến trúc bằng cách tích hợp Kinesis Data Firehose và đại tu quy trình IR với gắn thẻ (tagging) và EBS snapshotting cho việc nộp dự án\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/1.1-week1/","title":"Nhật ký Công việc Tuần 1","tags":[],"description":"","content":"Mục tiêu Tuần 1: Kết nối với các thành viên và cố vấn của FCJ. Tìm hiểu về môi trường làm việc văn phòng. Cài đặt Linux, học cách sử dụng Linux đúng cách. Học các kiến thức cơ bản về AWS, console và CLI. Hoàn thành module một và hai. Các nhiệm vụ được thực hiện trong tuần này: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Đọc quy tắc thực tập - Tạo tài khoản AWS - Học AWS là gì - Hoàn thành Lab 1 Module 1 (Học cách tạo tài khoản AWS và quản lý nhóm người dùng) - Hoàn thành Lab 7 Module 1 (Học cách tạo ngân sách sử dụng dịch vụ) - Lab 7-3 (Usage Budget) không thể hoàn thành do lỗi trong dropdown usage type, không hiển thị gì - Hoàn thành Lab 9 Module 1 (Học về AWS Support Services, loại hình, lợi ích và cách yêu cầu hỗ trợ) 08/09/2025 08/09/2025 Create new AWS Account MFA for AWS Accounts Create Admin Group and Admin User Account Authentication Support Explore and Configure AWS Management Console Creating Support Cases and Case Management in AWS 3 - Bắt đầu lý thuyết Module 2: + Học về VPC (Amazon Virtual Private Cloud)\n+ Học về Subnets và Routetable, Security Groups\n+ Học về ENI và EIP\n+ Học về VPC Peering và Transit Gateway + Học về Elastic Load Balancing\n+ Học về EC2\n- Thiết lập trang web cho báo cáo workshop - Cài đặt Hugo - Viết worklog thành công bằng markdown và Hugo 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Hoàn thành các lab của Module 2 - Lab 3: + Học về các tài nguyên cần thiết để tạo và chạy các EC2 instances + Cấu hình và chạy các EC2 instances thành công + Kết nối và ping đến các EC2 instances thành công + Tạo NAT Gateway để cho phép kết nối EC2 private - Lab 10: + Học cách tạo và sử dụng các cặp khóa (key pairs) để bảo mật + Học cách cấu hình security groups để quản lý kết nối + Kết nối và sử dụng RDP qua EC2 thành công + Thiết lập hybrid DNS với Route 53 Resolver (Đang tiến hành, Cloud Formation template không tạo security group để tiếp tục lab) - Lab 19: + Tạo VPC Peering Connection thành công + Học cách cấu hình Network ACLs + Bật Cross-Peer DNS để giải quyết tên host private - Tải xuống và sử dụng MobaXTerm để kết nối với các EC2 instances - Tải xuống và sử dụng PuTTY để cấu hình các cặp khóa 10/09/2025 11/09/2025 Lab 3 Lab 10 Lab 19 5 - Lab 20: + Tạo AWS Transit Gateway thành công để cho phép kết nối giữa các VPC qua một hub chung • Tệp yaml Cloud Formation template không được cập nhật, tạo thất bại • Đã sửa tệp template, thay đổi loại EC2 instance thành t3.micro - Học được bài học đắt giá về việc tại sao cần dọn dẹp tài nguyên sau khi làm lab, bị tính phí 12$ credits - Xác minh các kế hoạch chi phí và ngân sách hoạt động đúng như dự định, đã được thông báo qua email. 11/09/2025 11/09/2025 Lab 20 6 - Bắt đầu lý thuyết Module 3 + Học về EBS, tính năng Instance store và kiểm tra User và Meta Data + Học về Amazon Lightsail + Học về Elastic File System (EFS) và FSx + Học về MGN + Học cách sử dụng S3 Buckets trên AWS - Hoàn thành các lab của Module 3 - Lab 13: Tạo Backup Plan và Vaults thành công cho dữ liệu trong S3 Buckets + Thiết lập thông báo cho các sự kiện Backup thành công + Khôi phục backup thành công - Lab 24: + Tạo storage gateway + Hoàn thành chia sẻ tệp thành công - Lab 57: + Host static website bằng S3 Buckets thành công + Cấu hình các công cụ sửa đổi truy cập (access modifiers) thành công + Cấu hình Tăng tốc Static Websites với Cloudfront không hoạt động, bỏ qua bước này + Tạo bucket versions thành công + Di chuyển đối tượng giữa các buckets + Nhân bản bucket giữa các regions. 12/09/2025 12/09/2025 Lab 13 Lab 24 Lab 57 Thành tựu Tuần 1: Đã tạo và bảo mật tài khoản AWS, bao gồm thiết lập ngân sách và khám phá các dịch vụ hỗ trợ.\nHoàn thành lý thuyết và các lab thực hành cho VPC, Subnets, Security Groups, và Routetables.\nTriển khai và kết nối thành công với các EC2 instances, cấu hình NAT Gateway, và quản lý các kết nối chính bằng VPC Peering và AWS Transit Gateway.\nCó kinh nghiệm thực hành với S3 Buckets (static website hosting, quản lý phiên bản, nhân bản), AWS Backup, và Storage Gateway.\nThiết lập Tài liệu: Cài đặt Hugo thành công và cấu hình trang web để viết worklog bằng markdown.\nThành thạo Công cụ: Học cách sử dụng MobaXTerm và PuTTY để kết nối và quản lý các EC2 instances.\nĐã sửa thành công một CloudFormation template lỗi thời trong lab Transit Gateway và học được cách quản lý chi phí thông qua cảnh báo ngân sách.\nHoàn thành Module 1 và Module 2, và có một khởi đầu vững chắc cho Module 3.\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Báo cáo sự kiện: “Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders: Gen AI and Data track” Mục tiêu sự kiện Sự kiện công nghệ hàng đầu Việt Nam, quy tụ doanh nghiệp, kỹ sư và lãnh đạo để khai thác đổi mới về Cloud và AI. Khám phá những xu hướng mới nhất về Gen AI, công nghệ điện toán đám mây và các giải pháp số. Nhận được nhiều kiến thức giá trị qua các phiên khai mạc, học hỏi từ câu chuyện thành công của khách hàng, tham gia workshop thực hành và khám phá các giải pháp tiên tiến từ chuyên gia và đối tác AWS. Diễn giả H.E Pham Duc Long – Vice Minister of Science and Technology H.E Marc E. Knapper – US Ambassador to Vietnam Jaime Valles – Vice President, General Manager Asia Pacific and Japan, AWS Jeff Johnson – Managing Director ASEAN, AWS Dr Jens Lottner – CEO, Techcombank Dieter Botha – CEO, TymeX Trang Phung – CEO \u0026amp; Co-Founder, U2U Network Vu Van – CEO \u0026amp; Co-Founder, ELSA Corp Nguyen Hoa Binh – Chairman, Texttech Group Taiki Dang – Solutions Architect, AWS Jun Kai Loke – AI/ML Specialist SA, AWS Kien Nguyen – Solutions Architect, AWS Tamelly Lim – Storage Specialist SA, AWS Binh Tran – Senior Solutions Architect, AWS Michael Armentano – Principal WW GTM Specialist, AWS Nội dung nổi bật Khai mạc khách hàng AWS Xây dựng nền tảng dữ liệu hợp nhất trên AWS cho AI và phân tích Xây dựng nền tảng dữ liệu hợp nhất, có khả năng mở rộng trên AWS, phù hợp cho các khối lượng công việc AI và phân tích Bao gồm các thành phần chính như: Thu thập dữ liệu Lưu trữ Xử lý Quản trị Đảm bảo tổ chức có thể quản lý và khai thác dữ liệu hiệu quả cho phân tích nâng cao và AI Xây dựng tương lai: Ứng dụng Gen AI và lộ trình trên AWS Trình bày tầm nhìn tổng thể, xu hướng mới và lộ trình chiến lược cho việc ứng dụng công nghệ GenAI Bao gồm các dịch vụ và sáng kiến AWS giúp tổ chức tận dụng GenAI để thúc đẩy đổi mới và hiệu quả Vòng đời phát triển phần mềm hướng AI (AI-DLC) Phương pháp tiếp cận lấy AI làm trung tâm, đưa AI trở thành cộng tác viên chính trong toàn bộ vòng đời phát triển phần mềm Bảo mật ứng dụng AI tạo sinh với AWS: Nguyên tắc và thực tiễn tốt nhất Khám phá các thách thức bảo mật ở từng lớp của ngăn xếp AI tạo sinh—hạ tầng, mô hình và ứng dụng Khám phá các biện pháp bảo mật như mã hóa, kiến trúc zero-trust, giám sát liên tục và kiểm soát truy cập chi tiết để bảo vệ các khối lượng công việc AI tạo sinh Vượt ra ngoài tự động hóa: AI Agent như trợ lý tăng năng suất tối đa Sự thay đổi tư duy khi AI Agent không chỉ là công cụ mà còn là đối tác thông minh thúc đẩy doanh nghiệp phát triển. Giới thiệu về AI Agent mới của AWS: AWS Quick Suite Những điểm rút ra chính Kết nối lý thuyết với thực tiễn ngành Vai trò quan trọng của Data Pipeline trong AI/ML: Các phiên thảo luận khẳng định rằng các mô hình AI/ML tiên tiến hoàn toàn phụ thuộc vào nền tảng dữ liệu vững chắc. Điều này không chỉ là lưu trữ dữ liệu mà còn cần các pipeline được thiết kế tốt cho việc thu thập, xử lý, quản trị và lưu trữ, đây là thách thức kỹ thuật thực sự trước khi bắt đầu huấn luyện mô hình. Xu hướng phát triển phần mềm kết hợp AI và hệ thống bất đồng bộ: Tương lai của phát triển phần mềm là sự kết hợp của hai xu hướng mạnh mẽ. Thứ nhất, Vòng đời phát triển phần mềm hướng AI (AI-DLC) với các công cụ như Amazon Q Developer sẽ trở thành tiêu chuẩn, nâng cao năng suất lập trình viên. Thứ hai, ưu tiên mạnh cho giao tiếp bất đồng bộ, hướng sự kiện thay vì API đồng bộ truyền thống để xây dựng hệ thống bền vững và mở rộng hơn. Tích hợp bảo mật xuyên suốt vòng đời phát triển: Bảo mật không phải là bước cuối mà là phần không thể thiếu trong toàn bộ quá trình phát triển. Thảo luận đề cập đến việc bảo vệ toàn bộ stack—từ hạ tầng cloud, mô hình AI đến lớp ứng dụng. Trải nghiệm sự kiện \u0026ldquo;Vietnam Cloud Day 2025\u0026rdquo; thực sự rất giá trị vì đã cung cấp bối cảnh thực tiễn rõ ràng cho nhiều khái niệm lý thuyết mình học trong ngành Công nghệ Thông tin. Sự kiện giúp mình kết nối kiến thức học thuật với ứng dụng thực tế trong ngành.\nPhần trình diễn về Vòng đời phát triển phần mềm hướng AI là điểm nhấn. Nó gợi mở sự thay đổi vai trò của lập trình viên, tập trung nhiều hơn vào kiến trúc và giải quyết vấn đề phức tạp, trong khi các trợ lý AI như Amazon Q Developer sẽ đảm nhận nhiều công việc lặp lại như sinh mã và debug. Việc tìm hiểu về các công nghệ mới như AWS Quick Suite cho AI Agent cũng cho mình cái nhìn hấp dẫn về làn sóng tự động hóa tiếp theo.\nKết thúc sự kiện, mình có cái nhìn rõ ràng hơn về xu hướng ngành hiện tại và biết nên tập trung vào kỹ năng nào để chuẩn bị cho các kỳ thực tập và sự nghiệp tương lai.\nMột số hình ảnh sự kiện Selfie Ảnh nhóm\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/5.7.2.1-create-iam-role-and-policy-for-lambda/","title":"Cài đặt IAM Role và Policy cho Lambda","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt IAM Role và Policy cho Lambda.\nTạo IAM Role cho Lambda Mở IAM Console\nĐiều hướng tới https://console.aws.amazon.com/iam/ Hoặc: AWS Management Console → Services → IAM Create Role:\nChọn tùy chọn Role trên menu bên trái. Sau đó nhấn Create role. Chọn trusted entity:\nTrusted entity type: AWS Service Use case: Lambda Nhấn \u0026ldquo;Next\u0026rdquo; Đính kèm permissions policies:\nTrong hộp tìm kiếm, nhập AWSLambdaBasicExecutionRole Đánh dấu ô bên cạnh \u0026ldquo;AWSLambdaBasicExecutionRole\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Đặt tên, xem lại, và tạo:\nRole name: Nhập dashboard-query-role Description: Nhập Execution role for Lambda function Nhấn \u0026ldquo;Create role\u0026rdquo; Thêm inline policy:\nSau khi tạo, bạn sẽ ở trang chi tiết role Nhấn vào tab \u0026ldquo;Permissions\u0026rdquo; Nhấn \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Create inline policy\u0026rdquo; Tạo inline policy:\nNhấn vào tab \u0026ldquo;JSON\u0026rdquo; Dán policy sau: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AthenaActions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;athena:StartQueryExecution\u0026#34;, \u0026#34;athena:GetQueryExecution\u0026#34;, \u0026#34;athena:GetQueryResults\u0026#34;, \u0026#34;athena:StopQueryExecution\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;GlueCatalogRead\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;glue:GetDatabase\u0026#34;, \u0026#34;glue:GetDatabases\u0026#34;, \u0026#34;glue:GetTable\u0026#34;, \u0026#34;glue:GetTables\u0026#34;, \u0026#34;glue:GetPartitions\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;S3SourceAndResultAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::vel-athena-results\u0026#34;, \u0026#34;arn:aws:s3:::vel-athena-results/*\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-cloudtrail-logs\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-cloudtrail-logs/*\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-guardduty\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-guardduty/*\u0026#34;, \u0026#34;arn:aws:s3:::cloudwatch-formatted\u0026#34;, \u0026#34;arn:aws:s3:::cloudwatch-formatted/*\u0026#34; ] } ] } Nhấn \u0026ldquo;Next\u0026rdquo;\nTên Policy:\nPolicy name: Nhập lambda-query-policy Nhấn \u0026ldquo;Create policy\u0026rdquo; Xác minh tạo role:\nBạn sẽ thấy role với cả managed và inline policies được đính kèm "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.1-setup-s3/","title":"Cài đặt S3 Bucket cho Dashboard","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một S3 để chứa các file web và folder. Quan trọng: Thay thế ACCOUNT_ID bằng AWS Account ID của bạn và REGION bằng region mục tiêu (ví dụ: us-east-1) trong tất cả tên bucket.\nTên Bucket static-dashboard-bucket-ACCOUNT_ID-REGION - Lưu trữ các file web và folder đã build\nHướng dẫn tạo Bucket Mở Amazon S3 Console\nĐiều hướng tới https://console.aws.amazon.com/s3/ Hoặc: AWS Management Console → Services → S3 Nhấn vào \u0026ldquo;Create bucket\u0026rdquo;\nCài đặt tạo Bucket:\nGiữ các cài đặt như mặc định: Bucket name: Nhập static-dashboard-bucket-ACCOUNT_ID-REGION Ví dụ: static-dashboard-bucket-123456789012-us-east-1 Ownership: ACLs disabled Block Public Access: Block all public access Bucket versioning: Disable Tags (Tùy chọn): Thêm nếu bạn muốn Encryption: SSE-S3 Bucket key: Enable Nhấn Create bucket Xác minh tạo bucket:\nBạn sẽ thấy một thông báo thành công Bucket sẽ xuất hiện trong danh sách S3 bucket của bạn Tải lên files và folder:\nTruy cập Github để lấy nội dung web và tải lên S3 "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.10-cleanup/5.10.1-manual-cleanup/","title":"Dọn dẹp thủ công","tags":[],"description":"","content":"Clean up (Thiết lập cơ sở hạ tầng thủ công) Giai đoạn 1: Dọn dẹp Automation và Monitoring Mục tiêu ở đây là dừng tất cả các tiến trình đang hoạt động và xóa các tài nguyên monitoring và automation cốt lõi (EventBridge, Step Functions, SNS, GuardDuty, Flow Logs, CloudTrail).\n1. Xóa Incident Response Automation 1.1 Xóa EventBridge Rule\nVào EventBridge Console → Rules. Chọn rule: IncidentResponseAlert. Nhấn \u0026ldquo;Delete\u0026rdquo;. 1.2 Xóa Step Functions State Machine\nVào Step Functions Console → State Machines. Chọn State Machine: IncidentResponseStepFunctions. Nhấn \u0026ldquo;Delete\u0026rdquo;. 1.3 Xóa SNS Topic và Subscription\nVào SNS Console → Topics → IncidentResponseAlerts. Đầu tiên, xóa subscription liên kết với ir-alert-dispatch. Sau đó, xóa chính topic bằng cách nhấn \u0026ldquo;Delete topic\u0026rdquo;. 1.4 Xóa GuardDuty Detector\nVào GuardDuty Console → Settings → General. Nhấn \u0026ldquo;Suspend\u0026rdquo; để dừng xử lý, sau đó nhấn \u0026ldquo;Disable GuardDuty\u0026rdquo; (hoặc \u0026ldquo;Delete detector\u0026rdquo;). 1.5 Vô hiệu hóa VPC Flow Logs\nVào VPC Console → VPC Flow Logs. Chọn flow log đã tạo (liên kết với YOUR_VPC_ID). Nhấn \u0026ldquo;Delete flow log\u0026rdquo;. 1.6 Xóa CloudTrail Trail\nVào CloudTrail Console → Trails. Chọn trail: incident-responses-cloudtrail-ACCOUNT_ID-REGION. Nhấn \u0026ldquo;Delete\u0026rdquo;. Giai đoạn 2: Dọn dẹp Lambda và Compute 2. Xóa tất cả Lambda Functions (9 Functions) Vào Lambda Console và xóa các functions sau:\nincident-response-cloudtrail-etl incident-response-guardduty-etl cloudwatch-etl-lambda cloudwatch-eni-etl-lambda cloudwatch-export-lambda ir-parse-findings-lambda ir-isolate-ec2-lambda ir-quarantine-iam-lambda ir-alert-dispatch 3. Xóa Isolation Security Group Vào EC2 Console → Security Groups. Tìm và chọn Security Group: IR-Isolation-SG (sử dụng ID sg-XXXXXXX). Nhấn \u0026ldquo;Delete security group\u0026rdquo;. 4. Xóa CloudWatch Log Groups Vào CloudWatch Console → Log Groups và xóa:\nCentralized log group: /aws/incident-response/centralized-logs. Bất kỳ Lambda log groups nào liên quan đến 9 functions đã xóa (ví dụ: /aws/lambda/ir-parse-findings-lambda). Giai đoạn 3: Dọn dẹp Processing và Data Lake 5. Xóa Kinesis Data Firehose Streams Vào Kinesis Console → Delivery Streams và xóa:\ncloudtrail-firehose-stream vpc-dns-firehose-stream vpc-flow-firehose-stream 6. Xóa AWS Glue Tables và Database 6.1 Xóa Glue Tables\nVào Glue Console → Tables. Chọn và xóa: security_logs.processed_cloudtrail, security_logs.processed_guardduty, security_logs.vpc_logs, và security_logs.eni_flow_logs. 6.2 Xóa Glue Database\nVào Glue Console → Databases. Chọn database: security_logs và nhấn \u0026ldquo;Delete\u0026rdquo;. 7. Xóa IAM Roles và Policies 7.1 Xóa IAM Policies\nVào IAM Console → Policies. Xóa custom managed policy: IrQuarantineIAMPolicy. Lưu ý: Inline policies được tạo trong quá trình cài đặt sẽ tự động bị xóa khi role tương ứng bị xóa. 7.2 Xóa IAM Roles\nVào IAM Console → Roles. Xóa 17 roles sau: Lambda Execution Roles: CloudTrailETLLambdaServiceRole, GuardDutyETLLambdaServiceRole, CloudWatchETLLambdaServiceRole, CloudWatchENIETLLambdaServiceRole, CloudWatchExportLambdaServiceRole, ParseFindingsLambdaServiceRole, IsolateEC2LambdaServiceRole, QuarantineIAMLambdaServiceRole, AlertDispatchLambdaServiceRole. Service Roles: CloudTrailFirehoseRole, CloudWatchFirehoseRole, StepFunctionsRole, IncidentResponseStepFunctionsEventRole, FlowLogsIAMRole, GlueCloudWatchRole. Giai đoạn 4: Dọn dẹp S3 Bucket (Xóa dữ liệu) 8. Làm trống và Xóa S3 Buckets Đây là bước cuối cùng để đảm bảo tất cả các khoản phí lưu trữ được dừng lại.\nBucket Name Mục đích incident-response-log-list-bucket-ACCOUNT_ID-REGION Nguồn Log Chính (CloudTrail/GuardDuty/Exported CW) processed-cloudtrail-logs-ACCOUNT_ID-REGION Firehose Destination cho CloudTrail logs processed-cloudwatch-logs-ACCOUNT_ID-REGION Firehose Destination cho VPC DNS/Flow logs processed-guardduty-findings-ACCOUNT_ID-REGION ETL Destination cho GuardDuty logs athena-query-results-ACCOUNT_ID-REGION Lưu trữ kết quả truy vấn Athena Vào S3 Console. Đối với mỗi bucket trong 5 buckets: Nhấn vào tên bucket. Vào tab \u0026ldquo;Objects\u0026rdquo;. Nhấn \u0026ldquo;Empty\u0026rdquo; để xóa tất cả dữ liệu. Bạn phải xác nhận việc xóa vĩnh viễn bằng cách gõ permanently delete. Quay lại danh sách S3 bucket, chọn bucket, và nhấn \u0026ldquo;Delete\u0026rdquo;. "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.1-cloudtrail-etl/","title":"Mã CloudTrail ETL","tags":[],"description":"","content":" import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CẤU HÌNH (CONFIG) # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Trích xuất VPC ID từ đường dẫn file (Extract VPC ID from file path) vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Đọc và xử lý nội dung file (Read and process file content) content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Tạo flattened JSON record (Create flattened JSON record) out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Thêm dòng mới cho định dạng JSONL (Add newline for JSONL format) json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Gửi đến Firehose theo batch 500 (Send to Firehose in batches of 500) if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.5-processing-setup/5.5.1-create-kinesis-data-firehose/","title":"Tạo Kinesis Data Firehose","tags":[],"description":"","content":"Tạo Kinesis Data Firehose Delivery Streams Tạo cloudtrail-firehose-stream Mở Kinesis Console → Delivery streams → Create delivery stream\nCấu hình:\nSource: Direct PUT Destination: Amazon S3 Stream name: cloudtrail-firehose-stream S3 bucket: processed-cloudtrail-logs-ACCOUNT_ID-REGION Prefix: processed-cloudtrail/date=!{timestamp:yyyy-MM-dd}/ Error prefix: processed-cloudtrail/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ Buffer size: 10 MB Buffer interval: 300 seconds Compression: GZIP IAM role: CloudTrailFirehoseRole Create delivery stream\nTạo vpc-dns-firehose-stream Stream name: vpc-dns-firehose-stream S3 bucket: processed-cloudwatch-logs-ACCOUNT_ID-REGION Prefix: vpc-logs/date=!{timestamp:yyyy-MM-dd}/ Error prefix: vpc-logs/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ IAM role: CloudWatchFirehoseRole (Cài đặt buffer/compression giống như trên) Tạo vpc-flow-firehose-stream Stream name: vpc-flow-firehose-stream S3 bucket: processed-cloudwatch-logs-ACCOUNT_ID-REGION Prefix: eni-flow-logs/date=!{timestamp:yyyy-MM-dd}/ Error prefix: eni-flow-logs/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ IAM role: CloudWatchFirehoseRole (Cài đặt buffer/compression giống như trên) "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.1-create-lambda-excecution-roles/","title":"Tạo Lambda Execution Roles","tags":[],"description":"","content":"Tạo CloudTrailETLLambdaServiceRole Mở IAM Console:\nĐiều hướng đến https://console.aws.amazon.com/iam/ Hoặc: AWS Management Console → Tìm kiếm \u0026ldquo;IAM\u0026rdquo; → Nhấn \u0026ldquo;IAM\u0026rdquo; Điều hướng đến Roles:\nỞ thanh bên trái, nhấn \u0026ldquo;Roles\u0026rdquo; Nhấn \u0026ldquo;Create role\u0026rdquo;\nChọn trusted entity:\nTrusted entity type: Chọn \u0026ldquo;AWS service\u0026rdquo; Use case: Chọn \u0026ldquo;Lambda\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Thêm permissions:\nTrong hộp tìm kiếm, nhập AWSLambdaBasicExecutionRole Đánh dấu vào ô bên cạnh \u0026ldquo;AWSLambdaBasicExecutionRole\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Đặt tên, xem lại, và tạo:\nRole name: Nhập CloudTrailETLLambdaServiceRole Description: Nhập Execution role for CloudTrail ETL Lambda function Nhấn \u0026ldquo;Create role\u0026rdquo; Thêm inline policy:\nSau khi tạo, bạn sẽ ở trang chi tiết role Nhấn vào tab \u0026ldquo;Permissions\u0026rdquo; Nhấn \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Create inline policy\u0026rdquo; Tạo inline policy:\nNhấn vào tab \u0026ldquo;JSON\u0026rdquo; Dán policy sau (thay thế ACCOUNT_ID và REGION): { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/cloudtrail-firehose-stream\u0026#34; } ] } Nhấn \u0026ldquo;Next\u0026rdquo;\nTên Policy:\nPolicy name: Nhập CloudTrailETLPolicy Nhấn \u0026ldquo;Create policy\u0026rdquo; Xác minh tạo role:\nBạn sẽ thấy role với cả managed và inline policies được đính kèm Tạo các Lambda Roles còn lại Làm theo quy trình tương tự cho mỗi role dưới đây (các bước 3-11):\nGuardDutyETLLambdaServiceRole\nRole name: GuardDutyETLLambdaServiceRole Description: Execution role for GuardDuty ETL Lambda function Managed policy: AWSLambdaBasicExecutionRole Inline policy name: GuardDutyETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;arn:aws:s3:::processed-guardduty-findings-ACCOUNT_ID-REGION/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;kms:Decrypt\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:kms:REGION:ACCOUNT_ID:key/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;glue:CreatePartition\u0026#34;, \u0026#34;glue:GetPartition\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:catalog\u0026#34;, \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:database/security_logs\u0026#34;, \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:table/security_logs/processed_guardduty\u0026#34; ] } ] } CloudWatchETLLambdaServiceRole\nRole name: CloudWatchETLLambdaServiceRole Description: Execution role for VPC DNS logs ETL Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/vpc-dns-firehose-stream\u0026#34; } ] } CloudWatchENIETLLambdaServiceRole\nRole name: CloudWatchENIETLLambdaServiceRole Description: Execution role for VPC Flow logs ETL Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchENIETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/vpc-flow-firehose-stream\u0026#34; } ] } CloudWatchExportLambdaServiceRole\nRole name: CloudWatchExportLambdaServiceRole Description: Execution role for CloudWatch log export Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchExportPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateExportTask\u0026#34;, \u0026#34;logs:DescribeExportTasks\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34;, \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } ParseFindingsLambdaServiceRole\nRole name: ParseFindingsLambdaServiceRole Description: Execution role for parsing GuardDuty findings Managed policy: AWSLambdaBasicExecutionRole Không cần inline policy IsolateEC2LambdaServiceRole\nRole name: IsolateEC2LambdaServiceRole Description: Execution role for isolating compromised EC2 instances Managed policy: AWSLambdaBasicExecutionRole Inline policy name: IsolateEC2Policy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:DescribeInstances\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } QuarantineIAMLambdaServiceRole\nRole name: QuarantineIAMLambdaServiceRole Description: Execution role for quarantining compromised IAM users Managed policy: AWSLambdaBasicExecutionRole Inline policy name: QuarantineIAMPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iam:AttachUserPolicy\u0026#34;, \u0026#34;iam:ListAttachedUserPolicies\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:iam::ACCOUNT_ID:user/*\u0026#34;, \u0026#34;arn:aws:iam::ACCOUNT_ID:policy/IrQuarantineIAMPolicy\u0026#34; ] } ] } AlertDispatchLambdaServiceRole\nRole name: AlertDispatchLambdaServiceRole Description: Execution role for dispatching alerts via SNS/SES/Slack Managed policy: AWSLambdaBasicExecutionRole Inline policy name: AlertDispatchPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sns:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:REGION:ACCOUNT_ID:IncidentResponseAlerts\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ses:SendEmail\u0026#34;, \u0026#34;ses:SendRawEmail\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.1-set-up-s3-buckets/","title":"Thiết lập S3 buckets","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo 5 S3 buckets phục vụ làm nền tảng cho hệ thống Phản hồi Sự cố Tự động (Auto Incident Response system).\nQuan trọng: Thay thế ACCOUNT_ID bằng AWS Account ID của bạn và REGION bằng region mục tiêu của bạn (ví dụ: us-east-1) trong tất cả các tên bucket.\nTên Bucket incident-response-log-list-bucket-ACCOUNT_ID-REGION - Bucket thu thập log chính processed-cloudtrail-logs-ACCOUNT_ID-REGION - Lưu trữ CloudTrail logs đã xử lý athena-query-results-ACCOUNT_ID-REGION - Lưu trữ kết quả truy vấn Athena processed-cloudwatch-logs-ACCOUNT_ID-REGION - Lưu trữ CloudWatch logs đã xử lý processed-guardduty-findings-ACCOUNT_ID-REGION - Lưu trữ GuardDuty findings đã xử lý Hướng dẫn tạo Bucket Mở Amazon S3 Console Truy cập https://console.aws.amazon.com/s3/ Hoặc: AWS Management Console → Services → S3 Nhấn vào \u0026ldquo;Create bucket\u0026rdquo; Cấu hình chung: Bucket name: Nhập incident-response-log-list-bucket-ACCOUNT_ID-REGION Ví dụ: incident-response-log-list-bucket-123456789012-us-east-1 AWS Region: Chọn region mục tiêu của bạn (ví dụ: US East (N. Virginia) us-east-1) Object Ownership:\nGiữ mặc định: ACLs disabled (recommended) Cài đặt Block Public Access cho bucket này:\nChọn \u0026ldquo;Block all public access\u0026rdquo; Đảm bảo tất cả 4 tùy chọn phụ đều được chọn: ✓ Block public access to buckets and objects granted through new access control lists (ACLs) ✓ Block public access to buckets and objects granted through any access control lists (ACLs) ✓ Block public access to buckets and objects granted through new public bucket or access point policies ✓ Block public and cross-account access to buckets and objects through any public bucket or access point policies Bucket Versioning:\nChọn \u0026ldquo;Enable\u0026rdquo; Tags (tùy chọn):\nThêm tags nếu muốn Ví dụ: Key=Purpose, Value=IncidentResponse Mã hóa mặc định (Default encryption):\nEncryption type: Chọn \u0026ldquo;Server-side encryption with Amazon S3 managed keys (SSE-S3)\u0026rdquo; Bucket Key: Giữ mặc định (Enabled) Cài đặt nâng cao (Advanced settings):\nGiữ nguyên tất cả mặc định Nhấn \u0026ldquo;Create bucket\u0026rdquo;\nXác minh tạo bucket:\nBạn sẽ thấy thông báo thành công Bucket sẽ xuất hiện trong danh sách S3 buckets của bạn Lặp lại các bước 2-10 cho 4 buckets còn lại:\nprocessed-cloudtrail-logs-ACCOUNT_ID-REGION athena-query-results-ACCOUNT_ID-REGION processed-cloudwatch-logs-ACCOUNT_ID-REGION processed-guardduty-findings-ACCOUNT_ID-REGION Xác minh tất cả 5 buckets đã được tạo:\nĐiều hướng đến S3 Console Bạn sẽ thấy tất cả 5 buckets được liệt kê "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.1-workshop-overview/","title":"Tổng quan","tags":[],"description":"","content":"Các thành phần hệ thống Phản hồi sự cố và Điều tra số tự động (Auto Incident Response and Forensics) là một kiến trúc sử dụng các dịch vụ tự động hóa để thu thập, xử lý và tự động phản hồi các phát hiện bảo mật, giảm thiểu thời gian cần thiết cho sự can thiệp của con người và hỗ trợ nhân viên bảo mật trong việc trực quan hóa và phân tích log. Hệ thống này được xây dựng dựa trên AWS Security Services (CloudTrail, GuardDuty, VPC Flow Logs, CloudWatch) đưa dữ liệu vào một Data Lake tập trung (S3/Glue/Athena) để phân tích. Tự động hóa cốt lõi được điều khiển bởi AWS EventBridge rules kích hoạt AWS Step Functions workflows, sau đó thực thi AWS Lambda functions để thực hiện các hành động cách ly và cảnh báo. Ảnh kiến trúc của Workshop\nTổng quan về Workshop Trong workshop này, bạn sẽ triển khai một hệ thống đa giai đoạn để đạt được tự động hóa bảo mật từ đầu đến cuối. Bao gồm:\nThiết lập nền tảng (Foundation Setup): Tạo các S3 buckets và IAM roles chuyên dụng để hỗ trợ tất cả các dịch vụ. Thiết lập giám sát (Monitoring Setup): Kích hoạt và cấu hình các log bảo mật chính (CloudTrail, GuardDuty, VPC Flow Logs) để chuyển dữ liệu đến điểm thu thập log trung tâm. Thiết lập xử lý (Processing Setup): Triển khai Kinesis Firehose, Lambda ETLs, và Glue/Athena tables để chuyển đổi log thô thành một security data lake dễ dàng truy vấn. Thiết lập tự động hóa (Automation Setup): Tạo Isolation Security Group, SNS Topic, Incident Response Lambda Functions, và Step Functions State Machine thực thi các hành động cách ly tự động khi GuardDuty phát hiện các vấn đề. Thiết lập Dashboard (Dashboard Setup): Lưu trữ một giao diện web tĩnh dựa trên S3 an toàn được tăng tốc bởi CloudFront và bảo vệ bởi Cognito để cung cấp cho các nhà phân tích khả năng trực quan hóa thời gian thực của dữ liệu điều tra (forensic data) và khả năng truy vấn trực tiếp qua API Gateway. "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/2-proposal/","title":"Proposal","tags":[],"description":"","content":"\nHệ thống Ứng phó Sự cố và Điều tra Số Tự động trên AWS Proposal Link: Proposal 1. Tóm tắt Nhóm của chúng tôi đang xây dựng một giải pháp ứng phó sự cố và điều tra số tự động như một phần của chương trình thực tập AWS First Cloud Journey. Ý tưởng rất đơn giản—khi một vấn đề bảo mật xảy ra trong AWS, chúng tôi muốn hệ thống phản ứng tự động mà không cần chờ đợi sự can thiệp thủ công.\nChúng tôi đang tạo ra một nền tảng tự động phát hiện các phát hiện bảo mật từ GuardDuty, cô lập các tài nguyên bị ảnh hưởng, thu thập bằng chứng pháp y thông qua việc thu thập dữ liệu toàn diện, và cung cấp các phân tích và bảng điều khiển để các đội bảo mật có thể điều tra những gì đã xảy ra. Mọi thứ được xây dựng bằng Infrastructure-as-Code với AWS CDK, vì vậy khách hàng có thể dễ dàng triển khai nó vào tài khoản AWS của riêng họ.\n2. Báo cáo Vấn đề Vấn đề là gì? Tần suất và sự tinh vi ngày càng tăng của các mối đe dọa mạng đặt ra những rủi ro đáng kể cho các tổ chức dựa vào cơ sở hạ tầng đám mây. Quy trình ứng phó sự cố thủ công thường chậm chạp, không nhất quán và dễ mắc lỗi của con người, có thể dẫn đến thời gian ngừng hoạt động hệ thống kéo dài, vi phạm dữ liệu và tổn thất tài chính. Dự án nhằm giải quyết những thách thức này bằng cách phát triển một hệ thống ứng phó sự cố tự động, đáng tin cậy và có khả năng mở rộng.\nGiải pháp Các trường hợp sử dụng chính bao gồm phát hiện việc sử dụng trái phép thông tin xác thực AWS, xác định các EC2 instance bị xâm nhập, và đảm bảo dữ liệu pháp y được thu thập, xử lý và lưu trữ đúng cách để điều tra. Kiến trúc của chúng tôi tích hợp VPC Flow Logs, CloudTrail, CloudWatch và GuardDuty để phát hiện các mối đe dọa, trong khi Step Functions điều phối quy trình ứng phó tự động bao gồm cô lập EC2, tách khỏi ASG, tạo Snapshot và cách ly IAM. Tất cả bằng chứng được thu thập và xử lý thông qua Lambda ETL tùy chỉnh và Data Firehose, sử dụng Athena để phân tích pháp y. Hệ thống cũng bao gồm alert dispatching, notification bằng email và Slack, và cho chúng ta cái dashboard để analyze và điều tra chuyện đã xảy ra.\nLợi ích và Tỷ suất Lợi nhuận (ROI) Phát hiện mối đe dọa nhanh chóng: Phản ứng tự động giúp giảm thiểu khoảng thời gian dễ bị tổn thương. Thu thập bằng chứng toàn diện: Tự động hóa việc thu thập dữ liệu pháp y, tạo điều kiện cho các cuộc điều tra nhanh hơn. Hiệu quả về chi phí: Tận dụng các dịch vụ serverless của AWS giúp giảm thiểu chi phí cơ sở hạ tầng. Cải thiện tư thế bảo mật: Thông qua giám sát liên tục và cảnh báo thời gian thực. Thông tin chi tiết hữu ích: Các bảng điều khiển và phân tích trao quyền cho các đội bảo mật. Khả năng mở rộng: Thích ứng với các tổ chức có quy mô và khối lượng sự cố khác nhau. 3. Kiến trúc Giải pháp Giải pháp của chúng tôi sử dụng một kiến trúc đa giai đoạn toàn diện cho việc ứng phó sự cố và điều tra số tự động:\nCác Dịch vụ AWS Được Sử dụng Amazon GuardDuty: Liên tục theo dõi các mối đe dọa bảo mật và hoạt động đáng ngờ. AWS Step Functions: Điều phối quy trình ứng phó sự cố. AWS Lambda: Chạy mã tự động hóa để cô lập và xử lý dữ liệu. Amazon EventBridge: Định tuyến các phát hiện từ GuardDuty đến Step Functions. Amazon S3: Lưu trữ bằng chứng pháp y và lưu trữ bảng điều khiển tĩnh. Amazon Athena: Cho phép thực hiện các truy vấn SQL trên các tập dữ liệu pháp y. Amazon API Gateway: Tạo điều kiện giao tiếp giữa bảng điều khiển và backend. Amazon Cognito: Bảo mật quyền truy cập cho người dùng bảng điều khiển. Amazon CloudFront: Tăng tốc độ phân phối bảng điều khiển trên toàn cầu. Amazon SNS \u0026amp; SES: Xử lý thông báo qua tin nhắn và email. AWS CloudTrail: Ghi nhật ký tất cả các hành động để kiểm toán. Amazon CloudWatch: Giám sát và bảng điều khiển. Amazon EC2: Các instance tùy chọn để phân tích. AWS KMS: Quản lý khóa để mã hóa. Amazon Kinesis Data Firehose: Truyền dữ liệu đến S3. Thiết kế Thành phần Lớp Thu thập Dữ liệu \u0026amp; Phát hiện: Thu thập các sự kiện từ VPC Flow Logs, CloudTrail, CloudWatch, EC2 và GuardDuty. Lớp Xử lý Sự kiện: Alert Dispatch, EventBridge định tuyến các phát hiện đến Step Functions; các sự kiện được phân loại theo loại. Điều phối Ứng phó Tự động (Orchestration): Step Functions xử lý phân tích, ra quyết định, cô lập EC2, bảo vệ chấm dứt, tách ASG, tạo snapshot và cách ly IAM. Lớp Xử lý Dữ liệu \u0026amp; Phân tích: ETL pipeline với Lambda và Data Firehose xử lý nhật ký thô vào S3; Athena truy vấn dữ liệu. Lớp Bảng điều khiển \u0026amp; Phân tích: Bảng điều khiển React lưu trữ trên S3 với xác thực Cognito, sử dụng dữ liệu qua API Gateway và Athena. 4. Triển khai Kỹ thuật Các Giai đoạn Triển khai Chúng tôi sử dụng Agile Scrum với các sprint 1 tuần trong vòng 6 tuần:\nSprint 1: Nền tảng \u0026amp; Thiết lập (VPC, Security Groups, Đào tạo). Sprint 2: Điều phối Cốt lõi (Step Functions, Lambda, tích hợp GuardDuty). Sprint 3: Dữ liệu \u0026amp; Phân tích (S3, Athena, ETL pipeline). Sprint 4: Bảng điều khiển \u0026amp; UI (Trang web tĩnh, API Gateway, CloudFront). Sprint 5: Kiểm thử \u0026amp; Tối ưu hóa (Cognito, Kiểm thử hiệu suất, Mô phỏng). Sprint 6: Tài liệu \u0026amp; Bàn giao (Hướng dẫn, Demo, Hoàn thiện). Yêu cầu Kỹ thuật Frontend \u0026amp; Bảng điều khiển: HTML/CSS/JS tùy chỉnh được lưu trữ trên S3, phục vụ qua CloudFront. Backend \u0026amp; Xử lý: Python 3.12 cho Lambda, Step Functions để điều phối. Dữ liệu \u0026amp; Lưu trữ: S3 cho bằng chứng, Athena để truy vấn, Firehose để truyền dữ liệu. Cơ sở hạ tầng: Tất cả được định nghĩa trong AWS CDK (Python). Bảo mật: GuardDuty để phát hiện, IAM cho quyền hạn tối thiểu, KMS để mã hóa. 5. Thời gian biểu \u0026amp; Cột mốc Dòng thời gian Dự án Dòng thời gian Dự án\nTuần 6-7 (Nền tảng \u0026amp; Thiết lập) Hoạt động: Đào tạo nhóm về GuardDuty/Step Functions, đánh giá thiết kế kiến trúc, thiết lập VPC và bảo mật. Sản phẩm bàn giao: Tài liệu kiến trúc v1, hoàn thành đào tạo nhóm, kho lưu trữ GitHub được thiết lập. Tuần 7-9 (Điều phối Cốt lõi) Hoạt động: Phát triển quy trình Step Functions, lập trình hàm Lambda cho tất cả các hành động ứng phó, tích hợp EventBridge, thiết lập SNS/SES, kiểm thử tích hợp. Sản phẩm bàn giao: Định nghĩa máy trạng thái Step Functions, hơn 7 hàm Lambda có tài liệu, tích hợp GuardDuty, hệ thống thông báo, API Gateway. Tuần 10 (Dữ liệu \u0026amp; Phân tích) Hoạt động: Thiết lập lưu trữ pháp y S3, tạo bảng Athena, phát triển đường ống ETL, thư viện truy vấn SQL. Sản phẩm bàn giao: Hơn 15 truy vấn Athena được ghi lại, sách hướng dẫn phân tích pháp y, lưu trữ dữ liệu đã xử lý. Tuần 11 (Bảng điều khiển \u0026amp; UI) Hoạt động: Phát triển bảng điều khiển tĩnh, xác thực Cognito, thiết lập API Gateway, cấu hình CloudFront CDN, tích hợp bảng điều khiển. Sản phẩm bàn giao: Bảng điều khiển lưu trữ trên S3, hệ thống xác thực, giao diện truy vấn, tích hợp kết quả thời gian thực. Tuần 12 (Kiểm thử, Xác thực \u0026amp; Tối ưu hóa) Hoạt động: Kiểm thử thủ công, quét bảo mật bao gồm các kịch bản sự cố mô phỏng (hơn 5 quy trình), kiểm thử hiệu suất, mô phỏng tấn công. Tối ưu hóa dữ liệu với truy vấn Athena và Data Firehose. Sản phẩm bàn giao: Kết quả quét bảo mật, video mô phỏng sự cố, tối ưu hóa dữ liệu. Tuần 13 (Tài liệu \u0026amp; Bàn giao) Hoạt động: Hướng dẫn triển khai, tài liệu API, các phiên chuyển giao kiến thức, demo cuối cùng, dọn dẹp GitHub. Sản phẩm bàn giao: Kho lưu trữ GitHub hoàn chỉnh (công khai), hướng dẫn triển khai, buổi trình diễn workshop trực tiếp. 6. Ước tính Ngân sách Bạn có thể tìm thấy ước tính ngân sách chi tiết trên AWS Pricing Calculator.\nChi phí Cơ sở hạ tầng Chi phí triển khai hàng tháng điển hình (Bậc miễn phí / Quy mô nhỏ): ~$5.01\nGuardDuty: ~$1.80/tháng S3: ~$1.07/tháng KMS: ~$1.12/tháng CloudTrail: ~$0.55/tháng Athena: ~$0.29/tháng Amazon Simple Email Service (SES): ~$0.09/tháng Amazon API Gateway: ~$0.05/tháng Amazon Data firehose: ~$0.04/tháng Lambda, Step Functions, SNS: Thường nằm trong giới hạn Bậc miễn phí cho mức sử dụng thông thường. Lưu ý: Chi phí giả định mức sử dụng thông thường từ 20-150 sự cố mỗi tháng.\n7. Đánh giá Rủi ro Ma trận Rủi ro Tắc nghẽn Hiệu suất: Khối lượng dữ liệu lớn làm chậm các truy vấn. Vi phạm Bảo mật: Xâm phạm chính dữ liệu pháp y. Vượt quá Chi phí: Ghi nhật ký không kiểm soát hoặc vòng lặp vô hạn. Chiến lược Giảm thiểu Hiệu suất: Giám sát Athena/Firehose; tối ưu hóa truy vấn; điều chỉnh tài nguyên động. Bảo mật: Mã hóa (KMS), vai trò IAM nghiêm ngặt, ghi nhật ký kiểm toán. Chi phí: Cảnh báo ngân sách AWS, phát hiện bất thường chi phí, giới hạn tự động mở rộng. Khôi phục sau Thảm họa: Sao lưu, quy trình chuyển đổi dự phòng và các biện pháp dự phòng. 8. Kết quả Dự kiến Cải tiến Kỹ thuật Ứng phó Tự động: Cô lập không chạm (zero-touch) các tài nguyên bị xâm nhập. Tốc độ: Giảm thời gian điều tra từ hàng giờ xuống còn vài phút. Độ tin cậy: Thu thập bằng chứng nhất quán, có thể lặp lại mà không có lỗi của con người. Giá trị Dài hạn Kiến trúc Có thể Mở rộng: Nền tảng cho tự động hóa bảo mật trong tương lai. Kiến thức: Năng lực của nhóm về bảo mật AWS nâng cao và các khái niệm serverless. Tài sản Có thể Tái sử dụng: Một giải pháp có thể triển khai cho các khách hàng hoặc nhóm AWS khác. Trạng thái: Sẵn sàng cho Xem xét \u0026amp; Phê duyệt Mã Dự án: AWS-FCJ-IR-FORENSICS-2025\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/4-eventparticipated/4.2-event2/","title":"Sự kiện 2","tags":[],"description":"","content":"Báo Cáo Tóm Tắt: “AI-Driven Development Life Cycle: Reimagining Software Engineering” Mục tiêu Sự kiện Khám phá sự chuyển đổi mang tính cách mạng trong phát triển phần mềm được thúc đẩy bởi generative AI (AI tạo sinh). Giới thiệu AI-Driven Development Life Cycle (AI-DLC) và các khái niệm cốt lõi của nó. Demo về Kiro và Amazon Q Developer. Diễn giả Toan Huynh – Specialist SA, PACE My Nguyen - Sr. Prototyping Architect, Amazon Web Services - ASEAN Nội dung nổi bật Tập trung vào khái niệm AI-DLC, một khuôn khổ nơi AI điều phối quá trình phát triển, bao gồm lập kế hoạch, phân rã tác vụ và đề xuất kiến trúc, trong khi các nhà phát triển vẫn giữ trách nhiệm cuối cùng về xác thực, ra quyết định và giám sát. - Khái niệm Cốt lõi của AI-DLC: Phương pháp tiếp cận này lấy con người làm trung tâm (Human-Centric), với AI đóng vai trò là Cộng tác viên (Collaborator) để tăng cường khả năng của nhà phát triển, dẫn đến Tốc độ Giao hàng Nhanh hơn (Accelerated Delivery) (chu kỳ được tính bằng giờ/ngày thay vì tuần/tháng).\n- Quy trình làm việc của AI-DLC: Đây là một vòng lặp lặp đi lặp lại bao gồm AI Tasks (Tạo kế hoạch, Thực hiện kế hoạch, Tìm kiếm làm rõ) và Human Tasks (Cung cấp làm rõ, Thực hiện kế hoạch), trong đó AI liên tục đặt các câu hỏi làm rõ và chỉ thực hiện giải pháp sau khi có sự xác thực của con người.\n- Các giai đoạn của AI-DLC: Vòng đời được chia thành Khởi tạo (Inception), Xây dựng (Construction) và Vận hành (Operation). Mỗi giai đoạn xây dựng ngữ cảnh phong phú hơn cho giai đoạn tiếp theo:\nInception: Bao gồm xây dựng ngữ cảnh, làm rõ ý định bằng User Stories (Câu chuyện người dùng), và lập kế hoạch với Units of Work (Đơn vị công việc).\nConstruction: Bao gồm Lập mô hình Miền (Domain Modeling), tạo mã và kiểm thử, thêm các thành phần kiến trúc, và triển khai bằng IaC \u0026amp; kiểm thử.\nOperation: Tập trung vào triển khai vào sản xuất và quản lý sự cố (incidents).\n- Các Thách thức mà AI-DLC nhằm mục đích Giải quyết:\nMở rộng phát triển AI: Các công cụ lập trình AI có thể thất bại với các dự án phức tạp.\nKiểm soát hạn chế: Các công cụ hiện có gây khó khăn trong việc cộng tác và quản lý các AI agent.\nChất lượng mã: Việc duy trì kiểm soát chất lượng khi chuyển từ proof-of-concept sang sản xuất trở nên khó khăn.\nKhám phá Sâu hơn: Kiro - AI IDE cho Prototype đến Production Kiro, một Môi trường Phát triển Tích hợp (IDE) ưu tiên AI (AI-first), hỗ trợ AI-DLC, tập trung vào Phát triển dựa trên Đặc tả (Spec-driven development). - Phát triển dựa trên Đặc tả: Kiro biến một lời nhắc cấp cao (ví dụ: \u0026ldquo;Tôi muốn tạo một ứng dụng chat như Slack\u0026rdquo;) thành các yêu cầu rõ ràng (requirements.md), thiết kế hệ thống (design.md), và các tác vụ riêng biệt (tasks.md), về cơ bản chuyển đổi việc phát triển từ \u0026ldquo;vibe coding\u0026rdquo; sang một quy trình có cấu trúc, có thể truy vết. Các nhà phát triển cộng tác với Kiro dựa trên các đặc tả này, vốn đóng vai trò là nguồn sự thật duy nhất (source of truth).\n- Quy trình làm việc của Agentic: Các AI agent của Kiro thực hiện đặc tả trong khi vẫn giữ nhà phát triển con người kiểm soát, với các tính năng chính là:\n+ Implementation Plan (Kế hoạch Thực hiện): Kiro tạo ra một Kế hoạch Thực hiện chi tiết với các tác vụ bắt đầu, các tác vụ phụ (ví dụ: \u0026ldquo;Implement user registration and login endpoints,\u0026rdquo; \u0026ldquo;Implement JWT middleware\u0026rdquo;), và liên kết chúng trở lại các yêu cầu cụ thể để xác thực.\n+ Agent Hooks: Chúng ủy quyền các tác vụ cho AI agent kích hoạt trên các sự kiện như \u0026ldquo;lưu file\u0026rdquo;. Chúng tự động thực thi trong nền dựa trên các lời nhắc được xác định trước, giúp mở rộng công việc bằng cách tạo tài liệu, kiểm thử đơn vị (unit tests) hoặc tối ưu hóa hiệu suất mã.\nNhững điểm rút ra chính - AI Đảm bảo Khả năng Sẵn sàng cho Sản xuất: Kiro tạo các tài liệu thiết kế chi tiết (như sơ đồ luồng dữ liệu và API contracts) và tạo unit tests trước khi mã được viết, đảm bảo rằng mã được tạo bởi AI đã sẵn sàng cho sản xuất và dễ bảo trì, chứ không chỉ là một prototype nhanh chóng.\n- Kiểm soát của Con người thông qua Artifacts: Các nhà phát triển duy trì quyền kiểm soát không phải bằng cách viết phần lớn mã, mà bằng cách xác thực và tinh chỉnh các artifacts—các yêu cầu, thiết kế và kế hoạch tác vụ—trước khi các AI agent thực hiện triển khai.\nÁp dụng vào Công việc - Tích hợp Amazon Q Developer/Các Công cụ Tương tự: Tích hợp các trợ lý lập trình AI vào các dự án học thuật của tôi để tự động hóa mã boilerplate và các tác vụ thông thường nhằm tăng năng suất.\n- Tập trung vào các Tác vụ Giá trị Cao: Bằng cách để AI tự động hóa những công việc nặng nhọc không tạo ra sự khác biệt (undifferentiated heavy lifting), tôi có thể tập trung thời gian vào việc nắm vững các tác vụ sáng tạo, giá trị cao hơn như Lập mô hình Miền (Domain Modeling) và Thiết kế Kiến trúc (Architectural Design), đây là những hoạt động lấy con người làm trung tâm quan trọng trong giai đoạn Xây dựng (Construction). Trải nghiệm Sự kiện Tham dự sự kiện AI-Driven Development Life Cycle: Reimagining Software Engineering đã mang lại một cái nhìn hấp dẫn về tương lai của phát triển phần mềm. Rõ ràng là Generative AI không chỉ là một trợ lý lập trình; nó sẵn sàng trở thành một công cụ điều phối cốt lõi cho toàn bộ quá trình phát triển. Phiên này được cấu trúc tốt, chuyển từ khái niệm bao quát của AI-DLC sang các minh chứng cụ thể về Amazon Q Developer và Kiro. Bản demo về Kiro đặc biệt ấn tượng, cho thấy cách một lời nhắc văn bản đơn giản có thể được chuyển đổi thành một kế hoạch phát triển đầy đủ, có thể thực thi và truy vết ngay trong IDE.\nBài học rút ra Ba thách thức chính đối với phát triển AI hiện tại (mở rộng, kiểm soát hạn chế và chất lượng mã) khiến phương pháp tiếp cận có cấu trúc, được con người xác thực của AI-DLC trở nên rất cần thiết và được cân nhắc kỹ lưỡng. Một số hình ảnh sự kiện Ảnh nhóm\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/1.2-week2/","title":"Nhật ký Công việc Tuần 2","tags":[],"description":"","content":"Mục tiêu Tuần 2: Hoàn thành Module 3 \u0026amp; 4 Giúp các thành viên trong nhóm bắt kịp tiến độ Thảo luận ý tưởng workshop Thực hiện nghiên cứu tùy chọn đầu tiên: AWS Well-Architected Framework Xem qua AWS Advanced Networking - Specialty Study Guide Xem qua AWS Microsoft Workload Xem qua AWS Skill Builder Các nhiệm vụ được thực hiện trong tuần này: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Bắt đầu Module 4 - Học về các dịch vụ lưu trữ của AWS (AWS Storage services) - Học về S3 Bucket Access Point và Storage class 15/09/2025 15/09/2025 3 - Lab 4 - Lab 6: RDS Database - Sử dụng Linux qua EC2 instance thành công để: + Cài đặt và sử dụng cơ sở dữ liệu MySQL + Cài đặt và chạy một ứng dụng web, có thể kết nối từ browsers - Tạo Load Balancer và Target Groups - Công cụ Paessler Webstress đã ngừng hoạt động, không thể kiểm thử bằng công cụ được cung cấp - Cài đặt Siege trên EC2 instance thành công để load test: + Chạy load test, mô phỏng 50 người dùng cùng lúc trong 10 phút + EC2 instance bị terminate và cân bằng tải 10 lần liên tiếp + Siege tự động dừng sau 5 phút do mất quá nhiều gói (packet loss) + Lý do có thể là do EC2 instance và RDS Database được tạo bằng các tùy chọn miễn phí duy nhất có sẵn (free tier), và không thể xử lý lưu lượng truy cập tăng lên. - Host database bằng RDS thành công 16/09/2025 16/09/2025 Lab 6 4 Module 4.3, Module 4.4 - Giúp đồng đội với Lab 5 - Hướng dẫn Lab 5 bị thiếu một số bước: 5.5.3: Script được cung cấp không kết nối RDS database với MySQL, 5.5.5: Hướng dẫn thiếu bước: cd đến thư mục ứng dụng 17/09/2025 17/09/2025 Lab 5 5 - Tham gia Sự kiện AWS Cloud Day 2025 HCM: Gen AI and Data track 18/09/2025 18/09/2025 Vietnam Cloud Day Agenda Tóm tắt và Trải nghiệm Sự kiện 6 - Thử lại Lab 10: + Sửa template được cung cấp: Thay đổi Region thành ap-southeast-1, instance thành t3.micro + Cấu hình thành công các endpoints và rules trong Route 53 cho hybrid DNS + Triển khai Microsoft AD thành công\n- Lab 8:\n+ Xem các metrics và đồ thị bằng CloudWatch trên các EC2 Instances đã chọn + Học những kiến thức cơ bản về giám sát logs + 8.4.2: không thể thực hiện: Không thể tìm thấy tài nguyên s3://workshop-template-bucket/logger.py . + Cấu hình CloudWatch Alarm và Dashboard - Lab 14: Cài đặt Ubuntu - Định dạng lại worklog - Viết về trải nghiệm Cloud Day 2025 - Nghiên cứu bổ sung về AWS Well-Architected Framework: + Tài liệu hóa một bộ câu hỏi nền tảng giúp bạn hiểu kiến trúc cụ thể phù hợp với các cloud best practices như thế nào + Các trụ cột: • Operational Excellence (Vận hành Xuất sắc): Tập trung vào việc chạy và giám sát các hệ thống để mang lại giá trị kinh doanh, và liên tục cải tiến các quy trình và thủ tục hỗ trợ. • Security (Bảo mật): Tập trung vào việc bảo vệ thông tin, hệ thống và tài sản, đồng thời mang lại giá trị kinh doanh thông qua đánh giá rủi ro và chiến lược giảm thiểu. • Reliability (Độ tin cậy): Tập trung vào khả năng của một khối lượng công việc thực hiện chức năng dự định của nó một cách chính xác và nhất quán khi nó được mong đợi. • Performance Efficiency (Hiệu suất Hiệu quả): Tập trung vào việc sử dụng tài nguyên tính toán hiệu quả để đáp ứng các yêu cầu hệ thống, và duy trì hiệu suất đó khi nhu cầu thay đổi. • Cost Optimization (Tối ưu hóa Chi phí): Tập trung vào việc tránh các chi phí không cần thiết bằng cách quản lý và kiểm soát nơi chi tiêu tiền trong cloud. • Sustainability (Tính bền vững): Tập trung vào việc giảm thiểu các tác động môi trường của việc chạy các khối lượng công việc cloud. + Mục đích: • Một dịch vụ cloud để review và đo lường khối lượng công việc của bạn theo các best practices của AWS để xây dựng các hệ thống an toàn hơn, có khả năng phục hồi cao hơn, hiệu suất cao hơn và tiết kiệm chi phí hơn.\n• Chức năng Cốt lõi: Xác định các Vấn đề Rủi ro Cao (High Risk Issues - HRIs) và Vấn đề Rủi ro Trung bình (Medium Risk Issues - MRIs) trong kiến trúc của bạn và cung cấp kế hoạch cải tiến để giảm thiểu chúng. + Cách sử dụng: • Bước 1: Xác định một Khối lượng Công việc (Define a Workload): Chỉ định tên, môi trường, chủ sở hữu và regions cho ứng dụng hoặc hệ thống bạn đang review.\n• Bước 2: Tài liệu hóa Trạng thái (Document the State): Trả lời các câu hỏi dựa trên các trụ cột của AWS Well-Architected Framework (Security, Reliability, v.v.) và lưu một \u0026ldquo;mốc quan trọng\u0026rdquo; (milestone) để ghi lại tiến độ của bạn.\n• Bước 3: Review Kế hoạch Cải tiến (Review the Improvement Plan): Công cụ tạo ra một danh sách rủi ro được ưu tiên (HRIs và MRIs) dựa trên câu trả lời của bạn.\n• Bước 4: Thực hiện Cải tiến \u0026amp; Đo lường (Make Improvements \u0026amp; Measure): Cập nhật kiến trúc của bạn dựa trên kế hoạch, sau đó cập nhật câu trả lời của bạn trong công cụ để theo dõi sự giảm thiểu rủi ro theo thời gian + Tính năng Chính: • Workloads (Khối lượng Công việc): Thành phần trung tâm đại diện cho ứng dụng của bạn; có thể được xem, chỉnh sửa, chia sẻ và xóa. • Lenses (Ống kính): Cung cấp các câu hỏi tập trung cho các công nghệ cụ thể (ví dụ: Serverless Lens) hoặc các ngành công nghiệp. Bạn cũng có thể tạo Custom Lenses cho các tiêu chuẩn nội bộ. • Review Templates \u0026amp; Profiles (Mẫu Review \u0026amp; Hồ sơ): Giúp chuẩn hóa các review bằng cách điền trước các câu trả lời phổ biến (Templates) và ưu tiên các câu hỏi dựa trên mục tiêu kinh doanh (Profiles). • Jira Integration (Tích hợp Jira): Cho phép bạn đồng bộ hóa các mục cải tiến trực tiếp từ Well-Architected Tool vào các dự án Jira của bạn dưới dạng epics, tasks và sub-tasks để theo dõi hợp lý. + Bảo mật: • Shared Responsibility Model (Mô hình Trách nhiệm Chia sẻ): AWS bảo mật cơ sở hạ tầng cloud, trong khi bạn chịu trách nhiệm bảo mật khối lượng công việc của mình trong cloud. • IAM Integration (Tích hợp IAM): Quyền truy cập được kiểm soát thông qua AWS IAM, với các chính sách được xây dựng sẵn cho quyền truy cập đầy đủ và quyền truy cập chỉ đọc. • Data Protection (Bảo vệ Dữ liệu): Khuyến nghị sử dụng IAM users (không phải root), bật MFA, và tránh đặt dữ liệu nhạy cảm trong các trường văn bản tự do (free-form text fields). • Monitoring \u0026amp; Auditing (Giám sát \u0026amp; Kiểm tra): Tích hợp với AWS CloudTrail để ghi lại tất cả hoạt động API và với Amazon EventBridge để kích hoạt thông báo tự động. 19/09/2025 20/09/2025 Lab 10 Lab 8 Lab 14 AWS Well Architected Framework Thành tựu Tuần 2: Hoàn thành thành công các lab cốt lõi trong Module 3 (tập trung vào RDS, Load Balancing) và đạt tiến bộ đáng kể trong Module 4.\nSử dụng Linux qua EC2 để cài đặt và chạy cơ sở dữ liệu MySQL và triển khai một ứng dụng web được kết nối, host database thành công bằng RDS (Relational Database Service).\nThiết lập thành công Load Balancer và Target Groups, và thích ứng với một công cụ đã ngừng hoạt động bằng cách cài đặt và sử dụng Siege trên một EC2 instance để thực hiện load test.\nCấu hình các endpoints và rules của Route 53 cho thiết lập hybrid DNS, bao gồm cả việc triển khai Microsoft AD.\nĐạt được kiến thức nền tảng về giám sát cloud bằng cách xem các metrics và đồ thị trong CloudWatch, cấu hình Alarms và Dashboards, và học các kiến thức cơ bản về quản lý log.\nHỗ trợ Nhóm: Hỗ trợ các thành viên trong nhóm làm lab, xác định và giúp sửa các bước bị thiếu trong hướng dẫn lab.\nĐã tham dự Sự kiện AWS Cloud Day 2025 HCM (Gen AI and Data track).\nNghiên cứu Tùy chọn: Hoàn thành nghiên cứu về AWS Well-Architected Framework, tài liệu hóa mục đích, các bước sử dụng, các tính năng chính (Lenses, Templates, Profiles) và các cân nhắc về bảo mật của nó.\nThiết lập Kỹ thuật: Cài đặt Ubuntu trên máy thành công và định dạng lại worklog để cải thiện cách trình bày.\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"AWS DevOps \u0026amp; Developer Productivity Blog Amazon Q Developer CLI hỗ trợ đầu vào hình ảnh trong terminal của bạn bởi Keerthi Sreenivas Konjety vào ngày 21 tháng 5 2025 trong Amazon Q Developer, Announcements | Permalink | Chia sẻ\nTrong bài đăng này, tôi sẽ khám phá cách tính năng hỗ trợ hình ảnh trong Amazon Q Developer Command Line Interface (CLI) thay đổi quy trình làm việc phát triển. Q Developer CLI gần đây đã bổ sung hỗ trợ hình ảnh, mở rộng khả năng xử lý thông tin trực quan và tăng cường năng suất của nhà phát triển. Tính năng mới này cho phép các nhà phát triển tương tác trực tiếp với sơ đồ, bản thiết kế kiến trúc và các tài sản trực quan khác thông qua dòng lệnh.\nPhát triển phần mềm hiện đại ngày càng dựa vào các biểu diễn trực quan để truyền đạt ý tưởng. Ví dụ, sơ đồ kiến trúc minh họa các thành phần hệ thống và sự tương tác của chúng, trong khi sơ đồ thực thể liên kết phác thảo cấu trúc cơ sở dữ liệu. Việc chuyển đổi tài sản trực quan thành mã hoạt động thường là một quy trình giải thích và triển khai thủ công, dễ xảy ra lỗi.\nTính năng hỗ trợ hình ảnh mới trong Q Developer CLI thu hẹp khoảng cách này bằng cách cho phép các nhà phát triển cung cấp hình ảnh trực tiếp cho tác nhân Q Developer CLI để phân tích. Tôi rất hào hứng khi sử dụng tính năng này để chuyển đổi các sơ đồ kiến trúc của mình từ các ý tưởng phác thảo, vẽ tay thành các tài liệu thiết kế trau chuốt, và sau đó thành cơ sở hạ tầng dưới dạng mã. Tôi mong muốn áp dụng nó trong nhiều trường hợp sử dụng khác nhau, cho dù tôi đang bắt đầu một dự án mới hay tinh giản các quy trình làm việc hàng ngày của mình.\nTại thời điểm ra mắt, Q Developer CLI hỗ trợ các định dạng hình ảnh JPEG, PNG, WEBP và GIF, cùng với khả năng tải lên 10 hình ảnh cho mỗi yêu cầu. Bạn phải sử dụng phiên bản mới nhất (1.10.0 trở lên) của Q Developer CLI để tận hưởng tính năng hỗ trợ hình ảnh trong Q Developer CLI. Hãy sử dụng hướng dẫn này để nâng cấp hoặc cài đặt phiên bản mới nhất.\nTôi sẽ sử dụng bốn tình huống sau làm ví dụ để chứng minh lợi ích của hỗ trợ hình ảnh cho Q Developer CLI.\nTrường hợp sử dụng 1: Tạo cơ sở hạ tầng dưới dạng mã từ sơ đồ kiến trúc Sơ đồ sau mô tả một ứng dụng thay đổi kích thước hình ảnh. Nó bao gồm một bucket Amazon S3 nguồn mà người dùng tải hình ảnh lên, và một hàm AWS Lambda thay đổi kích thước hình ảnh và lưu trữ nó trong một S3 Bucket đích. Giờ đây tôi có thể chuyển đổi sơ đồ kiến trúc thành mã bằng Q Developer CLI.\nKiến trúc cho một ứng dụng thay đổi kích thước hình ảnh\nTrong ảnh chụp màn hình sau, tôi đã yêu cầu Q Developer CLI: “Vui lòng cung cấp cho tôi một mẫu terraform tham chiếu sử dụng các phương pháp hay nhất”. Lưu ý rằng việc kéo và thả hình ảnh vào CLI sẽ thêm đường dẫn vào lời nhắc của bạn. CLI với mã Terraform được tạo bởi Q Developer\nHình ảnh trên cho thấy một phần phản hồi mà Q Developer CLI đã tạo ra.\nQ Developer phản hồi bằng mẫu terraform cần thiết để bắt đầu xây dựng ứng dụng thay đổi kích thước hình ảnh. Q Developer CLI đã phân tích hình ảnh, xác định các thành phần và mối quan hệ của chúng, rồi tạo mã Terraform tương ứng. Mặc dù không hiển thị trong hình ảnh, phản hồi bao gồm mã của hàm Lambda bằng Python và quyền IAM cần thiết cho hàm Lambda.\nTrước đây, việc chuyển đổi sơ đồ này thành cơ sở hạ tầng dưới dạng mã sẽ yêu cầu tôi phải tự giải thích thủ công từng thành phần và viết cấu hình tương ứng. Với hỗ trợ hình ảnh, giờ đây tôi có thể tự động hóa phần lớn quy trình này và tinh chỉnh mã được tạo thông qua một cuộc trò chuyện với Q Developer. Sau đó, tôi có thể trò chuyện với Q Developer để tinh chỉnh mã đã tạo, đặt câu hỏi về các chi tiết triển khai cụ thể hoặc yêu cầu sửa đổi dựa trên các yêu cầu bổ sung và xuất mã sang tệp .tf.\nTrường hợp sử dụng 2: Chuyển đổi sơ đồ ER thành lược đồ cơ sở dữ liệu Đối với tình huống thứ hai, hãy xem xét một trường hợp sử dụng trong đó tôi là một phần của nhóm mô hình hóa dữ liệu đang phát triển phần mềm quản lý khóa học cho các trường đại học. Tôi đã tạo một sơ đồ thực thể liên kết (ER) cho các cấu trúc dữ liệu cốt lõi của họ. Giờ đây tôi có thể sử dụng Q Developer để giúp tôi chuyển đổi sơ đồ ER thành SQL.\nSơ đồ thực thể liên kết cho hệ thống Quản lý Khóa học\nTrong ảnh chụp màn hình sau, tôi đã yêu cầu Q Developer CLI sử dụng sơ đồ ER để tạo lược đồ cơ sở dữ liệu.\nCLI với câu lệnh của người dùng và mã SQL được tạo bởi Q Developer CLI với mã SQL được tạo bởi Q Developer\nHình ảnh trên cho thấy phản hồi mà Q Developer CLI đã tạo ra.\nQ Developer đã phân tích sơ đồ, xác định các thực thể, thuộc tính và mối quan hệ, sau đó tạo mã SQL thích hợp để tạo lược đồ cơ sở dữ liệu.\nSau khi Q Developer đưa ra kết quả, tôi có thể tinh chỉnh lược đồ này thông qua một cuộc trò chuyện với Q Developer bằng cách yêu cầu thay đổi độ dài chuỗi, chỉ mục, v.v., hoặc yêu cầu giải thích về các quyết định thiết kế.\nTrường hợp sử dụng 3: Chuyển đổi hình ảnh vẽ tay thành tài liệu thiết kế Hãy xem xét một tình huống trong đó tôi đã động não ra một ý tưởng trên giấy và tôi muốn chia sẻ ý tưởng này với nhóm của mình. Trong hình ảnh sau, tôi đã vẽ tay quy trình đặt hàng cho một trang web. Khi người dùng trang web đặt mua sách từ trang web, ứng dụng sẽ cập nhật kho hàng, sau đó gọi các hành động thanh toán và giao hàng. Giờ đây tôi có thể sử dụng Q Developer CLI để phác thảo tài liệu từ ý tưởng vẽ tay.\nSơ đồ vẽ tay của luồng quy trình đặt hàng cho một trang web\nTrong ví dụ sau, tôi đã yêu cầu Q Developer viết một tài liệu thiết kế bằng cách sử dụng hình ảnh này làm tham chiếu. CLI với câu lệnh của người dùng và phản hồi được tạo bởi Q Developer\nẢnh chụp màn hình trên cho thấy, Q Developer trước tiên đã đọc hình ảnh và hiểu nội dung từ sơ đồ vẽ tay. CLI với phản hồi được tạo bởi Q Developer\nẢnh chụp màn hình trên là một phần phản hồi mà Q Developer CLI đã tạo ra.\nQ Developer đã chuyển đổi ý tưởng thành một tài liệu thiết kế bao gồm kiến trúc hệ thống, luồng xử lý, mô hình dữ liệu, các yêu cầu chức năng, và các yêu cầu kỹ thuật. Tôi cũng có thể yêu cầu Q Developer xuất toàn bộ nội dung sang tệp .md. Điều này giảm lượng thời gian từ ý tưởng đến thực thi và tinh giản việc viết tài liệu.\nTrường hợp sử dụng 4: Xây dựng bản mô phỏng UI/wireframe từ ảnh chụp màn hình Giả sử tôi muốn bắt đầu xây dựng Giao diện Người dùng (UI) từ tài liệu thiết kế của mình trong trường hợp sử dụng 3. Tôi có thể cung cấp một hình ảnh tham chiếu cho Q Developer để tạo các wireframe ban đầu cho UI của mình.\nTrang chủ mẫu của trang web bán sách\nTrong ví dụ này, tôi đã yêu cầu Q Developer giúp tạo front-end cho một trang web mới bằng Vue.js CLI với câu lệnh của người dùng và phản hồi được tạo bởi Q Developer CLI với mã Vue.js được tạo bởi Q Developer\nHình ảnh trên cho thấy một phần mã Vue.js được tạo bởi Q Developer CLI để tái tạo front-end của trang web trong ảnh chụp màn hình. Sau khi tôi xác minh mã, tôi có thể yêu cầu Q Developer CLI tạo các tệp này cục bộ.\nCách tiếp cận này giảm các khía cạnh dễ xảy ra lỗi của việc tạo wireframe, cho phép tôi tập trung vào các quyết định thiết kế sáng tạo thay vì các tác vụ thiết lập lặp đi lặp lại. Bằng cách này, tôi có thể tăng tốc chu kỳ phát triển, đảm bảo tính nhất quán giữa các thành phần và cung cấp một nền tảng có thể dễ dàng tùy chỉnh để đáp ứng các yêu cầu dự án cụ thể.\nCác khả năng bổ sung: Ngoài các ví dụ trên, Q Developer CLI có thể phân tích nhiều loại hình ảnh, bao gồm:\nSơ đồ luồng (Flow charts) và sơ đồ quy trình Sơ đồ lớp (Class diagrams) cho thiết kế hướng đối tượng Sơ đồ cấu trúc liên kết mạng (Network topology diagrams) Ảnh chụp màn hình của thông báo lỗi hoặc trạng thái ứng dụng Tính linh hoạt này làm cho Q Developer CLI trở thành một công cụ mạnh mẽ cho các quy trình làm việc phát triển khác nhau.\nKết luận:\nViệc bổ sung hỗ trợ hình ảnh cho Amazon Q Developer CLI đại diện cho một bước tiến đáng kể trong việc thu hẹp khoảng cách giữa các biểu diễn trực quan và văn bản trong phát triển phần mềm. Bằng cách cho phép tôi làm việc với sơ đồ và các tài sản trực quan khác trực tiếp từ dòng lệnh, Amazon Q Developer cải thiện hiệu suất của tôi trong việc chuyển đổi thiết kế thành triển khai, giảm lỗi và tăng tốc các chu kỳ phát triển. Tôi khuyến khích bạn khám phá khả năng mới này và tìm hiểu cách nó có thể tăng cường quy trình làm việc phát triển của bạn.\nĐể tìm hiểu thêm về Q Developer và các khả năng của nó, hãy truy cập tài liệu.\nGiới thiệu về Tác giả: Keerthi Sreenivas Konjety\nKeerthi Sreenivas Konjety là Specialist Solutions Architect cho Amazon Q Developer, với hơn 3,5 năm kinh nghiệm về AI, ML và Kỹ thuật Dữ liệu. Chuyên môn của cô là tăng cường năng suất của nhà phát triển cho khách hàng AWS. Ngoài công việc, cô yêu thích nhiếp ảnh và sáng tạo nội dung AI.\nTAGS: Developer Tools, Development\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/","title":"Cài đặt IAM Roles và Policies","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo IAM role và Policy cho Lambda. Sau đó bạn sẽ tạo Lambda Function để thực thi truy vấn.\nNội dung Tạo Lambda Execution Roles và Policy Tạo Lambda Function "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/5.7.2.2-create-lambda-function/","title":"Cài đặt Lambda","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một Lambda sử dụng Python để thực thi truy vấn dùng dịch vụ Athena.\nTạo Lambda Function Mở Lambda Console\nĐiều hướng tới https://console.aws.amazon.com/lambda/ Hoặc: AWS Management Console → Services → Lambda Tạo Function:\nNhấn Create Function Trong mục cài đặt tạo mới, sử dụng cài đặt sau: Chọn Author from scratch Name: dashboard-query Runtime: Python 3.12 Architecture: x86_64 Change default execution role: Use an existing role Chọn dashboard-query-role Nhấn Create Thêm mã nguồn (code):\nTrong code editor copy và paste đoạn mã bên dưới sau đó nhấn Deploy: import boto3 import time import os import json athena = boto3.client(\u0026#39;athena\u0026#39;) RESOURCE_MAP = { \u0026#39;/logs/cloudtrail\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;processed_cloudtrail\u0026#39; }, \u0026#39;/logs/guardduty\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;processed_guardduty\u0026#39; }, \u0026#39;/logs/vpc\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;vpc_logs\u0026#39; }, \u0026#39;/logs/eni_logs\u0026#39;:{ \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;eni_flow_logs\u0026#39; } } OUTPUT_BUCKET_NAME = os.environ.get(\u0026#34;ATHENA_OUTPUT_BUCKET\u0026#34;) REGION = os.environ.get(\u0026#34;REGION\u0026#34;) OUTPUT_BUCKET = f\u0026#39;s3://{OUTPUT_BUCKET_NAME}/\u0026#39; def lambda_handler(event, context): print(\u0026#34;Received event:\u0026#34;, json.dumps(event)) resource_path = event.get(\u0026#39;resource\u0026#39;) config = RESOURCE_MAP.get(resource_path) if not config: return api_response(400, {\u0026#39;error\u0026#39;: f\u0026#39;Unknown resource path: {resource_path}\u0026#39;}) database_name = config[\u0026#39;db\u0026#39;] table_name = config[\u0026#39;table\u0026#39;] query_params = event.get(\u0026#39;queryStringParameters\u0026#39;, {}) or {} if config[\u0026#39;table\u0026#39;] == \u0026#39;processed_cloudtrail\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by eventtime desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;processed_guardduty\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by date desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;vpc_logs\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by timestamp desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;eni_flow_logs\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by timestamp_str desc\u0026#34;\u0026#34;\u0026#34; print(f\u0026#34;Querying DB: {database_name}, Table: {table_name}, Output: {OUTPUT_BUCKET}\u0026#34;) try: response = athena.start_query_execution( QueryString=query_string, QueryExecutionContext={\u0026#39;Database\u0026#39;: database_name}, ResultConfiguration={\u0026#39;OutputLocation\u0026#39;: OUTPUT_BUCKET} ) query_execution_id = response[\u0026#39;QueryExecutionId\u0026#39;] status = \u0026#39;RUNNING\u0026#39; while status in [\u0026#39;RUNNING\u0026#39;, \u0026#39;QUEUED\u0026#39;]: response = athena.get_query_execution(QueryExecutionId=query_execution_id) status = response[\u0026#39;QueryExecution\u0026#39;][\u0026#39;Status\u0026#39;][\u0026#39;State\u0026#39;] if status in [\u0026#39;FAILED\u0026#39;, \u0026#39;CANCELLED\u0026#39;]: reason = response[\u0026#39;QueryExecution\u0026#39;][\u0026#39;Status\u0026#39;].get(\u0026#39;StateChangeReason\u0026#39;, \u0026#39;Unknown\u0026#39;) return api_response(500, {\u0026#39;error\u0026#39;: f\u0026#39;Query Failed: {reason}\u0026#39;}) time.sleep(1) results = athena.get_query_results(QueryExecutionId=query_execution_id) return api_response(200, results) except Exception as e: print(f\u0026#34;Error: {str(e)}\u0026#34;) return api_response(500, {\u0026#39;error\u0026#39;: str(e)}) def api_response(code, body): return { \u0026#34;statusCode\u0026#34;: code, \u0026#34;headers\u0026#34;: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Access-Control-Allow-Methods\u0026#34;: \u0026#34;GET, OPTIONS\u0026#34; }, \u0026#34;body\u0026#34;: json.dumps(body) } "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.10-cleanup/5.10.2-cdk-cleanup/","title":"Dọn dẹp CDK","tags":[],"description":"","content":"Clean up (CDK) Hướng dẫn này đảm bảo bạn hủy bỏ (decommission) chính xác tất cả các tài nguyên được cung cấp bởi AWS CDK stack và dọn dẹp dữ liệu được tạo thủ công để tránh các khoản phí phát sinh.\nGiai đoạn 1: Dọn dẹp dữ liệu thủ công (Trước khi CDK Destroy) CDK tự động xóa hầu hết các tài nguyên nhưng không xóa nội dung trong S3 buckets. Bạn phải làm trống nội dung của các buckets này trước khi chạy lệnh cdk destroy.\nTên Resource Mục đích Hành động yêu cầu incident-response-log-list-bucket Nguồn Log Chính Làm trống nội dung processed-cloudwatch-logs ETL Destination Làm trống nội dung processed-guardduty-findings ETL Destination Làm trống nội dung processed-cloudtrail-logs ETL Destination Làm trống nội dung athena-query-results Kết quả truy vấn Athena Làm trống nội dung aws-incident-response-automation-dashboard React Dashboard S3 Bucket Làm trống nội dung Hướng dẫn làm trống Buckets:\nMở Amazon S3 Console trong trình duyệt của bạn. Đối với mỗi buckets được liệt kê ở trên (tìm tên dựa trên AWS Account ID và Region của bạn): Nhấn vào tên bucket. Điều hướng đến tab \u0026ldquo;Objects\u0026rdquo;. Nhấn nút \u0026ldquo;Empty\u0026rdquo;. Làm theo các lời nhắc để xác nhận xóa vĩnh viễn tất cả các objects. Giai đoạn 2: CDK Stack Destruction Bước này sử dụng CDK CLI để phá hủy tất cả các tài nguyên được cung cấp bởi CloudFormation stack.\nĐảm bảo môi trường ảo (Virtual Environment) đang hoạt động\nNếu bạn đã tắt môi trường Python, hãy kích hoạt lại nó (ví dụ: source .venv/bin/activate). Điều hướng đến Project Root\nĐảm bảo bạn đang ở thư mục chính nơi chứa file cdk.json. Thực thi lệnh Destroy\nChạy lệnh để phá hủy tất cả các stacks đã triển khai. Khi được nhắc, gõ y để chấp nhận việc xóa. $ cdk destroy --all Giai đoạn 3: Dọn dẹp sau khi phá hủy Bước này giải quyết việc dọn dẹp thủ công các tài nguyên còn sót lại.\nXóa các S3 Buckets còn lại\nLệnh cdk destroy sẽ xóa các S3 buckets trống. Nếu còn sót lại bucket nào (do kiểm tra cuối cùng hoặc bảo vệ dịch vụ), hãy xóa chúng ngay bây giờ qua S3 Console. Vô hiệu hóa Amazon GuardDuty\nVào GuardDuty Console → Settings → General. Xác minh dịch vụ đã bị vô hiệu hóa để đảm bảo ngừng tính phí. Xóa Cognito User và Pool\nVào Cognito Console → User pools. Xóa test user bạn đã tạo. Xóa User Pool đã tạo cho dashboard. Xóa SES Identity\nVào Amazon SES Console → Verified Identities. Xóa sender email identity (sender_email) bạn đã xác minh. Hủy kích hoạt môi trường ảo\nHủy kích hoạt môi trường ảo Python: $ deactivate "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.2-prerequiste/","title":"Điều kiện tiên quyết","tags":[],"description":"","content":"Các yêu cầu về Truy cập và Thông tin Trước khi tiến hành thiết lập Hệ thống Phản hồi Sự cố và Điều tra số AWS Tự động (Automated AWS Incident Response and Forensics System), hãy đảm bảo bạn đã thu thập đủ các thông tin và quyền truy cập cần thiết dưới đây.\n🔑 Truy cập \u0026amp; Định danh Tài khoản AWS với Quyền Quản trị (Administrative Access) Bạn cần toàn quyền quản trị để tạo tài nguyên trên nhiều dịch vụ AWS. Truy cập vào AWS Management Console. AWS Account ID của bạn Định dạng: số có 12 chữ số (ví dụ: 123456789012). Placeholder: Thay thế ACCOUNT_ID trong toàn bộ hướng dẫn. AWS Region Mục tiêu Chọn region nơi bạn sẽ triển khai hệ thống (ví dụ: us-east-1). Placeholder: Thay thế REGION trong toàn bộ hướng dẫn. VPC ID Một VPC có ít nhất một subnet được yêu cầu cho VPC Flow Logs. Placeholder: Thay thế YOUR_VPC_ID trong hướng dẫn. Địa chỉ Email đã xác thực Amazon SES Cần thiết để gửi và nhận thông báo qua email. Xác thực địa chỉ này trong SES Console. Placeholder: Thay thế YOUR_VERIFIED_EMAIL@example.com. Slack Webhook URL (Tùy chọn) Nếu bạn muốn nhận thông báo qua Slack, hãy lấy webhook URL từ Slack workspace của bạn. Placeholder: Thay thế YOUR_SLACK_WEBHOOK_URL. "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.2-guardduty-etl/","title":"Mã GuardDuty ETL","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime from urllib.parse import unquote_plus s3_client = boto3.client(\u0026#39;s3\u0026#39;) DATABASE_NAME = os.environ.get(\u0026#34;DATABASE_NAME\u0026#34;, \u0026#34;security_logs\u0026#34;) TABLE_NAME_GUARDDUTY = os.environ.get(\u0026#34;TABLE_NAME_GUARDDUTY\u0026#34;, \u0026#34;processed_guardduty\u0026#34;) S3_LOCATION_GUARDDUTY = os.environ.get(\u0026#34;S3_LOCATION_GUARDDUTY\u0026#34;, \u0026#34;s3://vel-processed-guardduty/processed-guardduty/\u0026#34;) DESTINATION_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;, \u0026#34;vel-processed-guardduty\u0026#34;) def promote_network_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) net_conn_action = action.get(\u0026#39;networkConnectionAction\u0026#39;, {}) if net_conn_action: remote_ip = net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;) or \\ net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV6\u0026#39;) return { \u0026#39;remote_ip\u0026#39;: remote_ip, \u0026#39;remote_port\u0026#39;: net_conn_action.get(\u0026#39;remotePortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), \u0026#39;connection_direction\u0026#39;: net_conn_action.get(\u0026#39;connectionDirection\u0026#39;), \u0026#39;protocol\u0026#39;: net_conn_action.get(\u0026#39;protocol\u0026#39;), } dns_action = action.get(\u0026#39;dnsRequestAction\u0026#39;, {}) if dns_action: return {\u0026#39;dns_domain\u0026#39;: dns_action.get(\u0026#39;domain\u0026#39;), \u0026#39;dns_protocol\u0026#39;: dns_action.get(\u0026#39;protocol\u0026#39;)} port_probe_action = action.get(\u0026#39;portProbeAction\u0026#39;, {}) if port_probe_action and port_probe_action.get(\u0026#39;portProbeDetails\u0026#39;): detail = port_probe_action[\u0026#39;portProbeDetails\u0026#39;][0] return { \u0026#39;scanned_ip\u0026#39;: detail.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), \u0026#39;scanned_port\u0026#39;: detail.get(\u0026#39;localPortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), } return {} def promote_api_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) aws_api_action = action.get(\u0026#39;awsApiCallAction\u0026#39;, {}) if aws_api_action: return { \u0026#39;aws_api_service\u0026#39;: aws_api_action.get(\u0026#39;serviceName\u0026#39;), \u0026#39;aws_api_name\u0026#39;: aws_api_action.get(\u0026#39;api\u0026#39;), \u0026#39;aws_api_caller_type\u0026#39;: aws_api_action.get(\u0026#39;callerType\u0026#39;), \u0026#39;aws_api_error\u0026#39;: aws_api_action.get(\u0026#39;errorCode\u0026#39;), \u0026#39;aws_api_remote_ip\u0026#39;: aws_api_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), } return {} def promote_resource_details(finding_resource): if not finding_resource: return {} instance_details = finding_resource.get(\u0026#39;instanceDetails\u0026#39;, {}) if instance_details: return { \u0026#39;target_resource_arn\u0026#39;: instance_details.get(\u0026#39;arn\u0026#39;), \u0026#39;instance_id\u0026#39;: instance_details.get(\u0026#39;instanceId\u0026#39;), \u0026#39;resource_region\u0026#39;: instance_details.get(\u0026#39;awsRegion\u0026#39;), \u0026#39;instance_type\u0026#39;: instance_details.get(\u0026#39;instanceType\u0026#39;), \u0026#39;image_id\u0026#39;: instance_details.get(\u0026#39;imageId\u0026#39;), \u0026#39;instance_tags\u0026#39;: instance_details.get(\u0026#39;tags\u0026#39;) } access_key_details = finding_resource.get(\u0026#39;accessKeyDetails\u0026#39;, {}) if access_key_details: return { \u0026#39;access_key_id\u0026#39;: access_key_details.get(\u0026#39;accessKeyId\u0026#39;), \u0026#39;principal_id\u0026#39;: access_key_details.get(\u0026#39;principalId\u0026#39;), \u0026#39;user_name\u0026#39;: access_key_details.get(\u0026#39;userName\u0026#39;), } s3_details = finding_resource.get(\u0026#39;s3BucketDetails\u0026#39;, []) if s3_details: return { \u0026#39;target_resource_arn\u0026#39;: s3_details[0].get(\u0026#39;arn\u0026#39;), \u0026#39;s3_bucket_name\u0026#39;: s3_details[0].get(\u0026#39;name\u0026#39;), } return {} def process_guardduty_log(bucket, key): response = s3_client.get_object(Bucket=bucket, Key=key) if key.endswith(\u0026#39;.gz\u0026#39;): content = gzip.decompress(response[\u0026#39;Body\u0026#39;].read()).decode(\u0026#39;utf-8\u0026#39;) else: content = response[\u0026#39;Body\u0026#39;].read().decode(\u0026#39;utf-8\u0026#39;) processed_findings = [] for line in content.splitlines(): if not line: continue try: finding = json.loads(line) except json.JSONDecodeError: print(f\u0026#34;Skipping malformed JSON line in {key}\u0026#34;); continue finding_type = finding.get(\u0026#39;type\u0026#39;, \u0026#39;UNKNOWN\u0026#39;) finding_service = finding.get(\u0026#39;service\u0026#39;, {}) network_fields = promote_network_details(finding_service) api_fields = promote_api_details(finding_service) resource_fields = promote_resource_details(finding.get(\u0026#39;resource\u0026#39;, {})) created_at_str = finding.get(\u0026#39;createdAt\u0026#39;) event_last_seen_str = finding_service.get(\u0026#39;eventLastSeen\u0026#39;) dt_obj = datetime.now() if event_last_seen_str: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass elif created_at_str: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass processed_record = { \u0026#39;finding_id\u0026#39;: finding.get(\u0026#39;id\u0026#39;), \u0026#39;finding_type\u0026#39;: finding_type, \u0026#39;title\u0026#39;: finding.get(\u0026#39;title\u0026#39;), \u0026#39;severity\u0026#39;: finding.get(\u0026#39;severity\u0026#39;), \u0026#39;account_id\u0026#39;: finding.get(\u0026#39;accountId\u0026#39;), \u0026#39;region\u0026#39;: finding.get(\u0026#39;region\u0026#39;), \u0026#39;created_at\u0026#39;: created_at_str, \u0026#39;event_last_seen\u0026#39;: event_last_seen_str, **network_fields, **api_fields, **resource_fields, \u0026#39;date\u0026#39;: dt_obj.strftime(\u0026#39;%Y-%m-%d\u0026#39;), \u0026#39;service_raw\u0026#39;: json.dumps(finding_service), \u0026#39;resource_raw\u0026#39;: json.dumps(finding.get(\u0026#39;resource\u0026#39;, {})), \u0026#39;metadata_raw\u0026#39;: json.dumps(finding.get(\u0026#39;metadata\u0026#39;, {})), } processed_findings.append(processed_record) return processed_findings def save_processed_data(processed_events, source_key): if not processed_events: return first_event = processed_events[0] date_str = first_event.get(\u0026#39;date\u0026#39;, datetime.now().strftime(\u0026#39;%Y-%m-%d\u0026#39;)) original_filename = source_key.split(\u0026#39;/\u0026#39;)[-1].replace(\u0026#39;.gz\u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;.json\u0026#39;, \u0026#39;\u0026#39;) output_key = f\u0026#34;processed-guardduty/date={date_str}/{original_filename}_processed.jsonl.gz\u0026#34; json_lines = \u0026#34;\u0026#34; for event in processed_events: event_to_dump = event.copy() json_lines += json.dumps(event_to_dump) + \u0026#34;\\n\u0026#34; compressed_data = gzip.compress(json_lines.encode(\u0026#39;utf-8\u0026#39;)) s3_client.put_object( Bucket=DESTINATION_BUCKET, Key=output_key, Body=compressed_data, ContentType=\u0026#39;application/jsonl\u0026#39;, ContentEncoding=\u0026#39;gzip\u0026#39; ) print(f\u0026#34;Saved processed data to: s3://{DESTINATION_BUCKET}/{output_key}\u0026#34;) def lambda_handler(event, context): for record in event[\u0026#39;Records\u0026#39;]: bucket = record[\u0026#39;s3\u0026#39;][\u0026#39;bucket\u0026#39;][\u0026#39;name\u0026#39;] key = unquote_plus(record[\u0026#39;s3\u0026#39;][\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;]) print(f\u0026#34;Processing GuardDuty finding file: s3://{bucket}/{key}\u0026#34;) try: processed_findings = process_guardduty_log(bucket, key) save_processed_data(processed_findings, key) print(f\u0026#34;Successfully processed {len(processed_findings)} findings from {key}\u0026#34;) except Exception as e: print(f\u0026#34;Error processing {key}: {str(e)}\u0026#34;) raise e return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;GuardDuty findings processed successfully\u0026#39;) } "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.5-processing-setup/5.5.2-create-aws-glue-database-and-tables/","title":"Tạo AWS Glue Database và Tables","tags":[],"description":"","content":"Tạo AWS Glue Database và Tables Tạo Database Mở Glue Console → Databases → Add database\nDatabase name: security_logs\nCreate database\nTạo Tables (Sử dụng Athena DDL) Mở Athena Console\nĐặt vị trí lưu kết quả truy vấn (query result location): s3://athena-query-results-ACCOUNT_ID-REGION/\nChọn database: security_logs\nTạo bảng processed_cloudtrail Chạy DDL này trong Athena (thay thế ACCOUNT_ID và REGION):\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.processed_cloudtrail ( `eventtime` string, `eventname` string, `eventsource` string, `awsregion` string, `sourceipaddress` string, `useragent` string, `useridentity` struct\u0026lt; type:string, invokedby:string, principalid:string, arn:string, accountid:string, accesskeyid:string, username:string, sessioncontext:struct\u0026lt; attributes:map\u0026lt;string,string\u0026gt;, sessionissuer:struct\u0026lt; type:string, principalid:string, arn:string, accountid:string, username:string \u0026gt; \u0026gt;, inscopeof:struct\u0026lt; issuertype:string, credentialsissuedto:string \u0026gt; \u0026gt;, `requestparameters` string, `responseelements` string, `resources` array\u0026lt;struct\u0026lt;arn:string,type:string\u0026gt;\u0026gt;, `recipientaccountid` string, `serviceeventdetails` string, `errorcode` string, `errormessage` string, `hour` string, `usertype` string, `username` string, `isconsolelogin` boolean, `isfailedlogin` boolean, `isrootuser` boolean, `isassumedrole` boolean, `ishighriskevent` boolean, `isprivilegedaction` boolean, `isdataaccess` boolean, `target_bucket` string, `target_key` string, `target_username` string, `target_rolename` string, `target_policyname` string, `new_access_key` string, `new_instance_id` string, `target_group_id` string, `identity_principalid` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudtrail-logs-ACCOUNT_ID-REGION/processed-cloudtrail/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudtrail-logs-ACCOUNT_ID-REGION/processed-cloudtrail/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); Tạo bảng processed_guardduty Chạy DDL này trong Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.processed_guardduty ( `finding_id` string, `finding_type` string, `title` string, `severity` double, `account_id` string, `region` string, `created_at` string, `event_last_seen` string, `remote_ip` string, `remote_port` int, `connection_direction` string, `protocol` string, `dns_domain` string, `dns_protocol` string, `scanned_ip` string, `scanned_port` int, `aws_api_service` string, `aws_api_name` string, `aws_api_caller_type` string, `aws_api_error` string, `aws_api_remote_ip` string, `target_resource_arn` string, `instance_id` string, `instance_type` string, `image_id` string, `instance_tags` string, `resource_region` string, `access_key_id` string, `principal_id` string, `user_name` string, `s3_bucket_name` string, `service_raw` string, `resource_raw` string, `metadata_raw` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-guardduty-findings-ACCOUNT_ID-REGION/processed-guardduty/\u0026#39; TBLPROPERTIES ( \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39;, \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-guardduty-findings-ACCOUNT_ID-REGION/processed-guardduty/date=${date}/\u0026#39; ); Tạo bảng vpc_logs Chạy DDL này trong Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.vpc_logs ( `version` string, `account_id` string, `region` string, `vpc_id` string, `query_timestamp` string, `query_name` string, `query_type` string, `query_class` string, `rcode` string, `answers` string, `srcaddr` string, `srcport` int, `transport` string, `srcids_instance` string, `timestamp` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;ignore.malformed.json\u0026#39; = \u0026#39;true\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/vpc-logs/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/vpc-logs/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); Tạo bảng eni_flow_logs Chạy DDL này trong Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.eni_flow_logs ( `version` int, `account_id` string, `interface_id` string, `srcaddr` string, `dstaddr` string, `srcport` int, `dstport` int, `protocol` int, `packets` bigint, `bytes` bigint, `start_time` bigint, `end_time` bigint, `action` string, `log_status` string, `timestamp_str` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/eni-flow-logs/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/eni-flow-logs/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.2-create-service-roles/","title":"Tạo Service Roles","tags":[],"description":"","content":"Tạo Firehose Roles Tạo CloudTrailFirehoseRole Mở IAM Console → Roles → Create role\nChọn trusted entity:\nTrusted entity type: AWS service Use case: Chọn \u0026ldquo;Kinesis\u0026rdquo; → \u0026ldquo;Kinesis Firehose\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Thêm permissions:\nBỏ qua việc thêm managed policies (chúng ta sẽ thêm inline policy) Nhấn \u0026ldquo;Next\u0026rdquo; Đặt tên và tạo:\nRole name: CloudTrailFirehoseRole Description: Allows Firehose to write CloudTrail logs to S3 Nhấn \u0026ldquo;Create role\u0026rdquo; Thêm inline policy:\nPolicy name: FirehosePolicy Policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } Tạo CloudWatchFirehoseRole Role name: CloudWatchFirehoseRole Description: Allows Firehose to write CloudWatch logs to S3 Trusted entity: Kinesis Firehose Inline policy name: FirehosePolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } Tạo Step Functions Role Tạo StepFunctionsRole Tạo role:\nTrusted entity: Step Functions Role name: StepFunctionsRole Description: Execution role for Incident Response Step Functions Thêm HAI inline policies:\nPolicy 1: LambdaInvokePolicy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-isolate-ec2-lambda\u0026#34;, \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-parse-findings-lambda\u0026#34;, \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-quarantine-iam-lambda\u0026#34; ] } ] } Policy 2: EC2AutoScalingPolicy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;autoscaling:DescribeAutoScalingInstances\u0026#34;, \u0026#34;autoscaling:DetachInstances\u0026#34;, \u0026#34;autoscaling:UpdateAutoScalingGroup\u0026#34;, \u0026#34;ec2:CreateSnapshot\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:DescribeVolumes\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Tạo EventBridge Role Tạo IncidentResponseStepFunctionsEventRole Role name: IncidentResponseStepFunctionsEventRole Description: Allows EventBridge to trigger Step Functions Trusted entity: EventBridge Inline policy name: StartStepFunctionsPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;states:StartExecution\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:REGION:ACCOUNT_ID:stateMachine:IncidentResponseStepFunctions\u0026#34; } ] } Tạo VPC Flow Logs Role Tạo FlowLogsIAMRole Tạo role:\nTrusted entity: EC2 (will edit trust policy - sẽ chỉnh sửa trust policy sau) Role name: FlowLogsIAMRole Chỉnh sửa trust relationship thành:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;vpc-flow-logs.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] } Thêm inline policy: Policy name: FlowLogsPolicy Policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:DescribeLogStreams\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Tạo Glue Role Tạo GlueCloudWatchRole Role name: GlueCloudWatchRole Description: Allows Glue to access S3 and CloudWatch Logs Trusted entity: Glue Managed policies (đính kèm 3 policies): AWSGlueServiceRole CloudWatchLogsReadOnlyAccess AmazonS3FullAccess Không cần inline policies "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.2-set-up-s3-buckets-policies/","title":"Thiết lập S3 buckets policies","tags":[],"description":"","content":"Trong phần này, bạn sẽ cấu hình bucket policy cho bucket log chính để cho phép CloudTrail, GuardDuty, và CloudWatch Logs ghi log.\nCấu hình Bucket Policy Điều hướng đến bucket log chính: Trong S3 Console, nhấn vào incident-response-log-list-bucket-ACCOUNT_ID-REGION Mở tab Permissions:\nNhấn vào tab \u0026ldquo;Permissions\u0026rdquo; Cuộn đến Bucket policy:\nCuộn xuống phần \u0026ldquo;Bucket policy\u0026rdquo; Nhấn \u0026ldquo;Edit\u0026rdquo; Dán bucket policy: Copy JSON policy sau Quan trọng: Thay thế ACCOUNT_ID và REGION bằng giá trị thực tế của bạn trong policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowGuardDutyPutObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;guardduty.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:guardduty:REGION:ACCOUNT_ID:detector/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowGuardDutyGetBucketLocation\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;guardduty.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:guardduty:REGION:ACCOUNT_ID:detector/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudWatchLogsGetBucketAcl\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.REGION.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudWatchLogsPutObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.REGION.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudTrailAclCheck\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudtrail.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudtrail:REGION:ACCOUNT_ID:trail/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudTrailWrite\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudtrail.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/AWSLogs/ACCOUNT_ID/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34;, \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudtrail:REGION:ACCOUNT_ID:trail/*\u0026#34; } } } ] } Nhấn \u0026ldquo;Save changes\u0026rdquo;\nXác minh policy đã lưu: Bạn sẽ thấy policy hiển thị trong phần Bucket policy\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/4-eventparticipated/4.3-event3/","title":"Sự kiện 3","tags":[],"description":"","content":"Báo Cáo Tóm Tắt: “AWS Cloud Mastery Series #1 - AI/ML/GenAI trên AWS” Mục tiêu Sự kiện Giới thiệu về AI/ML/GenAI trên AWS Diễn giả Lam Tuan Kiet – Sr DevOps Engineer, FPT Software Danh Hoang Hieu Nghi - AI Engineer, Renova Cloud Dinh Le Hoang Anh - Cloud Engineer Trainee, First Cloud AI Journey Van Hoang Kha - Cloud Security Engineer, AWS Community Builder Điểm nhấn chính Khám phá Generative AI với Amazon Bedrock: - Foundation Models (Mô hình Nền tảng): Khác với Traditional Model (Mô hình Truyền thống) ở chỗ có thể được điều chỉnh cho nhiều tác vụ, cung cấp nhiều mô hình được quản lý hoàn toàn (fully managed model) từ các công ty AI hàng đầu như: OpenAI, Claude, Anthropic, v.v. - Prompt Engineering: Soạn thảo và Tinh chỉnh Lời nhắc (Instructions) + Zero-Shot Prompting: Một lời nhắc không có ngữ cảnh hoặc ví dụ trước + Few-shot Prompting: Một lời nhắc với một vài ngữ cảnh và ví dụ trước + Chain of Thought (Chuỗi Suy nghĩ): Một lời nhắc bao gồm các quá trình suy nghĩ và các bước trước khi đưa ra câu trả lời thực tế - Retrieval Augmented Generation (RAG): Truy xuất thông tin liên quan từ một nguồn dữ liệu + R: Retrieval (Truy xuất) - Lấy thông tin liên quan từ một kho kiến thức hoặc nguồn dữ liệu + A: Augmented (Tăng cường) - Thêm thông tin được truy xuất làm ngữ cảnh bổ sung vào lời nhắc của người dùng trước khi đưa vào mô hình + G: Generation (Tạo ra) - Phản hồi từ mô hình cho lời nhắc đã được tăng cường + Các trường hợp sử dụng: Cải thiện chất lượng nội dung, chatbot và trả lời câu hỏi theo ngữ cảnh, tìm kiếm được cá nhân hóa và tóm tắt dữ liệu thời gian thực\n- Amazon Titan Embedding: Mô hình nhẹ, nổi bật trong việc dịch văn bản thành biểu diễn số (embeddings) cho các tác vụ truy xuất độ chính xác cao, với sự hỗ trợ cho hơn 100 ngôn ngữ\n- Pretrained AI Services (Các Dịch vụ AI đã được đào tạo trước): + Amazon Rekognition: Phân tích Hình ảnh và Video + Amazon Translate: Phát hiện và dịch văn bản + Amazon Textract: Trích xuất Văn bản và Bố cục từ tài liệu + Amazon Transcribe: Chuyển lời nói thành văn bản (Speech-to-text) + Amazon Polly: Chuyển văn bản thành lời nói (Text-to-speech) + Amazon Comprehend: Trích xuất Thông tin chi tiết và Mối quan hệ từ văn bản + Amazon Kendra: Dịch vụ Tìm kiếm Thông minh + Amazon Lookout: Phát hiện Bất thường (Anomalies) trong các chỉ số kinh doanh, thiết bị và hình ảnh + Amazon Personalize: Điều chỉnh các đề xuất cho người dùng\n- Demo: AMZPhoto: Nhận diện khuôn mặt từ hình ảnh bằng AI\n- Amazon Bedrock AgentCore: Một nền tảng đại lý (agentic platform) toàn diện được thiết kế để giải quyết các thách thức trong việc đưa agents vào sản xuất: + Thực thi và mở rộng mã agent một cách an toàn. + Tích hợp bộ nhớ (memory) (ghi nhớ các tương tác trong quá khứ và học hỏi). + Triển khai kiểm soát danh tính và truy cập (identity and access controls) cho agents và các công cụ (tools). + Cung cấp việc sử dụng công cụ đại lý (agentic tool use) cho các quy trình làm việc phức tạp. + Khám phá và kết nối với các công cụ và tài nguyên tùy chỉnh. + Hiểu và kiểm toán mọi tương tác (observability). + Foundational Services (Dịch vụ Nền tảng): Các dịch vụ này được phân loại để chạy agents an toàn ở quy mô lớn.\n+ Enhance with tools \u0026amp; memory (Tăng cường với công cụ \u0026amp; bộ nhớ): Bao gồm Memory, Gateway, Browser tool và Code Interpreter.\n+ Deploy securely at scale (Triển khai an toàn ở quy mô lớn): Bao gồm Runtime và Identity.\n+ Gain operational insights (Thu thập thông tin chi tiết về vận hành): Bao gồm Observability.\n+ Enabling Agents at Scale (Architecture) (Kích hoạt Agents ở Quy mô lớn (Kiến trúc)): Kết nối với AgentCore Gateway (qua MCP), Memory, Identity, Observability, Browser và Code Interpreter.\n+ Frameworks for Building Agents (Các Framework để Xây dựng Agents): CrewAI, Google ADK, LangGraph/LangChain, LlamaIndex, OpenAI Agents SDK và Strands Agents SDK.\nĐiểm nổi bật Chính Bedrock là Trung tâm GenAI: Amazon Bedrock cung cấp các Foundation Models được quản lý hoàn toàn từ các công ty hàng đầu cho nhiều tác vụ khác nhau.\nTùy chỉnh thông qua Prompts và Dữ liệu: Nhiều cách khác nhau để tạo prompts (Zero-Shot, Few-shot, CoT) và sử dụng RAG để bổ sung thông tin cho các phản hồi tốt hơn của mô hình.\nEmbeddings thúc đẩy Tìm kiếm: Amazon Titan Embedding là một mô hình nhẹ quan trọng để dịch văn bản sang số, giúp đạt được độ chính xác cao trong các tác vụ truy xuất (như RAG).\nMô hình được Đào tạo trước: AWS cung cấp nhiều dịch vụ AI sẵn sàng sử dụng cho các nhu cầu chung, như Rekognition cho hình ảnh và Textract cho tài liệu.\nAgentCore Giải quyết các vấn đề Sản xuất: Amazon Bedrock AgentCore là nền tảng toàn diện mới xử lý các phần khó khăn trong việc vận hành AI Agents ở quy mô lớn (như Memory, Identity và Observability).\nÁp dụng vào Công việc Rất hữu ích trong các dự án sau này của nhóm chúng tôi, có thể bao gồm việc sử dụng nhiều hơn các AI Foundation Models trong kiến trúc của chúng tôi. Trải nghiệm Sự kiện Các diễn giả nói rất tốt và cung cấp nhiều thông tin Q\u0026amp;A: Thành viên nhóm đã hỏi một câu hỏi lạc đề nhưng rất quan trọng đối với dự án của chúng tôi + Hỏi: SNS trong kiến trúc của chúng tôi được sử dụng để xử lý Guard Duty Findings đã gặp phải tình huống hơn 1000+ cảnh báo xuất hiện cùng một lúc, làm thế nào để chúng tôi giải quyết việc này? + Đáp: Thêm SQS để xếp hàng các sự kiện và đảm bảo không có cảnh báo nào bị bỏ lỡ Lọt top 10 trong trò chơi Kahoot Quiz cuối sự kiện và có một bức ảnh với các diễn giả Tạo một nhóm không chính thức: \u0026ldquo;Mèo Cam Đeo Khăn\u0026rdquo;, sự hợp tác chung giữa nhóm của tôi \u0026ldquo;The Ballers\u0026rdquo; và \u0026ldquo;Vinhomies\u0026rdquo; Một số hình ảnh sự kiện Top 10 Kahoot Top 10 người chơi Ảnh nhóm Mèo Cam Đeo Khăn\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/1.3-week3/","title":"Nhật ký Công việc Tuần 3","tags":[],"description":"","content":"Mục tiêu Tuần 3: Hoàn thành Module 5 Hỗ trợ đồng đội với các lab trước đó Thực hiện lại các lab không khả dụng với các gói miễn phí (free tiers) Thực hiện 2 nghiên cứu bổ sung Thảo luận ý tưởng dự án Các nhiệm vụ được thực hiện trong tuần này: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Lab 25: Không thể thực hiện hiện tại, tài khoản đang ở free tier - Nâng cấp tài khoản lên gói trả phí - Thử lại lab 25: + Template được cung cấp sử dụng runtime nodejs12.x cho các hàm Lambda, không còn được hỗ trợ, đã sửa bằng cách thay đổi thành nodejs20.x + Tạo FSx file system + Endpoint S3 bucket để kiểm thử dữ liệu chỉ có thể truy cập ở region US, vì vậy phải thay đổi thành Read-S3Object -BucketName nasanex -KeyPrefix /AVHRR -Folder Z:/nasanex/AVHRR -Region us-west-2 + Tạo file shares + Tạo HDD và SSD FSx + 25.4: Phiên bản công cụ được cung cấp đã lỗi thời, đã tải xuống phiên bản mới nhất + Kiểm thử hiệu suất ổ đĩa thành công với nhiều tham số khác nhau + Giám sát hiệu suất bằng CloudWatch: Alarm được kích hoạt, throughput đạt tối đa 400MB + Học cách deduplicate files:\n• Lịch trình dedup mặc định là mỗi Thứ Bảy • Chạy dedup ban đầu không tối ưu hóa gì do fileAge mặc định -\u0026gt; đã thay đổi thành 0 =\u0026gt; Tối ưu hóa một nửa số tệp + Tạo shadow copies để backup + Học cách quản lý các tệp đang mở và cách đóng chúng từ kết nối + Tạo thành công user quotas để quản lý dung lượng lưu trữ + Bật chia sẻ tệp Continuously Available (CA) trên Amazon FSx để nhiều người dùng có thể sử dụng cùng lúc + Mở rộng throughput và storage trên AWS Console - Học mô hình trách nhiệm chia sẻ (shared responsibility model): Cả nhà cung cấp và khách hàng đều có trách nhiệm về bảo mật - Module 5-2: Best practice là tạo một admin IAM user thay vì sử dụng tài khoản root - IAM Principal: Truy cập tài nguyên trong AWS Account - IAM Policy: Identity based và Resource based - IAM Role: Một tập hợp các quy tắc kiểm soát quyền truy cập vào tài nguyên và dịch vụ cho IAM User - IAM Role có thể được sử dụng để bật cross account - Môn học ở trường: + ENW493c: Hoàn thành Understanding Research Methods 22/09/2025 22/09/2025 Lab25 Understanding Research Methods 3 - Module 5: - Amazon Cognito: Một dịch vụ quản lý xác thực, quyền và người dùng, với hai tính năng chính: + User pool: Một tập hợp các tài khoản người dùng và thông tin xác thực, cho phép các dịch vụ xác thực bên thứ ba + Identity pools: Một ánh xạ các quyền và thông tin xác thực có thể được áp dụng cho người dùng - AWS Organization: Quản lý nhiều AWS Accounts và tài nguyên + Tổ chức các tài khoản theo OU và sử dụng Service Control Policies để xác định quyền cho người dùng trong tổ chức AWS Identity Center (SSO): Quản lý Ủy quyền AWS và Ứng dụng: + Tận dụng các permission sets - AWS KMS: Tạo và quản lý các khóa mã hóa: + CMK (Customer Managed Key) là tài nguyên chính, được sử dụng để tạo, mã hóa và giải mã Data Key - AWS Security Hub: Quét và kiểm thử các chính sách và best practices dựa trên bảo mật - Tiếp tục với lab 14: + Tạo role và S3 Bucket + Phiên bản Ubuntu mới nhất (25.04) bao gồm phiên bản kernel không được hỗ trợ, yêu cầu cài đặt lại để tiếp tục + Cài đặt Ubuntu 24.04: Thất bại, kernel của nó vẫn không được hỗ trợ + Cài đặt Ubuntu 22.04 + Import VM vào AWS thành công + Kết nối thành công với EC2 instance được tạo từ AMI bằng tên người dùng và mật khẩu của VM 23/09/2025 23/09/2025 Lab 14 4 Tiếp tục với lab 14: + Tạo export bucket, cấu hình quyền + Export instances thành công sang định dạng .OVA để sử dụng - Lab 18: Bật Security Hub và cấu hình AWS Config để ghi lại dữ liệu để phân tích (Có thể mất một thời gian dài để điểm số được tính toán) 24/09/2025 24/09/2025 Lab 14 5 - Lab 22: + Tạo các hàm Lambda để chạy và dừng các EC2 instances dựa trên lịch trình và tags + Ghi nhật ký thông báo qua Slack - Lab 28:\n+ Tạo các IAM policies và role, chỉ cho phép truy cập từ Singapore Region (ap-southeast-1) + Hạn chế truy cập EC2 từ các regions bên ngoài chính sách + Hạn chế tạo các EC2 instances mà không có tags hợp lệ Lab 30: Hạn chế IAM user chỉ sử dụng region được chỉ định để truy cập EC2 - Lab 18 (Cập nhật): Security quét xong, đạt điểm bảo mật 85%, 1 lỗ hổng nghiêm trọng: IAM User có administrative access policy - Lab 33: + Tạo Key Management Service + Thiết lập CloudTrail để ghi nhật ký dữ liệu trong S3 Bucket + Tạo Athena để truy vấn logs + KMS từ chối truy cập thành công đối với người dùng không có ủy quyền 25/09/2025 25/09/2025 Lab 22 Lab 28 Lab 30 Lab 18 Lab 33 6 - Lab 44: Cấu hình điều kiện role, hạn chế truy cập bằng IP, thời gian và các yếu tố khác - Lab 48:\n+ Sử dụng IAM access key để tải tệp lên S3 qua EC2 Instance + Tải tệp lên S3 qua EC2 Instance mà không cần access key bằng cách sử dụng IAM Roles - Lab 12: + Tạo AWS Organization + Tạo các tài khoản và chuyển chúng vào các đơn vị (units) + Mời các tài khoản vào tổ chức + Chuyển đổi roles cho các tài khoản thuộc tổ chức + Thiết lập các policies cho các tài khoản thuộc tổ chức + Cài đặt Python để tiếp tục lab + Tạo và cấu hình người dùng và nhóm bằng Identity Store APIs qua AWS CLI Các lab từ AWS for Microsoft Workloads: + Quản lý người dùng và nhóm trên Microsoft AD qua AWS CLI + Học cách khắc phục sự cố các EC2 instances bằng cách tách các volumes của instance bị lỗi và gắn nó vào một instance đang chạy khác để cấu hình và khắc phục sự cố + Học cách gắn các licenses vào các EC2 instances với Microsoft AD, demo với LibreOffice 26/09/2025 26/09/2025 Lab 44 Lab 48 Lab 12 Microsoft Workloads Thành tựu Tuần 3: Nâng cấp tài khoản AWS thành công để hoàn thành các lab trước đây không khả dụng trên Free Tier và học cách điều chỉnh tài nguyên, chẳng hạn như sửa các phiên bản Lambda runtime lỗi thời.\nAdvanced Storage (FSx): Hoàn thành Lab 25, tạo và cấu hình Amazon FSx file system. Đạt được các kỹ năng thực tế trong việc quản lý data deduplication, tạo shadow copies để backup, đặt user quotas và mở rộng throughput đồng thời giám sát hiệu suất với CloudWatch.\nHoàn thành lý thuyết Module 5 và các lab bảo mật chuyên sâu:\n* Học các khái niệm về IAM, Roles, Policies, Cognito, Organizations, Identity Center (SSO), và KMS.\n* Triển khai các Region Restriction policies (Lab 28 \u0026amp; 30) cho việc tạo và truy cập EC2.\n* Cấu hình Role Conditions để hạn chế truy cập dựa trên IP và thời gian (Lab 44).\n* Thực hành bảo mật việc tải tệp lên S3 bằng cách sử dụng IAM Roles thay vì access keys (Lab 48).\nBật Security Hub và AWS Config (Lab 18), đạt điểm bảo mật 85% và xác định một lỗ hổng nghiêm trọng (IAM User administrative access).\nTạo các hàm Lambda để lên lịch bắt đầu và dừng các EC2 instances dựa trên tags (Lab 22) và ghi nhật ký thông báo qua Slack.\nGiải quyết thành công các vấn đề tương thích kernel bằng cách chọn phiên bản Ubuntu chính xác (22.04), import một VM vào AWS, tạo AMI, và export instance trở lại định dạng .OVA (Lab 14).\nThiết lập AWS Organization, tạo Organizational Units (OUs) và tài khoản, cấu hình Service Control Policies, và thực hành chuyển đổi roles cho các tài khoản (Lab 12).\nAWS for Microsoft Workloads: Hoàn thành các lab bổ sung tập trung vào:\n* Quản lý người dùng/nhóm trong Microsoft AD qua AWS CLI.\n* Khắc phục sự cố EC2 nâng cao bằng cách tách và gắn lại các volumes.\n* Gắn các licenses vào các EC2 instances bằng Microsoft AD (đã demo với Libre Office).\nThiết lập CloudTrail để ghi nhật ký dữ liệu vào S3 và sử dụng Amazon Athena để truy vấn các logs này cho phân tích kiểm tra và bảo mật (Lab 33). "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Blog AWS Cloud Operations Mô phỏng lỗi cục bộ với AWS Fault Injection Service bởi Ozgur Canibeyaz và Pablo Colazurdo vào ngày 30 THÁNG 6 2025 trong AWS Fault Injection Service (FIS), AWS Resilience Hub (ARH), AWS Systems Manager, Management Tools, Resilience, Technical How-to | Permalink | Chia sẻ\nCác hệ thống phân tán hiện đại phải có khả năng chống chịu lỗi trước các gián đoạn không mong muốn để duy trì tính khả dụng, hiệu suất và độ ổn định. Chaos engineering giúp các nhóm phát hiện những điểm yếu tiềm ẩn bằng cách thực hiện fault injection lên hệ thống và quan sát cách nó phục hồi. Trong khi thử nghiệm truyền thống xác thực hành vi mong đợi, chaos engineering kiểm tra khả năng phục hồi của hệ thống trong suốt thời gian xảy ra lỗi. AWS Fault Injection Service (AWS FIS) là một dịch vụ AWS được quản lý toàn diện giúp các nhóm chạy các thí nghiệm fault injection trên các workloads của AWS. Nó hỗ trợ các tình huống như chấm dứt Amazon EC2 instances, điều tiết các Amazon API Gateway requests, và tạo độ trễ mạng. Điều này cho phép bạn xác thực khả năng phục hồi trong các môi trường giống như môi trường sản xuất. Mặc dù những khả năng này rất mạnh mẽ, nhiều lỗi thực tế chỉ ảnh hưởng đến một phần lưu lượng truy cập.\nTrong bài đăng này, bạn sẽ tìm hiểu cách mô phỏng lỗi cục bộ. Một kiểu lỗi phổ biến nhưng ít được kiểm tra—bằng cách kết hợp AWS FIS với weighted routing trong Application Load Balancer (ALB) và một hàm AWS Lambda trả về các phản hồi lỗi tùy chỉnh. Phương pháp này cho phép bạn kiểm tra cách ứng dụng của bạn xử lý các điều kiện suy giảm mà không cần thay đổi mã hoặc làm gián đoạn luồng truy cập thông thường.\nTổng quan về giải pháp Giải pháp của chúng tôi kết hợp AWS FIS với định tuyến có trọng số của ALB để điều hướng một tỷ lệ phần trăm lưu lượng truy cập có thể định cấu hình đến một hàm Lambda có thể trả về các lỗi mô phỏng. Cách tiếp cận này không yêu cầu thay đổi mã nguồn ứng dụng và sẽ tự động khôi phục về hoạt động bình thường sau khi kiểm thử. Hình 1 Giải pháp này cho thấy cách sửa đổi Load Balancer của bạn một cách an toàn để mô phỏng lỗi trong quá trình thực hiện thử nghiệm và khôi phục an toàn sau khi kết thúc\nLợi ích chính Giải pháp này cung cấp các lợi ích chính sau cho các nhóm triển khai kỹ thuật hỗn loạn:\nMô phỏng lỗi có kiểm soát. Không cần sửa đổi ứng dụng. Thiết lập và khôi phục tự động. Tỷ lệ lỗi có thể định cấu hình. Hướng dẫn triển khai Điều kiện tiên quyết Trước khi bắt đầu, hãy xác minh bạn có:\nMột tài khoản AWS với quyền triển khai các stack AWS CloudFormation và quản lý các thí nghiệm AWS FIS. Một ALB hiện có được cấu hình với một target group định tuyến lưu lượng truy cập đến một microservice đang chạy. ALB phải đã hoạt động và có thể truy cập công khai để kiểm tra các lỗi mô phỏng. Truy cập vào AWS Command Line Interface(AWS CLI) hoặc AWS Management Console. Bước 1: Triển khai mẫu CloudFormation Mẫu CloudFormation thiết lập tất cả các tài nguyên cần thiết, bao gồm:\nMột hàm Lambda để mô phỏng các phản hồi lỗi. Một tài liệu AWS Systems Manager (SSM) automation. Một IAM Role cấp quyền cho AWS FIS để gọi tài liệu SSM Automation. Một AWS FIS experiment template được cấu hình sẵn. Hình 2 Cái nhìn cấp cao về các thành phần giải pháp và sự tương tác của chúng.\nCác tham số thí nghiệm có thể định cấu hình Mẫu CloudFormation yêu cầu ba tham số sau khi triển khai:\nTên Application Load Balancer. ARN của Listener ALB rule cần sửa đổi. Thời lượng kiểm tra bằng giây — lỗi cục bộ nên kéo dài bao lâu. Các cài đặt thí nghiệm khác, chẳng hạn như tỷ lệ phần trăm lưu lượng truy cập cần chuyển hướng và mã phản hồi Lambda, được cấu hình sẵn trong định nghĩa thí nghiệm. Nếu bạn muốn tùy chỉnh các giá trị này, bạn có hai tùy chọn:\nTùy chọn 1: Sửa đổi Mẫu CloudFormation và triển khai lại\nBạn có thể chỉnh sửa trường documentParameters trong phần định nghĩa thí nghiệm của mẫu để thay đổi:\nFailurePercentage (ví dụ: 10, 50, 100). Để thay đổi HTTP status code được hàm Lambda trả về (ví dụ: từ 500 thành 404), hãy sửa đổi giá trị statusCode trực tiếp trong khối mã nội tuyến bên trong mẫu.\nSau khi chỉnh sửa, hãy triển khai lại stack để áp dụng các thay đổi của bạn.\nTùy chọn 2: Tạo phiên bản mới của tài liệu SSM Automation\nNếu bạn không muốn triển khai lại stack:\nTruy cập vào AWS Systems Manager → Documents console. Định vị tài liệu SSM được tạo bởi mẫu. Chọn Create new version và điều chỉnh các giá trị mặc định như FailurePercentage. Sử dụng phiên bản đã cập nhật bằng cách tham chiếu nó trong một thí nghiệm AWS FIS mới (thông qua CLI hoặc console). IAM Permissions:\nBạn cần có quyền tạo các IAM role và policy khi triển khai CloudFormation template. Khi triển khai thông qua AWS Management Console, bạn sẽ cần xác nhận rằng template tạo ra các tài nguyên IAM. Nếu sử dụng AWS CLI, hãy thêm flag --capabilities CAPABILITY_NAMED_IAM.\nTải xuống template: Bạn có thể tải xuống CloudFormation template tại đây và lưu cục bộ dưới dạng fis_template.yaml trước khi triển khai nó thông qua AWS Console hoặc CLI.\naws cloudformation create-stack --stack-name alb-fis-experiment \\ --template-body file://fis_template.yaml \\ --parameters \\ ParameterKey=LoadBalancerName,ParameterValue=LoadBalancerName \\ ParameterKey=ListenerRuleArn,ParameterValue=RuleARN \\ ParameterKey=TestDurationInSeconds,ParameterValue=60 \\ --capabilities CAPABILITY_NAMED_IAM LoadBalancerName và RuleARN đề cập đến tên Load Balancer và ARN đầy đủ của Listener rule trước dịch vụ mà bạn muốn mô phỏng lỗi. 60 chỉ định thời lượng của lỗi mô phỏng bằng giây.\nLưu ý: FISExperimentRole IAM policy sử dụng \u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot; cho các hành động nhất định để cho phép AWS FIS sửa đổi các tài nguyên Load Balancer được tạo động. Bởi vì tên tài nguyên như ARN của target group không được biết tại thời điểm triển khai, nên việc giới hạn phạm vi các quyền này là không khả thi trong ngữ cảnh của bài đăng này. Mặc dù điều này mang lại sự linh hoạt, AWS security best practices khuyến nghị giới hạn phạm vi quyền đối với các tài nguyên cụ thể bất cứ khi nào có thể. Nếu bạn biết chính xác các tài nguyên sẽ được sử dụng, hãy cân nhắc cập nhật chính sách để hạn chế quyền truy cập cho phù hợp.\nBước 2: Xác minh Hàm Lambda Sau khi triển khai, hãy kiểm tra hàm Lambda trong AWS console để xác nhận nó trả về phản hồi lỗi mong đợi. Hàm phải trả về nội dung như sau:\n{ \u0026#34;statusCode\u0026#34;: 503, \u0026#34;body\u0026#34;: \u0026#34;Service Unavailable - Simulated Error Response\u0026#34; } Bước 3: Bắt đầu Thí nghiệm AWS FIS Mở AWS Fault Injection Service console. Định vị template được cấu hình sẵn trong Experiment Templates. Chọn Start experiment. Xác nhận và khởi chạy kiểm tra. Hình 3 AWS FIS console hiển thị experiment template tùy chỉnh được tạo bởi mẫu CloudFormation.\nKhi bạn bắt đầu thí nghiệm, AWS FIS sẽ gọi một AWS Systems Manager Automation Document được tạo trong quá trình triển khai. Automation này thực hiện các hành động sau:\nTạo một ALB target group mới trỏ đến một hàm Lambda được cấu hình để trả về các error responses mô phỏng. Sửa đổi một ALB Listener rule để chia một phần lưu lượng truy cập đến target group mới này, mô phỏng hiệu quả một lỗi cục bộ. Đợi trong một khoảng thời gian xác định (có thể định cấu hình thông qua CloudFormation template). Khôi phục ALB listener rule về trạng thái ban đầu và xóa target group tạm thời. Toàn bộ vòng đời này được tự động hóa — bạn không cần viết bất kỳ mã nào hoặc thực hiện cập nhật thủ công nào cho Load Balancer của mình. Tất cả những gì bạn làm là bắt đầu thí nghiệm từ FIS console và quan sát cách dịch vụ của bạn phản hồi với một trường hợp lỗi cục bộ được kiểm soát.\nTrong ảnh chụp màn hình sau, bạn sẽ thấy quy tắc Listener ALB ban đầu chỉ được cấu hình với target group mặc định.\nHình 4 ALB listener rule trước khi thí nghiệm bắt đầu, hiển thị một target group duy nhất nhận 100% lưu lượng truy cập.\nSau khi thí nghiệm bắt đầu, AWS FIS sửa đổi rule để chia lưu lượng truy cập — như được hiển thị trong ảnh chụp màn hình Sau.\nHình 5 ALB listener rule sau khi thí nghiệm bắt đầu, hiển thị một target group mới với Lambda được cấu hình để nhận 50% lưu lượng truy cập và phản hồi bằng một mã lỗi được xác định trước.\nBước 4: Quan sát và phân tích kết quả Bạn có thể xác thực thí nghiệm bằng cách làm mới ALB DNS trong trình duyệt của bạn hoặc chạy một curl loop:\nwhile true; do curl -s http://\u0026lt;your-alb-dns-name\u0026gt;; sleep 1; done Hình 6 Đầu ra CLI động hiển thị các yêu cầu lặp lại đến URL ALB trong một vòng lặp để chứng minh cách giải pháp tiêm lỗi.\nBạn sẽ thấy đầu ra xen kẽ như:\nBackend service is healthy (dịch vụ backend đang hoạt động tốt) Service Unavailable – Simulated Error Response (Lambda) Bạn có thể giám sát Amazon CloudWatch Logs để xem các chỉ số thực thi hàm Lambda và hành vi của ứng dụng (logic thử lại, cơ chế chuyển đổi dự phòng)\nLưu ý: Sau khi bắt đầu thí nghiệm, có thể mất đến một phút trước khi target group mới được gắn vào ALB và lưu lượng truy cập bắt đầu định tuyến đến hàm Lambda. Trong khoảng thời gian ngắn này, tất cả các yêu cầu có thể tiếp tục đến dịch vụ backend ban đầu.\nCơ chế khôi phục Thí nghiệm nhằm mục đích giúp ích cho các hoạt động khôi phục, mặc dù nên kiểm tra trong môi trường của bạn:\nALB rule sẽ tự động được khôi phục vào cuối thời gian kiểm tra. Target group tạm thời được gỡ bỏ và xóa để ngăn chặn bất kỳ cấu hình còn sót lại nào. Nếu thí nghiệm bị hủy, quy trình khôi phục sẽ đưa hệ thống trở lại trạng thái ban đầu. Các điểm cần cân nhắc Bài đăng này cung cấp thông tin kỹ thuật và cấu hình ví dụ. Việc triển khai trong môi trường của bạn có thể yêu cầu thêm các cân nhắc về bảo mật, tuân thủ và kỹ thuật. Luôn kiểm tra kỹ lưỡng trước trong các môi trường phi sản xuất.\nDọn dẹp Để tránh phát sinh chi phí trong tương lai, hãy xóa các tài nguyên đã triển khai:\naws cloudformation delete-stack --stack-name alb-fis-experiment Kết luận Trong bài đăng này, chúng tôi đã chứng minh cách mở rộng khả năng của AWS FIS bằng cách mô phỏng lỗi cục bộ cho các workload đằng sau ALB bằng cách sử dụng Lambda. Giải pháp này cho phép các nhóm kiểm tra khả năng phục hồi của ứng dụng đối với các lỗi không liên tục mà không gây ra sự cố ngừng hoạt động hoàn toàn. Bằng cách tận dụng AWS FIS, Lambda, và các ALB routing rules, bạn có thể tạo ra các kịch bản lỗi có kiểm soát và tăng cường độ vững chắc của hệ thống.\nĐể tìm hiểu thêm, hãy khám phá các tài nguyên sau:\nTài liệu AWS Fault Injection Service Tài liệu Amazon ALB Sử dụng SSM Systems Manager document với AWS FIS Bắt đầu với CloudFormation template và chia sẻ kinh nghiệm của bạn trong phần bình luận bên dưới.\nTAGS: aws fault injection simulator, chaos engineering\nOzgur Canibeyaz Ozgur là Senior Technical Account Manager tại Amazon Web Services với 8 năm kinh nghiệm. Ozgur giúp khách hàng tối ưu hóa việc sử dụng AWS của họ bằng cách xử lý các thách thức kỹ thuật, khám phá các cơ hội tiết kiệm chi phí, đạt được sự xuất sắc trong vận hành và xây dựng các dịch vụ sáng tạo bằng các sản phẩm AWS.\nPablo Colazurdo Pablo là Principal Solutions Architect tại AWS, nơi anh ấy thích giúp khách hàng ra mắt các dự án thành công trên Cloud. Anh ấy có nhiều năm kinh nghiệm làm việc với nhiều công nghệ đa dạng và đam mê học hỏi những điều mới. Pablo lớn lên ở Argentina nhưng hiện đang tận hưởng cơn mưa ở Ireland trong khi nghe nhạc, đọc sách hoặc chơi D\u0026amp;D với các con.\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.3-setup-api-gateway/","title":"Cài đặt API Gateway","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một API Gateway để định tuyến cuộc gọi api từ dashboard tới Lambda.\nTạo API Gateway Mở API Gateway Console\nĐiều hướng tới https://console.aws.amazon.com/apigateway/ Hoặc: AWS Management Console → Services → API Gateway Tạo API:\nNhấn Create API Chọn REST API và nhấn Build Sử dụng cài đặt này để tạo: Chọn New API Name: dashboard-api API endpoint type: Regional Security policy: SecurityPolicy_TLS13_1_3_2025_09 Endpoint access mode: Basic IP address type: IPv4 Tạo Resources:\nBật CORS cho root resource Nhấn Create resource và đặt tên là logs Sau đó nhấn vào tài nguyên /logs vừa tạo và nhấn Create Resource để tạo tài nguyên con của /logs Đặt tên là cloudtrail và bật CORS Lặp lại ba lần nữa cho eni_logs, guardduty và vpc Tạo methods:\nNhấn vào /cloudtrail vừa tạo và nhấn Create method\nTrong phần tạo method, sử dụng cài đặt này:\nMethod type: GET Intergration type: Lambda function Bật Lambda proxy intergration chọn Buffered Lambda function: chọn region của bạn, tìm kiếm dashboard-query và chọn nó Timout: 29000 Lặp lại ba lần nữa cho eni_logs, guardduty và vpc\nTriển khai API (Deploy API):\nNhấn Deploy API ở góc phải Trong phần deploy API, sử dụng cài đặt này: Stage: New stage Name: prod Nhấn Deploy "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.3-cloudwatch-etl/","title":"Mã CloudWatch ETL","tags":[],"description":"","content":"import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CẤU HÌNH (CONFIG) # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Trích xuất VPC ID từ đường dẫn file (Extract VPC ID from file path) vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Đọc và xử lý nội dung file (Read and process file content) content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Tạo flattened JSON record (Create flattened JSON record) out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Thêm dòng mới cho định dạng JSONL (Add newline for JSONL format) json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Gửi đến Firehose theo batch 500 (Send to Firehose in batches of 500) if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.3-create-iam-policy/","title":"Tạo IAM Policy","tags":[],"description":"","content":"Tạo IAM Quarantine Policy Tạo IrQuarantineIAMPolicy Điều hướng đến IAM Console → Policies → Create policy\nPolicy JSON:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Policy name: IrQuarantineIAMPolicy Description: Deny-all policy for quarantining compromised IAM users "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/","title":"Tạo IAM Roles và Policies","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo 17 IAM roles cùng với các policies liên quan cho Lambda functions, Firehose streams, Step Functions, và các dịch vụ khác.\nTổng quan về IAM Roles Lambda Execution Roles (9 roles):\nCloudTrailETLLambdaServiceRole GuardDutyETLLambdaServiceRole CloudWatchETLLambdaServiceRole CloudWatchENIETLLambdaServiceRole CloudWatchExportLambdaServiceRole ParseFindingsLambdaServiceRole IsolateEC2LambdaServiceRole QuarantineIAMLambdaServiceRole AlertDispatchLambdaServiceRole Service Roles (6 roles): 10. CloudTrailFirehoseRole 11. CloudWatchFirehoseRole 12. StepFunctionsRole 13. IncidentResponseStepFunctionsEventRole 14. FlowLogsIAMRole 15. GlueCloudWatchRole\nIAM Policy (1 policy): 16. IrQuarantineIAMPolicy\nNội dung Tạo Lambda Execution Roles Tạo Service Roles Tạo IAM Policy "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.5-processing-setup/5.5.3-create-lambda-function-etl-processing/","title":"Tạo Lambda Function - Xử lý ETL","tags":[],"description":"","content":"Tạo Lambda Functions - Xử lý ETL Trong phần này, bạn sẽ tạo 5 Lambda functions để xử lý logs và gửi chúng đến Kinesis Firehose hoặc S3.\nincident-response-cloudtrail-etl Runtime: Python 3.12 Handler: CloudTrailETL.lambda_handler Role: CloudTrailETLLambdaServiceRole Timeout: 300s, Memory: 128MB Env: FIREHOSE_STREAM_NAME=cloudtrail-firehose-stream Code: cloudtrail-etl incident-response-guardduty-etl Runtime: Python 3.12 Handler: guardduty_etl.lambda_handler Role: GuardDutyETLLambdaServiceRole Timeout: 300s, Memory: 128MB Env: DESTINATION_BUCKET, S3_LOCATION_GUARDDUTY, DATABASE_NAME, TABLE_NAME_GUARDDUTY Code: guardduty-etl cloudwatch-etl-lambda Runtime: Python 3.12 Handler: cloudwatch_etl.lambda_handler Role: CloudWatchETLLambdaServiceRole Env: FIREHOSE_STREAM_NAME=vpc-dns-firehose-stream Code: cloudwatch-etl cloudwatch-eni-etl-lambda Runtime: Python 3.12 Handler: cloudwatch_eni_etl.lambda_handler Role: CloudWatchENIETLLambdaServiceRole Env: FIREHOSE_STREAM_NAME=vpc-flow-firehose-stream Code: cloudwatch-eni-etl cloudwatch-export-lambda Runtime: Python 3.12 Handler: cloudwatch_autoexport.lambda_handler Role: CloudWatchExportLambdaServiceRole Env: DESTINATION_BUCKET=incident-response-log-list-bucket-ACCOUNT_ID-REGION Code: cloudwatch-autoexport Cấu hình CloudWatch Logs Subscription Filter Cấu hình Subscription Filter Mở CloudWatch Console.\nỞ ngăn điều hướng bên trái, chọn Log Management.\nNhấn vào centralized log group: /aws/incident-response/centralized-logs.\nTạo Subscription Filter:\nNhấn vào tab \u0026ldquo;Subscription filters\u0026rdquo;. Nhấn \u0026ldquo;Create Lambda subscription filter\u0026rdquo;. Cấu hình Destination:\nDestination Lambda function: Chọn function cloudwatch-export-lambda. Log format: Chọn \u0026ldquo;Other\u0026rdquo;. (Điều này đảm bảo dữ liệu log thô được chuyển đi hiệu quả để Lambda xử lý). Cấu hình Log Format và Filter:\nSubscription filter name: Nhập tên mô tả, ví dụ, VPC-Log-Export-Filter. Filter pattern: Để trống trường này blank. (Đảm bảo tất cả logs trong group đều được xử lý). Nhấn \u0026ldquo;Start streaming\u0026rdquo;.\nCấu hình S3 Event Notifications S3 Console → incident-response-log-list-bucket-ACCOUNT_ID-REGION → Properties → Event notifications\nTạo 4 notifications với Event types/Object creation/✅All object create events:\nCloudTrailETLTrigger: Prefix AWSLogs/ACCOUNT_ID/CloudTrail/ → Lambda incident-response-cloudtrail-etl VPCDNSLogsTrigger: Prefix exportedlogs/vpc-dns-logs/ → Lambda cloudwatch-etl-lambda VPCFlowLogsTrigger: Prefix exportedlogs/vpc-flow-logs/ → Lambda cloudwatch-eni-etl-lambda GuardDutyFindingsTrigger: Prefix AWSLogs/ACCOUNT_ID/GuardDuty/ → Lambda incident-response-guardduty-etl "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/","title":"Thiết lập nền tảng","tags":[],"description":"","content":"Giai đoạn Thiết lập nền tảng ban đầu này xây dựng các điều kiện tiên quyết cốt lõi cho Hệ thống Phản hồi Sự cố Tự động, tập trung vào việc triển khai lưu trữ chuyên dụng và ủy quyền bảo mật thiết yếu. Điều này bắt buộc phải tạo năm Amazon S3 buckets an toàn để thu thập và xử lý log tập trung, áp dụng Bucket Policy cần thiết để phân phối log an toàn, và định nghĩa 17 IAM roles cùng chính sách cách ly (quarantine policy) để thực thi quyền truy cập đặc quyền tối thiểu (least-privilege access) trên tất cả các dịch vụ AWS được tích hợp.\nNội dung Thiết lập Amazon S3 Bucket Cấu hình S3 Bucket Policy cho Primary Log Bucket Tạo IAM Roles và Policies "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":" Blog 1 - Achieve Excellence in Aftermarket Service with Syncron and AWS Bài blog này giải thích cách các nhà sản xuất có thể nâng cao dịch vụ hậu mãi (aftermarket services) của họ bằng cách triển khai nền tảng Syncron Service Lifecycle Management (SLM) trên AWS. Bạn sẽ tìm hiểu lý do tại sao các hoạt động truyền thống, bị cô lập thường dẫn đến kém hiệu quả và tăng chi phí, và cách nền tảng SLM của Syncron tạo ra một hệ sinh thái kinh doanh kết nối bằng cách hợp nhất dữ liệu từ quản lý phụ tùng, dịch vụ và bảo hành. Bài viết cũng khám phá kiến trúc của giải pháp, vốn tận dụng các dịch vụ như Amazon S3 và AWS Glue, và trình bày các trường hợp sử dụng của khách hàng như việc truy cập dữ liệu tức thì và xây dựng các mô hình AI/ML tùy chỉnh để tối ưu hóa giá.\nBlog 2 - Amazon Q Developer CLI supports image inputs in your terminal Bài blog này giới thiệu khả năng mới mạnh mẽ của Amazon Q Developer CLI trong việc chấp nhận và phân tích đầu vào hình ảnh trực tiếp trong terminal của bạn. Bạn sẽ tìm hiểu cách tính năng này thu hẹp khoảng cách giữa tài sản thiết kế trực quan và mã chức năng, hợp lý hóa quá trình phát triển bằng cách giảm công việc thủ công, dễ xảy ra lỗi là dịch các sơ đồ thành triển khai. Bài viết cũng cung cấp hướng dẫn thực hành với một số trường hợp sử dụng thực tế, minh họa cách tạo mã Terraform từ sơ đồ kiến trúc, tạo SQL schema từ sơ đồ ER, chuyển đổi bản phác thảo vẽ tay thành tài liệu thiết kế chính thức và xây dựng mã UI từ một ảnh chụp màn hình đơn giản.\nBlog 3 - Simulating partial failures with AWS Fault Injection Service Bài blog này đi sâu vào một kỹ thuật chaos engineering nâng cao để mô phỏng các lỗi hệ thống cục bộ hoặc một phần (partial, or localized, system failures) bằng cách sử dụng AWS Fault Injection Service (FIS). Bạn sẽ tìm hiểu lý do tại sao việc kiểm thử các lỗi không hoàn toàn này lại rất quan trọng để xây dựng các ứng dụng thực sự có khả năng phục hồi (resilient applications) và cách các phương pháp fault injection truyền thống thường bỏ qua kịch bản quan trọng này. Bài viết cũng cung cấp một hướng dẫn chi tiết, từng bước về giải pháp, hướng dẫn bạn cách kết hợp FIS với Application Load Balancer (ALB) và một hàm AWS Lambda để chèn các lỗi được kiểm soát chỉ ảnh hưởng đến một tỷ lệ phần trăm lưu lượng truy cập, tất cả mà không yêu cầu bất kỳ thay đổi nào đối với mã ứng dụng của bạn.\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/4-eventparticipated/4.4-event4/","title":"Sự kiện 4","tags":[],"description":"","content":"Báo Cáo Tóm Tắt: “AWS Cloud Mastery Series #2 - DevOps on AWS” Mục tiêu Sự kiện Giới thiệu các Dịch vụ DevOps của AWS – CI/CD Pipeline Giới thiệu Infrastructure as Code (IaC) và các công cụ liên quan Giới thiệu các Dịch vụ Container trên AWS Đảm bảo khả năng Giám sát và Khả năng Quan sát (Monitoring and Observability) bằng cách sử dụng các Dịch vụ AWS Diễn giả Truong Quang Tinh – AWS Community Builder, Platform Engineer - TymeX Bao Huynh – AWS Community Builder Nguyen Khanh Phuc Thinh – AWS Community Builder Tran Dai Vi – AWS Community Builder Huynh Hoang Long – AWS Community Builder Pham Hoang Quy – AWS Community Builder Nghiem Le – AWS Community Builder Dinh Le Hoang Anh - Cloud Engineer Trainee, First Cloud AI Journey Điểm nhấn chính Tư duy DevOps (DevOps Mindset) - Văn hóa (Culture): Cộng tác, Tự động hóa, Học hỏi và Đo lường Liên tục (Collaboration, Automation, Continuous Learning and Measurement) - Các Vai trò DevOps: DevOps Engineer, Cloud Engineer, Platform Engineer, Site Reliability Engineer - Các Chỉ số Thành công (Success Metrics): + Đảm bảo tình trạng triển khai (deployment health) + Cải thiện tính linh hoạt (agility) + Độ ổn định hệ thống (System stability) + Tối ưu hóa Trải nghiệm Khách hàng (Optimize customer Experience) + Chứng minh giá trị các khoản đầu tư công nghệ (Justify technology investments)\nNÊN LÀM (DO) KHÔNG NÊN LÀM (DON\u0026rsquo;T) Bắt đầu với các Khái niệm Cơ bản (Fundamentals) Mắc kẹt trong Vòng lặp Tutorial (Tutorial Hell) Học bằng cách Xây dựng các Dự án Thực tế Sao chép-dán một cách mù quáng (Copy-paste blindly) Tài liệu hóa Mọi thứ (Document Everything) So sánh Tiến độ của Bản thân với Người khác Thành thạo từng thứ một Bỏ cuộc Sau khi Thất bại Tăng cường Kỹ năng Mềm (Soft Skills Enhancement) - Tích hợp Liên tục (Continuous Integration): Các thành viên trong nhóm tích hợp công việc của họ thường xuyên, nhằm mục đích Cung cấp Liên tục (Continuous Delivery) và Triển khai Liên tục (Deployment)\nCơ sở hạ tầng dưới dạng Mã (Infrastructure as Code - IaC) - Lợi ích: Tự động hóa, Khả năng Mở rộng, Khả năng Tái tạo (Reproducibility) và Cộng tác tốt hơn\nAWS CloudFormation Công cụ IaC tích hợp sẵn của AWS, sử dụng các template được viết bằng YAML hoặc JSON, có thể xây dựng mọi Cơ sở hạ tầng AWS một cách tự động\n- Stack: Một tập hợp các Tài nguyên AWS được định nghĩa trong một template, có thể được CloudFormation sử dụng để tạo, cập nhật hoặc xóa các tài nguyên đó\n- CloudFormation Template: Một tệp YAML/JSON định nghĩa Cơ sở hạ tầng AWS, hoạt động như một bản thiết kế (blueprint) để triển khai và cấu hình tài nguyên\n- Cách thức hoạt động: Tạo template -\u0026gt; Lưu trữ trong S3 Bucket hoặc bộ nhớ cục bộ -\u0026gt; Sử dụng CloudFormation để tạo Stacks dựa trên template -\u0026gt; CloudFormation xây dựng tài nguyên\n- Drift Detection (Phát hiện Lệch): Phát hiện các thay đổi trong cơ sở hạ tầng so với Stack =\u0026gt; Cập nhật Stack hoặc hoàn nguyên thay đổi, hữu ích cho việc quản lý phiên bản (versioning)\nAWS Cloud Development Kit (CDK) Khung phát triển phần mềm mã nguồn mở, hỗ trợ IaC bằng cách sử dụng các ngôn ngữ lập trình thực tế (Python, Java, C#.Net, Type/JavaScript và Go)\n- Construct: Các khối xây dựng, bao gồm các thành phần đại diện cho Tài nguyên AWS và Cấu hình của chúng, có 3 cấp độ construct: + L1 Construct: Tài nguyên cấp thấp ánh xạ trực tiếp tới một tài nguyên AWS CloudFormation duy nhất + L2 Construct: Cung cấp mức độ trừu tượng cao hơn thông qua API dựa trên ý định trực quan (intuitive intent-based API), đóng gói các phương pháp hay nhất và các mặc định bảo mật + L3 Construct: Các mẫu kiến trúc hoàn chỉnh với nhiều tài nguyên, triển khai có ý kiến chuyên môn (opinionated implementation) và triển khai nhanh chóng\nAWS Amplify Nền tảng AWS giúp dễ dàng xây dựng, triển khai và mở rộng các ứng dụng web và di động, sử dụng CloudFormation bên dưới: Các Stacks được triển khai để xây dựng cơ sở hạ tầng theo chương trình (programmatically)\nTerraform Công cụ IaC, bắt đầu bằng việc định nghĩa cơ sở hạ tầng bằng mã Terraform và lập kế hoạch sau đó áp dụng cơ sở hạ tầng trên nhiều nền tảng cloud như Azure, AWS, Google Cloud, v.v.\n- Điểm mạnh: Hỗ trợ Đa đám mây (Multi-Cloud), Theo dõi Trạng thái (State tracking) với cùng một cấu hình\nCách chọn Công cụ IaC? - Tiêu chí: + Lập kế hoạch sử dụng một Cloud hay nhiều Cloud? + Vai trò là Developer hay Ops? + Cloud và Hệ sinh thái có hỗ trợ công cụ đó không?\nDịch vụ Container trên AWS Dockerfile Một Dockerfile định nghĩa cách xây dựng một container image, mô tả môi trường, các phụ thuộc, các bước xây dựng và cấu hình thời gian chạy cuối cùng, đảm bảo rằng ứng dụng chạy nhất quán trên bất kỳ hệ thống nào hỗ trợ Dockers\n- Images: Một bản thiết kế đóng gói của một ứng dụng, được xây dựng từ một Dockerfile bằng cách sử dụng hệ thống tệp phân lớp (layered file system), được sử dụng để tạo các container nhất quán giữa các môi trường\n- Quy trình làm việc: Dockerfile xây dựng Docker Image, sau đó có thể được sử dụng để chạy Container và đẩy lên ECR/Docker Hub\nAmazon ECR Một container registry được quản lý hoàn toàn, giúp dễ dàng lưu trữ, quản lý và chia sẻ hình ảnh Docker container một cách an toàn. Container registry riêng tư, an toàn và có khả năng mở rộng của AWS\n- Tính năng: + Quét hình ảnh (Image Scanning) + Thẻ Bất biến (Immutable Tags) + Chính sách Vòng đời (Lifecycle Policies) + Mã hóa \u0026amp; IAM\n- Điều phối (Orchestration): Điều phối nhiều quy trình container: khởi động lại container, tự động mở rộng quy mô khi tải cao, phân phối lưu lượng truy cập hiệu quả, quản lý nơi đặt và chạy container\nKubernetes Mã nguồn mở, tự động hóa việc triển khai, mở rộng quy mô, tự phục hồi (healing) và cân bằng tải (load balancing) - Các thành phần: + Master Node: Control Plane, quản lý worker nodes và pods + Worker Node: Chạy khối lượng công việc ứng dụng bên trong pods + Pod: Đơn vị triển khai nhỏ nhất, có thể chứa một hoặc nhiều container + Service\nECS so với EKS\nTính năng Amazon ECS (Elastic Container Service) Amazon EKS (Elastic Kubernetes Service) Công nghệ Cốt lõi Điều phối container gốc AWS (AWS-native container orchestration) Dựa trên Kubernetes (tiêu chuẩn mã nguồn mở) Độ phức tạp Đơn giản hơn, dễ vận hành hơn Rất linh hoạt nhưng phức tạp hơn Kiến thức Yêu cầu Không cần kiến thức về Kubernetes Yêu cầu kiến thức về Kubernetes (pods, deployments, v.v.) Tích hợp AWS Tích hợp sâu với AWS (ALB, IAM, CloudWatch, v.v.) Tích hợp Kubernetes tiêu chuẩn Trường hợp Sử dụng/Lợi ích Tuyệt vời cho triển khai nhanh \u0026amp; chi phí vận hành thấp hơn Tính di động đa cluster, đa đám mây Hệ sinh thái/Cộng đồng Cộng đồng và công cụ gốc AWS Hệ sinh thái \u0026amp; công cụ cộng đồng lớn hơn Tóm tắt ECS = dễ hơn, chạy nhanh hơn, chi phí vận hành thấp hơn EKS = linh hoạt hơn, kiểm soát nhiều hơn, phức tạp hơn App Runner Thích hợp cho việc triển khai nhanh các ứng dụng web và REST API, lý tưởng cho khối lượng công việc sản xuất từ nhỏ đến trung bình\nGiám sát \u0026amp; Khả năng Quan sát (Monitoring \u0026amp; Observability) CloudWatch Giám sát Tài nguyên AWS và Ứng dụng chạy trên AWS theo thời gian thực Cung cấp khả năng quan sát Báo động (Alarms) và phản hồi tự động Dashboard giúp tối ưu hóa vận hành và chi phí - CloudWatch metrics: Dữ liệu về hiệu suất của hệ thống trên AWS hoặc tại chỗ với CloudWatch Agent, tích hợp tốt với EventBridge, Auto Scaling và quy trình làm việc DevOps\nAWS X-Ray - Truy vết Phân tán (Distributed Tracing): Theo dõi các yêu cầu từ đầu đến cuối, và vẽ bản đồ cùng đường dẫn giữa các dịch vụ đã truy cập, thêm SDK vào mã để truy vết IDs\n- Thông tin chi tiết về Hiệu suất (Performance Insight): Phân tích nguyên nhân gốc rễ cho độ trễ và lỗi, suy luận thông tin chi tiết từ các dấu vết và cung cấp Giám sát Người dùng Thật (Real User Monitoring)\nTrải nghiệm Sự kiện Sự kiện này rất quan trọng đối với dự án của chúng tôi vì nó giải quyết kế hoạch bổ sung IaC bằng cách sử dụng CDK, thay vì sử dụng ClickOps để duy trì và tái tạo. Ngoài ra, một số thông tin chi tiết hơn về CloudWatch đã giúp ích rất nhiều cho tính năng giám sát dữ liệu của chúng tôi\nCác diễn giả đã trả lời câu hỏi của nhóm chúng tôi:\nHỏi: Dự án của chúng tôi cho đến nay chỉ được xây dựng bằng ClickOps, và chúng tôi đang có kế hoạch sử dụng CDK. Có công cụ nào có thể quét và biến cơ sở hạ tầng hiện có của chúng tôi thành CDK hoặc CloudFormation thay vì phải tái tạo lại cơ sở hạ tầng từ đầu bằng IaC không?\nĐáp: Rất tiếc là chưa có công cụ nào có thể hỗ trợ vấn đề đó, nhóm của bạn sẽ phải xây dựng lại cơ sở hạ tầng từ đầu. Nếu có bất kỳ cơ hội nào mà bạn tìm thấy một công cụ có thể hỗ trợ, hãy chia sẻ với chúng tôi.\nHỏi: Chúng tôi nhận thấy rằng AWS X-Ray được sử dụng với CloudWatch tương tự như CloudTrail trong phương pháp truy vết của nó, bạn có thể giải thích thêm về điểm khác biệt giữa chúng không?\nĐáp: X-Ray được sử dụng cho CloudWatch và dùng để truy vết các tài nguyên và dịch vụ mà hệ thống tương tác, trong khi CloudTrail thường được sử dụng để truy vết các hành động của người dùng AWS.\nHỏi: Dự án của chúng tôi được xây dựng xoay quanh Guard Duty Findings, bạn có kinh nghiệm nào về cách kích hoạt Findings một cách đáng tin cậy cho các kịch bản demo không?\nĐáp: Theo kinh nghiệm của tôi, tôi biết rằng Guard Duty Findings có thể được kích hoạt bằng các hoạt động quét cổng (port scanning activities) nhưng tôi chắc chắn rằng cũng có những cách khác.\nĐáp: Guard Duty có thể được cấu hình để có một danh sách mối đe dọa (threat list) chứa các quy tắc tùy chỉnh để kích hoạt findings khi có các hoạt động liên quan đến các miền hoặc IP độc hại đã được cấu hình.\nSự kiện này cũng là lần đầu tiên một số diễn giả trình bày một chủ đề:\nCác phần DevOps và IaC được trình bày tốt Phần Monitoring \u0026amp; Observability không được tốt bằng và chúng tôi có thể nhận thấy sự lo lắng của diễn giả nhưng vẫn truyền tải được những giá trị tuyệt vời. Một số hình ảnh sự kiện Ảnh nhóm chụp bởi Tran Dai Vi\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/1.4-week4/","title":"Nhật ký Công việc Tuần 4","tags":[],"description":"","content":"Mục tiêu Tuần 4: Hoàn thành Module 6 Bắt đầu đề xuất dự án Các nhiệm vụ được thực hiện trong tuần này: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Module 6: Ôn tập Khái niệm Cơ sở Dữ liệu:\n+ Database (Cơ sở dữ liệu) + Session (Phiên) + Primary/Foreign Key (Khóa chính/Khóa ngoại) + Index (Chỉ mục) + Partitions (Phân vùng) + Execution/Query Plan (Kế hoạch Thực thi/Truy vấn) + Log \u0026amp; Buffer (Nhật ký \u0026amp; Bộ đệm) + RDBMS (Relational Database Management System - Hệ thống Quản lý Cơ sở Dữ liệu Quan hệ) + NOSQL + OLTP (Online Transaction Processing): Dùng cho thanh toán, giao dịch + OLAP (Online Analytical Processing): Phân tích dữ liệu, dự đoán xu hướng và mô hình - AWS RDS (Relational Database Service): Bao gồm Aurora, MySQL, PostgreSQL, MSSQL, Oracle, MariaDB + Sao lưu tự động (Automatic backup) + Tạo read replica (bản sao chỉ đọc) + Read replica có thể được chuyển thành primary node + Tự động chuyển đổi dự phòng/Đa AZ (Auto Failover/Multi AZ) (Sao lưu trên nhiều AZ) + Thường được sử dụng cho OLTP + Mã hóa dữ liệu khi nghỉ (at rest)/đang truyền (in transit) + Được bảo vệ bởi Security Group và NACL + Có thể thay đổi kích thước instance + Tự động mở rộng lưu trữ (Storage Auto Scaling) - Amazon Aurora: Cơ sở hạ tầng lưu trữ cơ bản được tối ưu hóa, sử dụng MySQL và PostgreSQL + Backtrack: hoàn nguyên về trạng thái trước đó + Clone (Sao chép) + Global Database (Đa Region) + Multi Master: Nhiều Cơ sở Dữ liệu Master - Amazon Redshift: Dịch vụ kho dữ liệu (Data warehouse service): core PostgreSQL, được tối ưu hóa cho OLAP + Sử dụng MPP Database: dữ liệu được phân vùng và lưu tại các compute nodes, một Leader node được sử dụng để phối hợp và biên dịch các truy vấn + Lưu trữ dữ liệu ở định dạng lưu trữ cột (columnar storage format), hữu ích cho các ứng dụng OLAP + Sử dụng SQL và các driver như JDBC và ODBC + Cung cấp các dịch vụ tiết kiệm chi phí (Transient Cluster/Redshift Spectrum) - Amazon ElastiCache: Tạo Công cụ Caching Cluster (Redis/Memcached) + Phát hiện và thay thế các nodes bị lỗi + Đặt trước lớp CSDL để lưu vào bộ đệm dữ liệu + Khuyến nghị sử dụng Redis cho các khối lượng công việc mới + Sử dụng ElastiCache yêu cầu logic lưu vào bộ đệm trên các ứng dụng, không khuyến nghị sử dụng lưu vào bộ đệm hệ thống mặc định - Xây dựng đề xuất workshop với đồng đội - Môn học ở trường: + KS57: Hoàn thành Quản trị dữ liệu và an toàn thông tin 29/09/2025 29/09/2025 Quản trị dữ liệu và an toàn thông tin 3 - Lab 43: Hướng dẫn bị hỏng, liên kết không dẫn đến đâu, làm theo video + Tải xuống Schema Conversion Tool + Tải xuống MSSQL trong EC2 Instance + Không có SQL script nào được cung cấp, thử với custom basic MSSQL Database + Không có CloudFormation Stack nào được cung cấp, bỏ qua kết nối Oracle Database + Cài đặt MySQL trên EC2 Instance + Di chuyển custom MSSQL Database sang MySQL Database bằng AWS Schema Conversion Tool + Tạo custom RDS để kiểm thử tác vụ di chuyển + Cố gắng di chuyển từ máy cục bộ sang RDS + Thử sử dụng AWS Replication Agent: Không thành công do nó chỉ được tạo cho Windows/Linux server, không phải OS X + Cố gắng port forward PC để được sử dụng làm endpoint + Port forwarding thất bại, không được phép bởi ISP 30/09/2025 30/09/2025 Lab 43 Application Migration Service Guide 4 - Phát hiện credits tài khoản AWS đã hết hạn do làm lab 12 - Viết support case - Tạm dừng các lab - Tập trung nghiên cứu về đề xuất của nhóm 01/10/2025 01/10/2025 - Môn học ở trường: + ENW439c: Hoàn thành Research Methodologies Research Methodologies 5 - Tiếp tục làm lab bằng cách nhận sự trợ giúp từ thành viên nhóm: Tạo một IAM User với quyền admin để tôi đăng nhập và sử dụng tài khoản của họ - Dịch blog đầu tiên 02/10/2025 02/10/2025 Blog 1 6 - Tham gia sự kiện AI-Driven Development Life Cycle: Reimagining Software Engineering - Dịch blog thứ hai và thứ ba 03/10/2025 04/10/2025 Blog 2 Blog 3 Thành tựu Tuần 4: Hoàn thành một đánh giá toàn diện về các khái niệm cơ sở dữ liệu cốt lõi bao gồm RDBMS, keys, indexes, partitioning, OLTP/OLAP, và các dịch vụ cơ sở dữ liệu dành riêng cho AWS.\nĐạt được kiến thức lý thuyết về các tính năng và trường hợp sử dụng của AWS RDS, Amazon Aurora (ví dụ: Backtrack, Global Database), Amazon Redshift (Data Warehouse cho OLAP), và Amazon ElastiCache (caching với Redis/Memcached).\nDi chuyển Cơ sở Dữ liệu: Thử nghiệm một lab di chuyển cơ sở dữ liệu phức tạp, thể hiện sự tháo vát bằng cách:\n* Tìm kiếm custom MSSQL Database và cài đặt các dịch vụ cần thiết trên EC2 instance do hướng dẫn lab bị hỏng.\n* Di chuyển thành công custom MSSQL database sang MySQL Database bằng AWS Schema Conversion Tool (SCT).\nXác định và giải quyết vấn đề credits AWS đã hết hạn bằng cách gửi support case.\nĐảm bảo tiếp tục công việc lab bằng cách thiết lập một IAM User với đặc quyền admin trên tài khoản của thành viên nhóm.\nXây dựng đề xuất cho workshop sắp tới của nhóm.\nHoàn thành việc dịch ba blog.\nĐã tham dự sự kiện AI-Driven Development Life Cycle: Reimagining Software Engineering.\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong quá trình thực tập, mình đã tham gia bảy sự kiện. Mỗi sự kiện đều là một trải nghiệm đáng nhớ, mang lại nhiều kiến thức mới, thú vị và hữu ích, cùng với những phần quà và khoảnh khắc tuyệt vời.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders: Gen AI and Data track\nThời gian: 08:30, ngày 18 tháng 9 năm 2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hai Trieu, phường Sài Gòn, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nEvent 2 Tên sự kiện: AI-Driven Development Life Cycle: Reimagining Software Engineering\nThời gian: 09:00, ngày 3 tháng 10 năm 2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hai Trieu, phường Sài Gòn, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nEvent 3 Tên sự kiện: AWS Cloud Mastery Series #1 - AI/ML/GenAI on AWS\nThời gian: 08:30, ngày 15 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hai Trieu, phường Sài Gòn, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nEvent 4 Tên sự kiện: AWS Cloud Mastery Series #2 - DevOps on AWS\nThời gian: 08:30, ngày 17 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hai Trieu, phường Sài Gòn, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nEvent 5 Tên sự kiện: Secure Your Applications: AWS Perimeter Protection Workshop\nThời gian: 08:30, ngày 19 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hai Trieu, phường Sài Gòn, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nEvent 6 Tên sự kiện: AWS Well-Architected – Security Pillar Workshop\nThời gian: 08:30, ngày 29 tháng 11 năm 2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hai Trieu, phường Sài Gòn, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nEvent 7 Tên sự kiện: BUILDING AGENTIC AI - Context Optimization with Amazon Bedrock\nThời gian: 08:30, ngày 5 tháng 12 năm 2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hai Trieu, phường Sài Gòn, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.4-setup-cloudfront/","title":"Cài đặt Cloudfront","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một Cloudfront để cache, định tuyến và truy cập web.\nTạo Cloudfront Distribution Mở Cloudfront Console\nĐiều hướng tới https://console.aws.amazon.com/cloudfront/ Hoặc: AWS Management Console → Services → Cloudfront Tạo Distribution:\nNhấn nút Create distribution Trong phần tạo distribution, sử dụng cài đặt này: Chọn plan: Free plan Name: Static Dashboard Website CloudFront Origin type: Amazom S3 S3 Origin: Chọn static-dashboard-bucket Giữ phần còn lại như mặc định Bật security: Sử dụng cái này nếu bạn chọn free plan Xem lại và nhấn Create distribution Cài đặt chung (General setting):\nSau khi tạo xong, trên tab General của Cloudfront nhấn vào Edit Tại Default root object nhập index.html Description: Static Dashboard Distribution Nhấn Save change Tạo API Gateway origin:\nNhấn Origins trên các tab menu Sau đó nhấn Create origin Trong phần tạo origin, sử dụng cài đặt này: Origin domain: chọn dashboard-api Protocol: HTTPS only HTTPS port: 443 Minimum Origin SSL protocol: TLSv1.2 Origin path: /prod Nhấn Create origin Tạo behaviors cho API Gateway:\nNhấn Behaviors trên các tab menu Sau đó nhấn Create behavior Trong phần tạo behavior, sử dụng cài đặt này: Path pattern: /logs/* Origin và origin groups: chọn dashboard-api Để các cài đặt còn lại như mặc định Nhấn Create behavior Cập nhật S3 policy để hoạt động với Cloudfront:\nNhấn Origins trên các tab menu, chọn tên origin s3-static-dashboard Nhấn Edit Tại phần Origin access controll nhấn Go to S3 bucket permissions Kiểm tra xem quyền S3 của bạn có giống thế này không, nếu không hãy copy và paste nó vào quyền S3 của bạn (Thay đổi ACCOUNT_ID, ACCOUNT_REGION và CLOUDFRONT_ID thành của bạn): { \u0026#34;Version\u0026#34;: \u0026#34;2008-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;PolicyForCloudFrontPrivateContent\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontServicePrincipal\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::s3-static-dashboard-[ACCOUNT_ID]-[ACCOUNT_REGION]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;ArnLike\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::[ACCOUNT_ID]:distribution/[CLOUDFRONT_ID]\u0026#34; } } } ] } Nhấn Save change Tạo error pages:\nNhấn Error pages trên các tab menu Nhấn Create custom error page Trong phần tạo custom error page, sử dụng cài đặt này: HTTP error code: 403: Forbident Error caching minimum TTL: 300 Customize error response: Yes Response page path: /index.html HTTP Response code: 200: OK Lặp lại bước này cho 404 code "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.4-cloudwatch-eni-etl/","title":"Mã CloudWatch ENI ETL","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose = boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CONFIGURATION # -------------------------------------------------- FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) # ----------------------------- UTILS ----------------------------- def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def safe_int(x): try: return int(x) except: return None def parse_flow_log_line(line): parts = line.strip().split(\u0026#39; \u0026#39;) if len(parts) \u0026lt; 14: return None try: start_timestamp = safe_int(parts[10]) time_str = None if start_timestamp: dt_object = datetime.fromtimestamp(start_timestamp) time_str = dt_object.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;) record = { \u0026#34;version\u0026#34;: safe_int(parts[0]), # Cột 1: version (int) \u0026#34;account_id\u0026#34;: parts[1], # Cột 2: account_id (STRING) \u0026#34;interface_id\u0026#34;: parts[2], # Cột 3: eni-... \u0026#34;srcaddr\u0026#34;: parts[3], \u0026#34;dstaddr\u0026#34;: parts[4], \u0026#34;srcport\u0026#34;: safe_int(parts[5]), \u0026#34;dstport\u0026#34;: safe_int(parts[6]), \u0026#34;protocol\u0026#34;: safe_int(parts[7]), \u0026#34;packets\u0026#34;: safe_int(parts[8]), \u0026#34;bytes\u0026#34;: safe_int(parts[9]), \u0026#34;start_time\u0026#34;: start_timestamp, # Cột 11 \u0026#34;end_time\u0026#34;: safe_int(parts[11]), \u0026#34;action\u0026#34;: parts[12], \u0026#34;log_status\u0026#34;: parts[13], \u0026#34;timestamp_str\u0026#34;: time_str } return record except Exception as e: print(f\u0026#34;Error parsing line: {e}\u0026#34;) return None def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] # Duyệt qua các file S3 gửi về (Iterate through files sent from S3) for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] # Chỉ xử lý file .gz (Process .gz files only) if not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping non-gz: {key}\u0026#34;) continue print(f\u0026#34;Processing: {key}\u0026#34;) # Đọc nội dung (Read content) content = read_gz(bucket, key) if not content: continue # Parse từng dòng log (Parse each log line) for line in content.splitlines(): rec = parse_flow_log_line(line) if not rec: continue # Chuyển thành JSON string và thêm xuống dòng (\\n) (Convert to JSON string and add newline) json_row = json.dumps(rec) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Đẩy sang Firehose (Batching 500 dòng) (Push to Firehose - batching 500 lines) if firehose_records: total = len(firehose_records) print(f\u0026#34;Flushing {total} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed.\u0026#34;) except Exception as e: print(f\u0026#34;Firehose API Error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;count\u0026#34;: len(firehose_records)} "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.4-monitoring-setup/","title":"Thiết lập giám sát","tags":[],"description":"","content":"Giai đoạn Thiết lập giám sát này kích hoạt và cấu hình ba nguồn log cốt lõi để phát hiện mối đe dọa. Giai đoạn này bao gồm việc bật CloudTrail cho các sự kiện quản lý và dữ liệu toàn diện, kích hoạt GuardDuty để xuất các phát hiện bảo mật sang S3 bucket chính, và thiết lập VPC Flow Logs trên mạng của bạn để gửi tất cả metadata lưu lượng truy cập đến CloudWatch Log Group chuyên dụng. Điều này đảm bảo luồng dữ liệu log liên tục, tập trung luôn sẵn sàng cho việc xử lý và phản hồi tự động.\nTạo CloudWatch Log Group Mở CloudWatch Console → Log Management → Create log group Cấu hình:\nLog group name: /aws/incident-response/centralized-logs Retention: 90 ngày KMS key: None Nhấn \u0026ldquo;Create\u0026rdquo;\nBật AWS CloudTrail Mở CloudTrail Console → Trail → Create trail Thuộc tính Trail:\nTrail name: incident-responses-cloudtrail-ACCOUNT_ID-REGION Storage location: Sử dụng S3 bucket hiện có S3 bucket: Chọn incident-response-log-list-bucket-ACCOUNT_ID-REGION của bạn Log file SSE-KMS encryption: Disable (Tắt) Log file validation: Enabled (Bật) Nhấn next Chọn log events:\nEvents Chọn Management events, Data events Management events: Tất cả (Read + Write) Data events: S3 - Log tất cả events Nhấn next đến bước 4 và Create Trail Advanced event selectors: Loại trừ log buckets:\nNhấn vào Trail sau đó cuộn xuống Data Event và nhấn Edit Thiết lập như hình với định dạng dưới đây: -arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-guardduty-findings-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION\n-arn:aws:s3:::athena-query-results-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION/\nLưu thay đổi Bật Amazon GuardDuty Mở GuardDuty Console → Get Started → Enable GuardDuty\nCấu hình cài đặt:\nFinding export frequency: Update CWE và S3 mỗi 15 phút S3 export: incident-response-log-list-bucket-ACCOUNT_ID-REGION KMS encryption: Chọn hoặc tạo KMS key Bật VPC Flow Logs Mở VPC Console → Your VPCs → Chọn VPC của bạn\nActions → Create flow log\nCấu hình:\nFilter: All (Tất cả) Aggregation interval: 10 phút Destination: CloudWatch Logs Log group: /aws/incident-response/centralized-logs IAM role: FlowLogsIAMRole Log format: Default (Mặc định) Tạo flow log\nBật VPC DNS Query Logging Cấu hình Resolver Query Logging Mở Amazon Route 53 Console.\nỞ thanh điều hướng bên trái, chọn VPC Resolver -\u0026gt; Query logging.\nNhấn \u0026ldquo;Configure query logging\u0026rdquo;.\nCấu hình:\nName: Nhập tên mô tả, ví dụ: IR-DNS-Query-Log-Config. Destination for query logs: CloudWatch Logs log group Log group: Chọn \u0026ldquo;Existing log group\u0026rdquo; và chọn: /aws/incident-response/centralized-logs Nhấn \u0026ldquo;Configure query logging\u0026rdquo;.\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/4-eventparticipated/4.5-event5/","title":"Sự kiện 5","tags":[],"description":"","content":"Báo Cáo Tóm Tắt: “Secure Your Applications: AWS Perimeter Protection Workshop” Mục tiêu Sự kiện Giới thiệu CloudFront như nền tảng cho việc bảo vệ vòng ngoài (perimeter protection) Giới thiệu WAF và Bảo vệ Ứng dụng (Application Protection) Workshop Thực hành: Tối ưu hóa ứng dụng web với CloudFront Workshop Thực hành: Bảo mật Ứng dụng Web Internet Diễn giả Nguyen Gia Hung - Head of Solution Architect Julian Ju - Senior Edge Services Specialist Solution Architect Kevin Lim - Senior Edge Services Specialist GTM Điểm nhấn chính CloudFront Hình thức Bảo mật Khách hàng cần và Giải pháp Chân dung Khách hàng (Customer Personas):\nChủ sở hữu trang web nhỏ: Bảo vệ bảo mật cơ bản Người dùng Doanh nghiệp: Bảo mật toàn diện chống lại DDoS và bots Doanh nghiệp đang mở rộng quy mô: Khả năng cấu hình nâng cao như origin failover và giảm tải origin (origin load reduction) Giải pháp: CloudFront\nBảo mật với chi phí hàng tháng có thể dự đoán: Trả giá cố định cho CDN, WAF, DDoS Protection, DNS và Storage Lựa chọn gói đơn lẻ Chính sách Giá CloudFront Mới: CloudFront Flat-Rate Giá cố định cho CDN, WAF, DDoS Protection, DNS và Storage, trả cùng một mức giá cho việc sử dụng không giới hạn\nAWS cung cấp 4 gói giá cố định cho CloudFront: + Free: $0/Tháng + Pro: $15/Tháng + Business: $200/Tháng + Premium: $1000/Tháng\nMỗi gói có giới hạn sử dụng riêng hàng tháng: + Free: 1 triệu yêu cầu + 100 GB Dữ liệu + Pro: 10 triệu yêu cầu + 50 TB Dữ liệu + Business: 125 triệu yêu cầu + 50 TB Dữ liệu + Premium: 500 triệu yêu cầu + 50 TB Dữ liệu\nVượt quá giới hạn sử dụng =\u0026gt; Không phát sinh chi phí nhưng CloudFront sẽ giảm hiệu suất và gửi cảnh báo\nCách CloudFront giúp bảo vệ vòng ngoài (perimeter protection) Chống lại các cuộc tấn công phân tán bằng phòng thủ phân tán: Thay vì phòng thủ các cuộc tấn công từ khắp nơi trên thế giới cùng một lúc, CloudFront giúp bằng cách phòng thủ tại các vị trí biên (edge locations) gần nhất với nguồn tấn công Shield Advanced: Có được khả năng hiển thị các cuộc tấn công lớp hạ tầng, quyền truy cập vào Đội ngũ Phản ứng Shield (Shield Response Team) 24/7 Tấn công Volumetric: CloudFront cung cấp giảm thiểu nội tuyến (inline mitigation), STN Proxy bảo vệ khỏi tấn công SYN flood và định tuyến mạng tự động Tối ưu hóa chi phí với Amazon CloudFront Truyền dữ liệu ra khỏi AWS (AWS Data transfer out) tới CloudFront: Miễn phí Nén HTTP (HTTP compression): Nén tệp đối tượng khoảng 80% Mã hóa HTTPS trong quá trình truyền (in transit): + TLS độc quyền của AWS (AWS proprietary TLS) + Cấp và xác thực chứng chỉ TLS tự động mà không mất thêm chi phí + Chuyển hướng tự động từ HTTP sang HTTPS + Phiên bản TLS và bộ mã hóa được quản lý bằng chính sách bảo mật + TLS 1.3, ECDSA cert, post quantum Hỗ trợ mutual TLS sắp ra mắt Che giấu Origin (Origin cloaking) với Origin Access Control: ký yêu cầu bằng thông tin xác thực ngắn hạn, áp dụng cho S3 Bucket, Lambda Function URL, Elemental Media Package Che giấu Origin cho các custom origins: Chỉ cho phép CloudFront IP với danh sách tiền tố được quản lý (managed prefixes list) và thêm custom header với một bí mật được xác định trước Bảo vệ nội dung với Signed URL: Ngăn chặn hành vi sao chép-dán URL đánh cắp nội dung Lợi ích của Bộ nhớ đệm (Caching benefits) để cải thiện tính khả dụng: Bộ nhớ đệm nội dung dựa trên TTL, phản hồi mà không cần yêu cầu đến origin và phản hồi nội dung cũ (stale content) trong trường hợp origin hết thời gian chờ Failover tích hợp sẵn và origin failover: Tự động định tuyến lưu lượng truy cập đến vị trí biên tối ưu và khỏe mạnh, điều tương tự cũng xảy ra với origin khi origin chính bị lỗi =\u0026gt; failover sang origin phụ Thất bại duyên dáng (Graceful failure): Hỗ trợ trang lỗi tùy chỉnh, nội dung cũ và kết quả lỗi được lưu trong bộ nhớ đệm Hiệu suất nâng cao với Amazon CloudFront Kiến trúc bộ nhớ đệm đa lớp (Multi-layer caching architecture): Tập hợp lưu lượng truy cập từ các CloudFront PoPs trong Regional Edge Caches và Origin Shield, cho phép gộp yêu cầu (request collapsing) và cải thiện tỷ lệ truy cập bộ nhớ đệm (cache hit ratio) Multiplexing: Tải xuống song song Kết nối bền bỉ với origins (Persistent connections to origins): Tránh bắt tay TCP bổ sung và duy trì dung lượng TCP đầy đủ AWS Global backbone: Độ trễ thấp hơn và không bị ảnh hưởng bởi sự kiện internet công cộng Chạy logic tại biên (Run logic at the edge): + Chuyển hướng tại biên (Redirect at edge) (CloudFront Function, Lambda at Edge) + Viết lại URL / Thử nghiệm AB Testing / Chuyển hướng Địa lý (Geographic Redirect Device-based Redirect) + Cung cấp nội dung dựa trên thiết bị (Device based content delivery) + Phản hồi nhanh hơn mà không cần origin: Giới hạn tốc độ (Rate limiting) / API Mocking / Kiểm tra tình trạng (Health check) / Xử lý Lỗi (Error Handling) Các trường hợp sử dụng CloudFront Tài nguyên web tĩnh: Tỷ lệ truy cập bộ nhớ đệm cao =\u0026gt; Tăng hiệu suất + Tải origin tối thiểu Phân phối toàn bộ trang web: Hiệu suất toàn cầu + Bảo mật + Tính khả dụng cao + Tối ưu hóa chi phí Tăng tốc API (API acceleration): Tái sử dụng kết nối + AWS backbone =\u0026gt; Giảm độ trễ + Bộ nhớ đệm chọn lọc Truyền phát đa phương tiện (Media Streaming): Khả năng mở rộng không giới hạn + Độ trễ thấp + Hiệu quả về chi phí + Hàng triệu người dùng đồng thời Tải xuống tệp lớn: Yêu cầu phạm vi (Range requests) + Bộ nhớ đệm tại biên (Edge caching) + Tiết kiệm chi phí 80-90% Các phương pháp hay nhất của CloudFront Khả năng hiển thị từ đầu đến cuối (End to end visibility): Giám sát người dùng thật/Internet/Hạ tầng Tối đa hóa bộ nhớ đệm: Chuẩn hóa khóa bộ nhớ đệm (Normalize cache key), bộ nhớ đệm nội dung động/riêng tư và bộ nhớ đệm lỗi Chặn các yêu cầu không mong muốn: Mô hình độc hại, giới hạn tốc độ, giảm thiểu DDoS và lọc các yêu cầu API Chuyển logic nghiệp vụ: Phản hồi CORS, chuyển hướng tại biên và đặt cookies Failover tự động: Định tuyến failover của Route 53 + CloudFront Origin Group cho failover cấp yêu cầu AWS WAF \u0026amp; Bảo vệ Ứng dụng Các mối đe dọa và tác động đến doanh nghiệp Từ chối dịch vụ (Denial of Service) Lỗ hổng Ứng dụng (App Vulnerabilities) Lưu lượng truy cập Bot =\u0026gt; Dữ liệu bị đánh cắp, thông tin xác thực bị xâm phạm, spam, thời gian ngừng hoạt động, can thiệp thủ công, tăng chi phí hạ tầng, mất uy tín\nSự gia tăng hoạt động của bot Các bot AI đa dạng từ nhiều nguồn khác nhau tăng đáng kể trong môi trường khách hàng: Tăng 155% so với cùng kỳ năm trước\nRoute 53 trong bảo vệ vòng ngoài Các máy chủ DNS phân tán trên toàn cầu =\u0026gt; Tự động mở rộng quy mô và giảm thiểu DDoS + SLA về Tính khả dụng 100%\nBảo vệ Hạ tầng với AWS Shield Tại biên (At edge): + SYN Proxy + Kiểm tra (Inspection) + Xác thực gói tin (Packet validation) + Dung lượng lọc phân tán (Distributed scrubbing capacity) + Chính sách Định tuyến Tự động\nTại biên giới (At border): + Lọc Lưu lượng truy cập + Phát hiện và giảm thiểu cấp tài nguyên + Phát hiện dựa trên Tình trạng (Health-based detection)\nKiểm tra HTTP với AWS WAF WAF hoạt động cùng với CloudFront Phát hiện HTTP flood, các mẫu độc hại, IP xấu Kiểm soát Bot Kiểm soát Gian lận (Fraud control) Phản hồi Sự cố của Shield Advanced Shield/Shield Advanced có metric để kích hoạt báo động nhằm bắt đầu phản hồi sự cố Shield Advanced cung cấp Đội ngũ Phản ứng Shield (Shield Response Team) 24/7 Tìm kiếm vector tấn công và bên đóng góp Cấu hình WAF Thêm quy tắc (rules) và nhóm quy tắc (rules group) Sử dụng quy tắc được quản lý (managed rules) và quy tắc tùy chỉnh (custom rules) Bắt đầu với chế độ COUNT: Giám sát để tránh dương tính giả (false positives) Sử dụng labels để tùy chỉnh logic và phản hồi Giới hạn phạm vi (Scope-down) để tối ưu hóa chi phí Web ACL/Protection Pack Tập hợp các quy tắc, nhóm quy tắc và hành động mặc định Liên kết với các tài nguyên như CloudFront Distribution Cấu hình ghi nhật ký (Logging) và lấy mẫu (sampling) WAF Rules Tiêu chí kiểm tra (Inspection criteria) (Địa chỉ IP/Header value/Request Body) =\u0026gt; Hành động (Action) (Cho phép/Chặn/Đếm/Tùy chỉnh) Quy tắc dựa trên tỷ lệ (Rate-based rule): Dựa trên số lượng yêu cầu HTTP từ một IP WAF Anti-DDoS Application Layer Protection Giảm thiểu DDoS lớp ứng dụng tự động Bảo vệ bằng các quy tắc được cấu hình sẵn Bảo vệ DDoS có thể cấu hình dựa trên nhu cầu ứng dụng WAF Labels Được thêm bởi quy tắc được quản lý (Luôn luôn) và quy tắc tùy chỉnh (Tùy chọn): Cho biết quy tắc đã khớp, trạng thái phiên, dữ liệu Địa lý và dựa trên IP cùng các hoạt động của Bot/Fraud\nCommon bots (Bot phổ biến) Là gì: Các bot tự nhận dạng hoặc Công cụ Tìm kiếm, Mạng xã hội, thư viện HTTP Kiểm soát bot phổ biến: Tìm kiếm yêu cầu, IP, TLS fingerprint và xác minh bot bằng labels\nEvasive bots (Bot lẩn tránh) Là gì: Scrapers, kẻ nhồi thông tin xác thực (credential stuffers), máy quét lỗ hổng, sử dụng các header và giá trị browser hiện có, không nổi tiếng và bắt chước các bot phổ biến thực Giải pháp: Thẩm vấn máy khách (Client interrogation), xác định phiên máy khách duy nhất và giám sát hành vi của nó\nThực hành CloudFront: Workshop Bảo vệ Vòng ngoài So sánh giữa Origin lưu trữ S3 tĩnh thông thường và Origin lưu trữ S3 với CloudFront CloudFront phân phối một đối tượng nhanh hơn khi nó được phục vụ từ bộ nhớ đệm CloudFront phân phối một đối tượng nhanh hơn bằng cách sử dụng mạng toàn cầu AWS thay vì internet công cộng Trong CloudFront, nén được áp dụng, kích thước đối tượng được giảm đáng kể Thực hành AWS WAF: Tăng cường Khả năng Phòng thủ Ứng dụng Web của Bạn với AWS WAF Đã tạo các quy tắc WAF để bảo vệ chống lại: + Cross site Scripting (XSS) + SQL Injection + Tấn công Path traversal + Tài sản phía máy chủ (Server-side asset) + Bot Phổ biến/Lẩn tránh (Common/Evasive Bot) + Lạm dụng API (API misuse) + Thử nghiệm Bí ẩn (Mystery Test): Cấu hình quy tắc để chặn quyền truy cập bằng giá trị header được mã hóa Trải nghiệm Sự kiện Sự kiện này rất nhiều thông tin và đúng lúc vì nhóm chúng tôi vừa thiết lập CloudFront vào đêm hôm trước. Hệ thống định giá mới tốt hơn rất nhiều đối với chúng tôi, với WAF bổ sung để bảo mật\nWorkshop rất tương tác và vui vẻ, với Mr.Julian cũng hỗ trợ hết mức có thể Chúng tôi cũng nhận được câu trả lời cho các câu hỏi của mình từ Mr.Julian sau sự kiện:\nHỏi: WAF có thể được sử dụng để kiểm soát và chặn hoạt động của bot, nhưng gần đây với sự cải tiến của AI: Đặc biệt là Agent mới của Gemini, có thể tương tác trực tiếp trên trình duyệt của chúng tôi, không phải headless, liệu WAF có thể giúp bảo vệ chống lại những thứ đó không?\nĐáp: Với Gemini, các tương tác vẫn được gọi bằng API nên WAF có thể phát hiện điều đó, nhưng có một loại khác mà chúng ta không thể phát hiện, đó là Claude Agent, nhưng nó chỉ là một công cụ hỗ trợ tiếp cận và không gây ra nhiều hành động độc hại như bot thông thường, vì vậy trong tương lai gần chúng ta chưa cần phải lo lắng về nó.\nMột số hình ảnh sự kiện Hình ảnh Nhóm Người tham dự Sự kiện\nĐạt Top 24 trong Bài Quiz Kahoot cuối sự kiện\nĐã chặn tất cả các mối đe dọa của workshop\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/1.5-week5/","title":"Nhật ký Công việc Tuần 5","tags":[],"description":"","content":"Mục tiêu Tuần 5: Tiếp tục xây dựng và lập kế hoạch đề xuất dự án Các nhiệm vụ được thực hiện trong tuần này: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Việc gia đình 06/10/2025 06/10/2025 3 - Việc gia đình 07/10/2025 07/10/2025 4 - Học cách tạo Sơ đồ Kiến trúc AWS cơ bản - Đã tạo sơ đồ kiến trúc workshop của nhóm 08/10/2025 08/10/2025 5 - Lab 35: + Thiết lập thành công data stream bằng Kinesis + Gửi thành công dữ liệu mẫu đến S3 bằng Kinesis Data Generator với Amazon Cognito + Học cách sử dụng AWS Glue Crawler để map data đến S3 Bucket + Sử dụng Athena để truy vấn dữ liệu + Sử dụng AWS Glue Notebook để xây dựng dataset dựa trên dữ liệu mẫu + Sử dụng Athena để phân tích dữ liệu và trực quan hóa với QuickSight - Cập nhật sơ đồ kiến trúc dựa trên các thay đổi trong đề xuất workshop - Bắt đầu nghiên cứu GuardDuty để sử dụng làm thành phần của workshop 09/10/2025 09/10/2025 Lab 35 6 - Lab 40: + Thực hành thêm với AWS Glue và Athena, sử dụng để phân tích dữ liệu AWS Monthly Cost - Môn học ở trường: + KS57: Hoàn thành Giáo dục và Phát triển nguồn nhân lực số 10/10/2025 10/10/2025 Lab 40 Giáo dục và Phát triển nguồn nhân lực số Thành tựu Tuần 5: Phát triển Đề xuất: Đã tạo và cập nhật thành công sơ đồ kiến trúc workshop của nhóm, học các best practices cho việc vẽ sơ đồ kiến trúc AWS.\nData Streaming và Analytics: Hoàn thành một lab phức tạp tập trung vào các data pipelines:\n* Thiết lập thành công data stream real-time bằng Amazon Kinesis.\n* Sử dụng Kinesis Data Generator với Amazon Cognito để gửi dữ liệu mẫu đến S3.\n* Học cách sử dụng AWS Glue Crawler để map data và AWS Glue Notebook để xây dựng datasets.\n* Sử dụng Amazon Athena để truy vấn dữ liệu và Amazon QuickSight để trực quan hóa dữ liệu.\nThực hành các kỹ năng analytics nâng cao bằng cách sử dụng AWS Glue và Athena để phân tích dữ liệu AWS Monthly Cost.\nNghiên cứu Workshop: Đã bắt đầu nghiên cứu về Amazon GuardDuty như một thành phần cho đề xuất workshop của nhóm.\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.5-setup-cognito/","title":"Cài đặt Cognito","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ tạo một Cognito user pool để đăng nhập dashboard.\nTạo Cognito User Pool Mở Amazon Cognito Console\nĐiều hướng tới https://console.aws.amazon.com/cognito/ Hoặc: AWS Management Console → Services → Cognito Tạo user pool:\nNhấn Create user pool Trong phần tạo user pool, sử dụng cài đặt này: Application type: Single-page application (SPA) Application name: dashboard-user-pool-client Options for sign-in identifiers: Email và Username Self-registration: Enable self-registration Required attributes for sign-up: email Add a return URL: Vào Cloudfront, chọn cái bạn vừa tạo và copy Distribution domain name và dán vào đây (Ví dụ: https://d2bvvvpr6s4eyd.cloudfront.net) Nhấn Create user directory Sau khi tạo, cuộn xuống và nhấn Go to overview Cấu hình User pool App clients:\nChọn App clients trên menu bên trái Chọn dashboard-user-pool-client Trong phần App client information, nhấn Edit Thay đổi cài đặt như hình bên dưới: Nhấn Save change Cấu hình Managed login pages:\nTrong phần Managed login pages configuration, nhấn Edit Nhấn Add sign-out URL tại phần Allowed sign-out URLs Copy URL trên callbacks URL và dán vào Allowed sign-out URLs Cuộn xuống OpenID Connect scopes thêm Profile vào scopes Nhấn Save change Tạo một user:\nTrên menu bên trái, chọn tùy chọn User Nhấn Create user Nhập thông tin người dùng của bạn Nhấn Create user "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.5-cloudwatch-autoexport/","title":"Mã CloudWatch Autoexport","tags":[],"description":"","content":" import json import base64 import gzip from io import BytesIO import boto3 import os import time s3 = boto3.client(\u0026#39;s3\u0026#39;) # --- CONFIGURATION (CẤU HÌNH) --- RAW_S3_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;) # The log group pattern constant is no longer used for filtering, but is kept for reference. # VPC_DNS_LOG_PATTERN = \u0026#39;/aws/route53/query/\u0026#39; def is_vpc_dns_log(log_message): try: json_body = json.loads(log_message.strip()) if \u0026#39;query_name\u0026#39; in json_body and \u0026#39;query_type\u0026#39; in json_body: return True return False except Exception: return False def lambda_handler(event, context): try: compressed_payload = base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]) f = BytesIO(compressed_payload) decompressed_data = gzip.GzipFile(fileobj=f).read() log_data = json.loads(decompressed_data.decode(\u0026#39;utf-8\u0026#39;)) log_lines = [] for log_event in log_data.get(\u0026#39;logEvents\u0026#39;, []): log_lines.append(log_event.get(\u0026#39;message\u0026#39;, \u0026#39;\u0026#39;)) if not log_lines: print(f\u0026#34;Batch skipped: No log events found in payload. Log Group: {log_data.get(\u0026#39;logGroup\u0026#39;)}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;Log batch ignored (No events).\u0026#39;} is_dns_log = is_vpc_dns_log(log_lines[0]) if is_dns_log: key_prefix = \u0026#39;vpc-dns-logs\u0026#39; filename_prefix = \u0026#39;vpc-\u0026#39; # Add vpc- to the filename else: key_prefix = \u0026#39;vpc-flow-logs\u0026#39; filename_prefix = \u0026#39;eni-\u0026#39; # Keep filename blank for other logs output_content = \u0026#39;\\n\u0026#39;.join(log_lines) full_log_group_name = log_data.get(\u0026#39;logGroup\u0026#39;, \u0026#39;unknown-group\u0026#39;) log_group_name_safe = full_log_group_name.strip(\u0026#39;/\u0026#39;).replace(\u0026#39;/\u0026#39;, \u0026#39;_\u0026#39;) final_filename = f\u0026#34;{filename_prefix}{context.aws_request_id}.gz\u0026#34; s3_key = f\u0026#39;exportedlogs/{key_prefix}/{log_group_name_safe}/{final_filename}\u0026#39; buffer = BytesIO() with gzip.GzipFile(fileobj=buffer, mode=\u0026#39;w\u0026#39;) as gz: gz.write(output_content.encode(\u0026#39;utf-8\u0026#39;)) gzipped_data = buffer.getvalue() s3.put_object( Bucket=RAW_S3_BUCKET, Key=s3_key, Body=gzipped_data, ContentType=\u0026#39;application/x-gzip\u0026#39; ) num_logs = len(log_lines) print(f\u0026#34;Exported {num_logs} raw log lines to s3://{RAW_S3_BUCKET}/{s3_key}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: f\u0026#39;Logs exported. {num_logs} events processed. Key Prefix: {key_prefix}\u0026#39;} except Exception as e: print(f\u0026#34;Error in CW Export Lambda: {e}\u0026#34;) raise e "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.5-processing-setup/","title":"Thiết lập xử lý","tags":[],"description":"","content":"Giai đoạn Thiết lập xử lý này xây dựng đường ống dữ liệu (data pipeline) cốt lõi để cấu trúc log thô và chuẩn bị chúng cho việc phân tích truy vấn. Giai đoạn này bắt buộc triển khai ba luồng Kinesis Data Firehose để đệm và phân phối CloudTrail và VPC logs đến các S3 buckets đích. Đồng thời, bạn sẽ cấu hình AWS Glue Database và bốn bảng Athena thông qua DDL để làm cho dữ liệu có cấu trúc có thể truy vấn được. Pipeline này dựa vào năm Lambda functions ETL được kích hoạt bởi S3 Event Notifications để thực hiện chuyển đổi dữ liệu cần thiết khi log đến.\nNội dung Tạo Kinesis Data Firehose Delivery Streams Tạo AWS Glue Database và Tables Tạo Lambda Functions - Xử lý ETL "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Thiết lập hệ thống phản hồi sự cố tự động và pháp y số trên AWS Tổng quan Hướng dẫn này cung cấp quy trình từng bước hoàn chỉnh để triển khai hệ thống phản hồi sự cố và điều tra số (forensics) tự động của chúng tôi trên AWS. Hệ thống này tận dụng CloudTrail, GuardDuty, VPC Flow Logs, Kinesis Firehose, Glue, Athena, và Lambda functions được điều phối bởi AWS Step Functions để tự động phát hiện, phân tích và cách ly các tài nguyên bị xâm phạm như EC2 instances và IAM users. Khả năng điều tra log sâu hơn được bổ sung bằng cách thiết lập Security Dashboard lưu trữ trên S3 và truy cập qua CloudFront và Cognito, truy vấn log sử dụng API Gateway và Lambda.\nNội dung Tổng quan Điều kiện tiên quyết Giai đoạn 1: Thiết lập nền tảng Giai đoạn 2: Thiết lập giám sát Giai đoạn 3: Thiết lập xử lý Giai đoạn 4: Thiết lập tự động hóa Giai đoạn 5: Thiết lập Dashboard Kiểm tra Sử dụng CDK Dọn dẹp Phụ lục "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/4-eventparticipated/4.6-event6/","title":"Sự kiện 6","tags":[],"description":"","content":"Báo Cáo Tóm Tắt: “AWS Cloud Mastery Series #3: AWS Well-Architected – Security Pillar Workshop” Mục tiêu Sự kiện Giới thiệu AWS Cloud Club Trụ cột 1: Quản lý Danh tính và Truy cập (Identity \u0026amp; Access Management - IAM) Trụ cột 2: Phát hiện \u0026amp; Giám sát Liên tục (Detection \u0026amp; Continuous Monitoring) Trụ cột 3: Bảo vệ Cơ sở hạ tầng (Infrastructure Protection) Trụ cột 4: Bảo vệ Dữ liệu (Data Protection) Trụ cột 5: Ứng phó Sự cố (Incident Response) Diễn giả Le Vu Xuan An - AWS Cloud Club Captain HCMUTE\nTran Duc Anh - AWS Cloud Club Captain SGU\nTran Doan Cong Ly - AWS Cloud Club Captain PTIT\nDanh Hoang Hieu Nghi - AWS Cloud Club Captain HUFLIT\nHuynh Hoang Long - AWS Community Builders\nDinh Le Hoang Anh - AWS Community Builders\nNguyen Tuan Thinh - Cloud Engineer Trainee\nNguyen Do Thanh Dat - Cloud Engineer Trainee\nVan Hoang Kha - Cloud Security Engineer, AWS Community Builder\nThinh Lam - FCJ Member\nViet Nguyen - FCJ Member\nMendel Grabski (Long) - Ex-Head of Security \u0026amp; DevOps, Cloud Security Solution Architect\nTinh Truong - Platform Engineer at TymeX, AWS Community Builder\nĐiểm nhấn chính AWS Cloud Club Giới thiệu về AWS Cloud Club:\nGiúp khám phá và phát triển các kỹ năng cloud computing Phát triển khả năng lãnh đạo kỹ thuật Xây dựng các kết nối có ý nghĩa trên toàn cầu Cung cấp kinh nghiệm thực hành AWS (hands-on AWS Experiences), cố vấn với các AWS Professional và hỗ trợ nghề nghiệp lâu dài Các AWS Cloud Club là thành viên của FCJA:\nAWS Cloud Club HCMUTE AWS Cloud Club SGU AWS Cloud Club PTIT AWS Cloud Club HUFLIT Lợi ích: Xây dựng Kỹ năng, Cộng đồng và Cơ hội\nQuản lý Danh tính và Truy cập (IAM) IAM là một dịch vụ AWS thiết yếu, chịu trách nhiệm kiểm soát truy cập an toàn. IAM quản lý Người dùng (Users), Nhóm (Groups), Vai trò (Roles) và Quyền (Permissions), đồng thời đảm bảo cả xác thực (authentication) và ủy quyền (authorization).\nCác Phương pháp Hay nhất bao gồm: + Nguyên tắc Đặc quyền Tối thiểu (Least Privilege Principle).\n+ Xóa khóa truy cập root sau khi tạo.\n+ Tránh sử dụng \u0026ldquo;*\u0026rdquo; trong Actions/Resources\n+ Sử dụng Single Sign-On (SSO) để tích hợp đa tài khoản và quản lý truy cập tập trung.\nService Control Policies (SCPs): Các chính sách cấp Tổ chức (Organization-level) đặt ra các quyền tối đa có sẵn cho tất cả các tài khoản trong một Tổ chức. SCPs chỉ lọc quyền; chúng không bao giờ cấp quyền.\nPermission Boundaries: Đặt ra các quyền tối đa mà một chính sách dựa trên danh tính (identity-based policy) có thể cấp cho một Người dùng/Vai trò cụ thể trong một tài khoản.\nMFA:\nTOTP (Mật khẩu Dùng một lần dựa trên Thời gian) FIDO2 (Fast Identity Online 2) Bí mật được chia sẻ Mã hóa khóa công khai Yêu cầu nhập thủ công mã 6 chữ số Yêu cầu chạm đơn giản hoặc quét sinh trắc học Miễn phí Thay đổi Sao lưu và phục hồi linh hoạt Sao lưu nghiêm ngặt và không phục hồi Xoay vòng Thông tin Xác thực (Credential Rotation) với AWS Secrets Manager: + Credential Updater sử dụng các hàm của Secrets Manager theo một chu kỳ: Tạo Secret, Đặt Secret (ví dụ: cứ sau 7 ngày) Kiểm tra Secret, và Hoàn tất Secret + Các sự kiện xoay vòng có thể được gửi đến một EventBridge Schedule để kiểm soát thời gian. + Cuối cùng loại bỏ Secret trước đó\nPhát hiện và Giám sát Liên tục (Detection and Continous Monitoring) Khả năng hiển thị Bảo mật Đa lớp (Multi-Layer Security Visibility): + Management Events: Các cuộc gọi API và hành động console trên tất cả các tài khoản tổ chức. + Data Events: Truy cập đối tượng S3 và thực thi Lambda ở quy mô lớn. + Network Activity Events: Tích hợp VPC Flow Logs để giám sát cấp độ mạng. + Organization Coverage: Ghi nhật ký thống nhất trên tất cả các tài khoản thành viên và khu vực.\nCảnh báo \u0026amp; Tự động hóa với EventBridge\n+ Real-time Events: Các sự kiện CloudTrail chảy đến EventBridge để xử lý ngay lập tức. Đây là nền tảng của Kiến trúc Hướng sự kiện (Event-Driven Architecture - EDA), cho phép các hệ thống phản ứng với các thay đổi khi chúng xảy ra.\n+ Automated Alerting: Phát hiện các hoạt động đáng ngờ trên tất cả các tài khoản tổ chức.\n+ Cross-account Event Routing: Xử lý sự kiện tập trung và phản hồi tự động. EventBridge làm cho điều này liền mạch, định tuyến các sự kiện dựa trên các quy tắc tới các đích trên các tài khoản hoặc khu vực.\n+ Integration \u0026amp; Workflows: Tích hợp Lambda, SNS, SQS cho các quy trình làm việc bảo mật tự động.\nPhát hiện dưới dạng Mã (Detection-as-Code): + CloudTrail Lake Queries: Tạo và sử dụng các quy tắc phát hiện dựa trên SQL cho việc săn tìm mối đe dọa nâng cao (advanced threat hunting). + Version-Controlled Logic: Các quy tắc và logic phát hiện được theo dõi và quản lý thông qua các kho mã.\n+ Automated Deployment: Các dấu vết và quy tắc phát hiện được triển khai tự động trên tất cả các tài khoản tổ chức liên quan, đảm bảo phạm vi bảo mật đồng nhất.\n+ Infrastructure-as-Code (IaC): Sử dụng các công cụ IaC để thiết lập và cấu hình tự động các dấu vết ghi nhật ký và sự kiện của tổ chức\nGuard Duty GuardDuty là một giải pháp Phát hiện Mối đe dọa Thông minh, Luôn Bật (Always-On, Intelligent Threat Detection solution)\nGuardDuty Hoạt động như thế nào – Dựa trên phân tích liên tục của Three Pillars of Detection (Ba Trụ cột Phát hiện):\nNguồn Dữ liệu Những gì nó Giám sát Ví dụ Thực tế CloudTrail Events Hành động IAM, thay đổi quyền, cuộc gọi API Kẻ tấn công vô hiệu hóa ghi nhật ký để che giấu dấu vết. VPC Flow Logs Lưu lượng mạng đến/đi từ tài nguyên của bạn EC2 gửi dữ liệu đến máy chủ C2 botnet. DNS Logs Truy vấn DNS từ cơ sở hạ tầng của bạn Các truy vấn bị nhiễm Malware đến các trang web đào tiền mã hóa. Các Gói Bảo vệ Nâng cao (Advanced Protection Plans): GuardDuty cung cấp các tiện ích bổ sung phát hiện chuyên biệt để bao phủ toàn diện: + S3 Protection: Phát hiện các mẫu truy cập S3 bất thường và quét malware trong các đối tượng S3 tại thời điểm tải lên.\n+ EKS Protection: Giám sát nhật ký kiểm tra Kubernetes để phát hiện truy cập trái phép và xâu chuỗi các phát hiện với S3 để lập bản đồ đường tấn công đầy đủ.\n+ Malware Protection: Tự động quét các khối EBS của các phiên bản EC2 khi nghi ngờ bị xâm phạm.\n+ RDS Protection: Phân tích nhật ký hoạt động đăng nhập vào cơ sở dữ liệu (Aurora/RDS) và phát hiện các cuộc tấn công brute-force (nhiều lần đăng nhập thất bại từ một IP).\n+ Lambda Protection: Giám sát nhật ký mạng chảy từ các lời gọi hàm Lambda và phát hiện xem một hàm bị xâm phạm có gửi dữ liệu đến các IP độc hại hay không.\n+ Runtime Monitoring – Deep Inside Your OS (Giám sát Runtime – Sâu bên trong OS của bạn): Đạt được bằng cách sử dụng một GuardDuty Agent được cài đặt trên EC2/EKS/ECS Fargate. Nó giám sát các quy trình đang chạy, các mẫu truy cập tệp, các cuộc gọi hệ thống và các nỗ lực leo thang đặc quyền (privilege escalation) hoặc reverse shells.\nCác Tiêu chuẩn Tuân thủ (Compliance Standards): + AWS Foundational Security Best Practices: Được phát triển bởi AWS và bao gồm một loạt các dịch vụ AWS.\n+ CIS AWS Foundations Benchmark: được phát triển bởi: AWS và các chuyên gia trong ngành tập trung vào Danh tính (IAM), Ghi nhật ký \u0026amp; Giám sát, và Mạng.\nThực thi Tuân thủ với Detection-as-Code + IaC Tool: AWS CloudFormation được sử dụng để triển khai cấu hình.\n+ Compliance Engine: AWS CloudFormation đẩy các kiểm tra cấu hình đến AWS Security Hub CSPM.\n+ Compliance Standards Applied: Security Hub thực hiện kiểm tra đối với các tiêu chuẩn được liệt kê (AWS Foundational Security Best Practices, CIS AWS Foundations Benchmark, PCI DSS, NIST).\n+ Resources Covered: Amazon S3, Amazon EC2, và Amazon RDS.\nKiểm soát Bảo mật Mạng (Network Security Controls) Vector Tấn công: Các mối đe dọa được phân loại thành Tấn công Vào (Ingress Attacks) (DDoS, SQL injection), Tấn công Ra (Egress Attacks) (data exfiltration, DNS tunneling), và Tấn công Bên trong (Inside Attacks) (lateral movement).\nSecurity Groups (SG): Hoạt động như một Stateful firewall ở cấp độ phiên bản/giao diện. Chúng chỉ hỗ trợ các quy tắc cho phép (allow rules) và có một từ chối tất cả ngầm định (implicit deny all).\nNetwork ACLs (NACLs): Hoạt động ở cấp độ subnet. Chúng là stateless và sử dụng các quy tắc được đánh số để cho phép (ALLOW) hoặc từ chối (DENY) lưu lượng truy cập một cách rõ ràng.\nAWS TGW Security Group Referencing: Cho phép các Transit Gateway (TGW) VPCs xác định các quy tắc Đến (Inbound rules) chỉ bằng cách sử dụng các tham chiếu SG.\nRoute 53 Resolver: Định tuyến các truy vấn DNS đến Private DNS (private hosted zones), VPC DNS, hoặc Public DNS.\nAWS Network Firewall:\n+ Trường hợp Sử dụng: Lọc lưu lượng ra (Egress filtering) (chặn các miền xấu, các giao thức độc hại), Phân đoạn môi trường (Environment segmentation) (VPC to VPC), và Ngăn chặn Xâm nhập (Intrusion prevention) (quy tắc IDS/IPS).\n+ Phòng thủ Chủ động (Active Defense): Có thể tự động chặn lưu lượng truy cập độc hại bằng cách sử dụng Amazon Threat Intelligence, nơi các phát hiện của GuardDuty được đánh dấu để chặn tự động.\nBảo vệ \u0026amp; Quản trị Dữ liệu (Data Protection \u0026amp; Governance) Mã hóa (Encryption - KMS): Dữ liệu được mã hóa bằng Khóa Dữ liệu (Data Key), được bảo vệ bởi Khóa Chính (Master Key - CMK). Các chính sách KMS thực thi lớp bảo mật thứ hai bằng Khóa Điều kiện (Condition keys) để xác định Khi nào mã hóa/giải mã được cho phép.\nQuản lý Chứng chỉ (Certificate Management - ACM): Cung cấp chứng chỉ công khai miễn phí và tự động gia hạn chứng chỉ 60 ngày trước khi hết hạn. Xác thực DNS là phương pháp xác thực được khuyến nghị.\nSecrets Manager: Giải quyết vấn đề thông tin xác thực được mã hóa cứng (hardcoded credentials). Nó sử dụng logic Lambda 4 bước (createSecret, setSecret, testSecret, finishSecret) để tự động xoay vòng thông tin xác thực mà không bị gián đoạn.\nBảo mật Dịch vụ API (S3 \u0026amp; DynamoDB): S3 yêu cầu TLS 1.2+ và chính sách bucket với aws:SecureTransport để thực thi. DynamoDB an toàn theo mặc định với HTTPS bắt buộc.\nBảo mật Dịch vụ Cơ sở dữ liệu (Database Service Security - RDS): Yêu cầu tin cậy phía máy khách trong AWS Root CA Bundle để xác minh danh tính máy chủ và thực thi phía máy chủ (ví dụ: rds.force_ssl=1 cho PostgreSQL).\nỨng phó \u0026amp; Phòng ngừa Sự cố (Incident Response \u0026amp; Prevention) Các Phương pháp Hay nhất về Phòng ngừa: Các bước chính bao gồm sử dụng thông tin xác thực tạm thời, không bao giờ để lộ S3 buckets trực tiếp, đặt các dịch vụ nhạy cảm phía sau các private subnets, quản lý mọi thứ thông qua Infrastructure as Code, và sử dụng cổng đôi cho các thay đổi rủi ro cao (phê duyệt PR, triển khai pipeline).\nQuy trình Ứng phó Sự cố: Một cách tiếp cận có cấu trúc gồm 5 bước: Chuẩn bị, Phát hiện \u0026amp; Phân tích, Ngăn chặn (cô lập, thu hồi thông tin xác thực), Tiêu diệt \u0026amp; Phục hồi, và Sau Sự cố (Post-Incident) (bài học kinh nghiệm).\nTrải nghiệm Sự kiện Sự kiện này cực kỳ hữu ích cho nhóm chúng tôi, phù hợp trực tiếp với dự án Automated Incident Response and Forensics của chúng tôi\nHỏi: Dự án của nhóm chúng tôi là một công cụ Automated Incident Response and Forensics với Guard Duty là trọng tâm chính trong việc ứng phó sự cố, nhưng qua thử nghiệm chúng tôi thấy rằng Guard Duty có thể mất tới 5 phút để tạo ra một finding khi sự cố xảy ra, chúng tôi muốn hỏi có giải pháp nào để giảm độ trễ này không?\nĐáp: Việc Guard Duty mất 5 phút để tạo ra các findings là điều bạn phải chấp nhận, vì đó là cách Guard Duty được cấu hình để hoạt động: Guard Duty phải đi qua một lượng lớn bộ dữ liệu bảo mật để xác định mối đe dọa chính xác và sau đó tạo ra một finding. Tuy nhiên, nếu bạn muốn giảm độ trễ, một trong những cách bạn giải quyết nó là với tích hợp dịch vụ bảo mật của bên thứ ba như: Open Clarity Free để có các findings gần như thời gian thực và bạn cũng có thể phát hiện các bất thường và hành vi người dùng bất thường với CloudTrail.\nMr.Mendel Grabski đã rất nhiệt tình đề nghị hỗ trợ khi chúng tôi hỏi về dự án của mình sau sự kiện\nMột số hình ảnh sự kiện Hình ảnh tất cả Người tham dự\nẢnh nhóm với Diễn giả Mendel Grabski và Diễn giả Van Hoang Kha\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/1.6-week6/","title":"Nhật ký Công việc Tuần 6","tags":[],"description":"","content":"Mục tiêu Tuần 6: Hoàn thành và nộp đề xuất dự án Phân công nhiệm vụ cho thành viên nhóm để bắt đầu workshop Các nhiệm vụ được thực hiện trong tuần này: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Định dạng lại và tinh chỉnh worklog, thêm thông tin và tóm tắt - Triển khai worklog thành công lên GitHub Pages 13/10/2025 13/10/2025 3 - Họp nhóm - Sửa đổi đề xuất workshop: Tập trung sử dụng GuardDuty để phát hiện xâm nhập thay vì hàm Lambda tùy chỉnh do cần bộ dữ liệu lớn và thời gian phát triển mở rộng. - Vẽ lại Kiến trúc AWS: Thêm GuardDuty thay thế CloudWatch Alarm - Viết bản nháp đề xuất phác thảo chức năng cơ bản và cung cấp ước tính chi phí sơ bộ. 14/10/2025 14/10/2025 4 - Họp nhóm - Sửa đổi đề xuất workshop: + Kết hợp việc sử dụng EventBridge + Tính toán lại chi phí bằng cách giảm loại EC2 instance và số giờ hoạt động - Cập nhật Kiến trúc AWS: Bao gồm biểu tượng EventBridge và các kết nối 15/10/2025 15/10/2025 5 - Cập nhật Kiến trúc AWS: + Sắp xếp lại các biểu tượng để các kết nối rõ ràng hơn. + Di chuyển SSM vào bên trong nhóm region + Thêm nhóm public subnet cho EC2 Instance - Cài đặt AmazonQ để tăng cường phân tích đề xuất - Sửa đổi đề xuất workshop: Tính toán lại chi phí bằng AWS Pricing Calculator - Dịch bản nháp đề xuất sang mã markdown và triển khai thành công lên GitHub Pages - Tham gia hội thảo trực tuyến DX Talk#7: Reinventing DevSecOps with AWS Generative AI 16/10/2025 16/10/2025 6 - Biên soạn tài liệu học tập cho kỳ thi giữa kỳ - Môn học ở trường: + ENW493c: Hoàn thành Being a researcher (in Information Science and Technology) 17/10/2025 17/10/2025 Being a researcher (in Information Science and Technology) Thành tựu Tuần 6: Tinh chỉnh Đề xuất: * Hoàn thành nhiều lần sửa đổi đề xuất workshop, chuyển từ việc sử dụng hàm Lambda tùy chỉnh sang sử dụng GuardDuty để phát hiện xâm nhập.\n* Tính toán lại thành công và giảm chi phí ước tính bằng cách tối ưu hóa loại EC2 instance và số giờ hoạt động. * Dịch sang markdown, và triển khai bản nháp đề xuất lên GitHub Pages.\nCập nhật Kiến trúc và Hệ thống: * Sửa đổi sơ đồ Kiến trúc AWS, kết hợp GuardDuty, EventBridge, và tinh chỉnh cách sắp xếp biểu tượng cùng nhóm subnet để rõ ràng và chính xác hơn.\n* Cập nhật worklog và triển khai thành công worklog đã tinh chỉnh lên GitHub Pages.\n* Cài đặt AmazonQ.\nĐã tham dự hội thảo trực tuyến \u0026lsquo;DX Talk#7: Reinventing DevSecOps with AWS Generative AI\u0026rsquo;.\nBiên soạn tài liệu học tập cho kỳ thi giữa kỳ.\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.6-parse-findings/","title":"Mã Parse Findings","tags":[],"description":"","content":" import json import logging logger = logging.getLogger() logger.setLevel(logging.INFO) def lambda_handler(event, context): instance_ids = [] detail = event.get(\u0026#39;detail\u0026#39;, {}) region = event.get(\u0026#39;region\u0026#39;) or detail.get(\u0026#39;region\u0026#39;) or \u0026#39;ap-southeast-1\u0026#39; instance_id_primary = detail.get(\u0026#39;resource\u0026#39;, {}).get(\u0026#39;instanceDetails\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if instance_id_primary: instance_ids.append(instance_id_primary) # --- 2. Extract from the older/secondary \u0026#39;resources\u0026#39; array structure --- # --- 2. Trích xuất từ cấu trúc mảng \u0026#39;resources\u0026#39; cũ/phụ --- for r in detail.get(\u0026#34;resources\u0026#34;, []): if r.get(\u0026#34;type\u0026#34;) == \u0026#34;AwsEc2Instance\u0026#34;: id_from_details = r.get(\u0026#39;details\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if id_from_details: instance_ids.append(id_from_details) else: arn_id = r.get(\u0026#39;id\u0026#39;) if arn_id and arn_id.startswith(\u0026#39;arn:aws:ec2:\u0026#39;): instance_ids.append(arn_id.split(\u0026#39;/\u0026#39;)[-1]) unique_instance_ids = list(set([id for id in instance_ids if id])) return { \u0026#34;InstanceIds\u0026#34;: unique_instance_ids, \u0026#34;Region\u0026#34;: region } "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.6-automation-setup/","title":"Thiết lập tự động hóa","tags":[],"description":"","content":"Giai đoạn 4: Thiết lập tự động hóa Tạo Isolation Security Group EC2 Console → Security Groups → Create security group Name: IR-Isolation-SG Description: Denies all inbound and outbound traffic for compromised instances (Chặn tất cả lưu lượng đi và đến cho các instance bị xâm phạm) VPC: Chọn VPC của bạn Inbound rules: Không có (từ chối tất cả - deny all) Outbound rules: Xóa mặc định (từ chối tất cả - deny all) Tạo và ghi lại Security Group ID (ví dụ: sg-0078026b70389e7b3) Tạo SNS Topic SNS Console → Create topic Type: Standard, Name: IncidentResponseAlerts Access policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;events.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sns:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:ap-southeast-1:831981618496:IncidentResponseAlerts\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;AWSEvents_IncidentResponseAlert_Target0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;events.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;SNS:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:ap-southeast-1:831981618496:IncidentResponseAlerts\u0026#34; } ] } Tạo Lambda Functions - Phản hồi sự cố (Incident Response) ir-parse-findings-lambda Handler: parse_findings.lambda_handler Role: ParseFindingsLambdaServiceRole Code: parse-findings ir-isolate-ec2-lambda Handler: isolate_ec2.lambda_handler Role: IsolateEC2LambdaServiceRole Env: ISOLATION_SG_ID=sg-XXXXXXX (từ bước 12) Code: isolate-ec2 ir-quarantine-iam-lambda Handler: quarantine_iam.lambda_handler Role: QuarantineIAMLambdaServiceRole Env: QUARANTINE_POLICY_ARN=arn:aws:iam::ACCOUNT_ID:policy/IrQuarantineIAMPolicy Code: quarantine-iam ir-alert-dispatch Handler: alert_dispatch.lambda_handler Role: AlertDispatchLambdaServiceRole Env: SENDER_EMAIL, RECIPIENT_EMAIL, SLACK_WEBHOOK_URL Add SNS trigger: Topic IncidentResponseAlerts Code: alert-dispatch Cập nhật SNS Topic Subscription SNS Console → IncidentResponseAlerts → Subscriptions Xác minh: Protocol=AWS Lambda, Endpoint=ir-alert-dispatch, Status=Confirmed Tạo Step Functions State Machine Step Functions Console → Create state machine Type: Standard, Name: IncidentResponseStepFunctions Definition: Step Functions Definition Role: StepFunctionsRole Create Tạo EventBridge Rule EventBridge Console → Rules → Create rule Name: IncidentResponseAlert Event pattern: { \u0026#34;source\u0026#34;: [\u0026#34;aws.guardduty\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;GuardDuty Finding\u0026#34;] } Targets (2): SNS topic: IncidentResponseAlerts Step Functions: IncidentResponseStepFunctions với role IncidentResponseStepFunctionsEventRole Cấu hình Athena Workgroup Athena Console → Workgroups → primary → Edit Query result location: s3://athena-query-results-ACCOUNT_ID-REGION/ Lưu (Save) "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Đánh giá thực tập Trong thời gian thực tập tại Amazon Web Services Vietnam từ 08/09/2025 đến 12/12/2025, mình đã có cơ hội học hỏi, thực hành và áp dụng kiến thức đã học ở trường vào môi trường làm việc thực tế.\nMình đã dẫn dắt nhóm và tham gia xây dựng Hệ thống Tự động Phản hồi Sự cố và Phân tích Forensics trên AWS, qua đó cải thiện kỹ năng lãnh đạo từ xa, làm việc với AWS và các dịch vụ Cloud, học và lập trình Python cho Lambda.\nVề tác phong, mình luôn cố gắng hoàn thành mọi nhiệm vụ được giao và hỗ trợ đồng đội khi có thể, tuân thủ quy định nơi làm việc, dù không làm tại văn phòng vẫn luôn làm việc từ xa và trao đổi thường xuyên.\nĐể phản ánh khách quan quá trình thực tập, mình tự đánh giá bản thân theo các tiêu chí sau:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức \u0026amp; kỹ năng chuyên môn Hiểu biết lĩnh vực, áp dụng kiến thức thực tế, thành thạo công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ✅ ☐ ☐ 3 Chủ động Tự tìm hiểu, nhận việc mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành nhiệm vụ đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, quy định, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận góp ý và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ✅ ☐ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng đội, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ✅ ☐ ☐ 11 Đóng góp dự án/nhóm Hiệu quả công việc, sáng kiến, được ghi nhận bởi nhóm ✅ ☐ ☐ 12 Tổng thể Đánh giá chung toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Dù làm việc từ xa khá ổn, năng suất tổng thể không cao như khi làm tại văn phòng Chưa giao tiếp đủ với mentor và các thành viên FCJ như mong muốn Cần học cách phân chia công việc tốt hơn, tránh ôm quá nhiều dẫn đến quá tải, may mắn là các thành viên nhóm rất chủ động và đã thúc giục mình giao thêm việc cho họ "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/4-eventparticipated/4.7-event7/","title":"Sự kiện 7","tags":[],"description":"","content":"Báo Cáo Tóm Tắt: “BUILDING AGENTIC AI - Context Optimization with Amazon Bedrock” Mục tiêu Sự kiện Phân tích chuyên sâu về kỹ thuật AWS Bedrock Agent Core Xây dựng Agentic Workflow trên AWS Giới thiệu về Diaflow Giới thiệu về CloudThinker CloudThinker Agentic Orchestration, Context Optimization trên Amazon Bedrock CloudThinker Hack: Workshop Thực hành Diễn giả Nguyen Gia Hung - Head of Solutions Architect AWS\nKien Nguyen - AWS Startup Solutions Architect\nViet Pham - CEO \u0026amp; Founder of Diaflow\nThang Ton - Co-Founder \u0026amp; COO CloudThinker\nHenry Bui - Head of Engineering CloudThinker Van Hoang Kha - AWS Comumnity Leaders\nNhat Tran - CTO CloudThinker\nĐiểm nhấn chính Amazon Bedrock AgentCore Sự phát triển thành Agentic AI: Số lượng doanh nghiệp sử dụng hệ thống Agentic AI đang gia tăng =\u0026gt; AWS cung cấp nơi tốt nhất để xây dựng và mở rộng AI Agents AWS cung cấp những gì?\nFrameworks để xây dựng agents: Strands, Langgraph, OpenAI, v.v. Ứng dụng: Kiro, AWS QuickSuite Amazon Sagemaker Amazon Bedrock Models và AgentCore Amazon Bedrock AgentCores là gì?\nRuntime: Triển khai agent serverless, an toàn =\u0026gt; Mở rộng khối lượng công việc và tăng tốc thời gian đưa ra thị trường Identity: Quản lý danh tính và truy cập agent cấp doanh nghiệp =\u0026gt; Tăng tốc phát triển và bảo mật truy cập cho AI Agents và xây dựng trải nghiệm AI Agent hợp lý Gateway: Truy cập công cụ hợp nhất, an toàn =\u0026gt; Phát triển đơn giản và truy cập công cụ an toàn, với khám phá công cụ thông minh Memory: Lưu giữ bộ nhớ nhận biết ngữ cảnh thông minh =\u0026gt; Đơn giản hóa quản lý bộ nhớ của dữ liệu cấp doanh nghiệp với tùy chỉnh sâu Browser: Runtime browser cloud có khả năng mở rộng: Cung cấp cơ sở hạ tầng browser serverless với bảo mật và khả năng quan sát cấp doanh nghiệp Code Interpreter: Thực thi mã trong sandbox an toàn =\u0026gt; Thực thi mã an toàn, cung cấp xử lý dữ liệu quy mô lớn và dễ sử dụng Observability: Khả năng hiển thị hiệu suất agent hoàn chỉnh =\u0026gt; Duy trì chất lượng tin cậy và tăng tốc thời gian đưa ra thị trường, cho phép tích hợp với các công cụ observability khác Diaflow: Khuếch đại tiềm năng của đội ngũ bằng Tự động hóa AI Diaflow là một Nền tảng Tự động hóa AI cho Doanh nghiệp với sứ mệnh khai phá toàn bộ tiềm năng của các đội ngũ bằng cách cung cấp các công cụ mạnh mẽ, linh hoạt để tự động hóa những gì quan trọng nhất—nhanh chóng và không cần mã\nChuyển đổi các quy trình thủ công thành các quy trình làm việc thông minh trong vài phút, không phải vài tháng =\u0026gt; giải quyết hơn 20 giờ/tuần/người lãng phí vào các tác vụ lặp đi lặp lại trong 90% doanh nghiệp, và các mối lo ngại về quyền riêng tư và bảo mật dữ liệu khi triển khai AI nội bộ\nKhách hàng: Hơn 6000 người dùng từ các khách hàng toàn cầu trên nhiều ngành khác nhau, bao gồm Bán lẻ, Dịch vụ IT, Tài chính, Tiếp thị và Chăm sóc sức khỏe.\nĐược Hỗ trợ Bởi: Được phát triển bởi các chuyên gia từ các tổ chức công nghệ và học thuật lớn và được tài trợ/hỗ trợ bởi các đối tác chính như NVIDIA, Microsoft, AWS và Google.\nĐịa điểm: Mỹ, Thụy Sĩ, Pháp, Hàn Quốc, Singapore và Việt Nam.\nKhả năng của Diaflow Tự động hóa hỗ trợ bởi AI (AI-Powered Automation): Giảm 80% các tác vụ thủ công bằng cách kết nối Databases, Apps, Knowledge bases, APIs và Legacy systems\nAI Agents: Triển khai hỗ trợ thông minh 24/7\nInternal AI Tools \u0026amp; Apps: Triển khai các ứng dụng hỗ trợ AI được điều chỉnh cho các nhu cầu kinh doanh cụ thể.\nTính năng của Diaflow Thực thi Tác vụ Tự động (Autonomous Task Execution): Mô tả mục tiêu của bạn, Diaflow sẽ lập kế hoạch và thực thi nó\nXử lý Đa Mô hình (Multi-Model Processing): Chọn từ Claude, Gemini, Deepseek, v.v.\nTích hợp với các công cụ có thể sử dụng: Built-in Drive, Pages, Table và Vector\nBảo mật Cấp Doanh nghiệp (Enterprise-Grade Security): HIPAA, SOC2 và GDPR\nCloudThinker Một số vấn đề đối với khách hàng sử dụng nền tảng cloud: Chi phí Cloud tăng vọt, Độ phức tạp của Cloud \u0026gt; Khả năng của Cloud và Ứng phó Sự cố Phản ứng (Reactive Incident Response)\nKhả năng của CloudThinker Vận hành Cloud bằng Agentic AI: Insights -\u0026gt; Reasoning -\u0026gt; Execution\nCộng tác Đa Agent (Multi-agent Collaboration) Vận hành Tự động (Autonomous Operations) Tối ưu hóa Liên tục (Continuous Optimization) Học hỏi Liên tục (Continuous Learning) Khả năng Đa Cloud (Multi-cloud Capability) Tính năng Sản phẩm của CloudThinker Code review Incident Response Operation Automation Infastructure Observability Kubernetes Management (Sắp ra mắt) Cloud Keeper (Sắp ra mắt) Giải pháp của CloudThinker Cloud Migration \u0026amp; Modernization Cloud Operation \u0026amp; Optimization Compliance Readiness Security Assessment Đội ngũ AI Agent của CloudThinker Alex: Cloud Engineer Kai: Kubenetes Engineer Anna: General Manager Oliver: Security Engineer Tony: Database Engineer CloudThinker Agentic Orchestration và Context Optimization trên Amazon Bedrock Sự phát triển và Kiến trúc AI Agent Chatbots: Phản ứng (Reactive), sử dụng các quyết định dựa trên quy tắc cho các tác vụ đơn giản và có khả năng thích ứng hạn chế.\nAgents: Chủ động (Proactive), có khả năng khởi tạo hành động, đưa ra các quyết định động và phức tạp, và thích ứng bằng cách học hỏi từ kinh nghiệm để xử lý các tác vụ phức tạp, nhiều bước.\nCác Thành phần Kiến trúc Core Agent Core: + Planning: Chia nhỏ tác vụ và tạo các bước.\n+ Memory: Nhớ lại ngữ cảnh và các tương tác.\n+ Tools: Sử dụng API bên ngoài, tìm kiếm và mã.\n+ Action: Thực thi kế hoạch và cung cấp phản hồi cuối cùng.\nBắt đầu với Agents Kiến trúc ReAct Agent: Lồng ghép suy nghĩ và hành động cho các tác vụ phức tạp =\u0026gt; User Input → Reasoning (Thought) → Action (Tool Use) → Observation → Final Answer.\nEvals \u0026amp; Observability từ Ngày 1\nTận dụng tools: Các tools hiệu quả có Agent Context, quy trình làm việc đa dạng, giải quyết vấn đề trực quan và có kiểm thử trong thế giới thực\nCác kỹ thuật thắng nhanh (Quick win techniques): Prompt Caching -\u0026gt; Context Compaction -\u0026gt; Tool Consolidation -\u0026gt; Parallel tool calling\nMulti-Agent so với Multi Session: Giải quyết các Nút thắt Đơn Agent Các hệ thống Đơn Agent (Single-Agent systems): xử lý tất cả các tác vụ một cách monolithic, đối mặt với các vấn đề như cô lập ngữ cảnh (100k+ tokens), xử lý tuần tự và các vấn đề đa lô (multi-batch). Điều này dẫn đến hai mô hình cho điều phối phân tán: Đa Agent (Multi-Agent) và Đa Phiên (Multi-Session).\nCác Mô hình Phối hợp Agent Tính năng Network (Peer-to-Peer) Supervisor Cấu trúc Agents giao tiếp trực tiếp với nhau. Một Supervisor trung tâm ủy quyền các tác vụ cho các Worker agent chuyên biệt. Ưu điểm * Giao tiếp linh hoạt. * Khả năng chịu lỗi tốt. * Dễ dàng chuyển từ chế độ đơn agent sang đa agent. * Ủy quyền tác vụ rõ ràng. * Điều phối trung tâm. * Modular và có khả năng mở rộng. Nhược điểm * Debugging phức tạp. * Mơ hồ về quyền sở hữu. * Nguy cơ tắc nghẽn. * Không thể chuyển sang chế độ đơn agent. Các Biến thể Supervisor: Ba Phương pháp Phương pháp Group Chat-based Supervisor Supervisor as Tool (Subagents) Hierarchical Ghi chú Ngữ cảnh cộng tác, điều phối đơn giản, Tốt nhất cho các đội ngũ nhỏ. CloudThinker sử dụng phương pháp này. Kiểm soát chi tiết (Fine-grained control), quyền tự chủ của worker ít hơn, không có quyền truy cập trực tiếp của người dùng. Mở rộng quy mô cho các tổ chức lớn, nhiều lớp giám sát, thiết lập phức tạp hơn. Đơn Agent và Đa Agent trong một Kiến trúc Hợp nhất: Kiến trúc hợp nhất định tuyến động các tác vụ đến các agents thích hợp: Sử dụng Supervisor để điều phối đa agent và thử lại (retry).\nĐịnh tuyến tác vụ được xác định bởi độ phức tạp và khả năng của agent: + Các yêu cầu đơn giản được gửi trực tiếp đến các chuyên gia + Các tác vụ phức tạp yêu cầu phối hợp được chuyển cho Supervisor. + Các tác vụ đơn giản mà một agent có thể tự xử lý được quản lý bởi agent đó. + Các tác vụ đơn giản yêu cầu cộng tác được xử lý thông qua Group Chat. + Một agent chuyên gia mặc định xử lý các yêu cầu khi không có agent cụ thể nào được đề cập\nGiải quyết Vấn đề Chi phí Agentic 100:1 Các Kiến trúc Agentic đối mặt với \u0026ldquo;Bùng nổ Ngữ cảnh (Context Explosion)\u0026rdquo; nơi tỷ lệ Input/Output token có thể là 100:1, so với khoảng 3:1 đối với chatbots. Chi phí Input chiếm ưu thế do 50–100 cuộc gọi tool cho mỗi tác vụ, làm suy giảm ngữ cảnh và độ trễ.\n=\u0026gt; Bốn Kỹ thuật Thắng nhanh: Tổng tiết kiệm 80–95% và giảm độ trễ 3–5 lần:\nPrompt Caching: + Mục tiêu: Đạt được giảm chi phí 70–90% và tỷ lệ truy cập bộ nhớ đệm 95%+.\n+ Phương pháp: Sử dụng Kiến trúc Ba Lớp (Three-Tier Architecture) nơi System Prompt (Lớp 1) và Lịch sử Cuộc trò chuyện (Lớp 2) được lưu vào bộ nhớ đệm, trong khi lượt hiện tại (Lớp 3) thì không, bảo tồn khả năng thích ứng từng lượt.\nContext Compaction: + Mục tiêu: Giảm chi phí tóm tắt 80% và duy trì các phiên dài hơn.\n+ Phương pháp: Tóm tắt Bảo tồn Bộ nhớ đệm (Cache-Preserving Summarization) thêm các hướng dẫn tóm tắt ở cấp độ payload để bảo tồn các khóa bộ nhớ đệm, tóm tắt các tin nhắn cũ để bảo tồn ngữ cảnh mà không vượt giới hạn.\nTool Consolidation: + Mục tiêu: Giảm 20% số lượng token và hallucination, dẫn đến thời gian quyết định nhanh hơn.\n+ Vấn đề Ô nhiễm Công cụ (Tool Pollution Problem): Quá nhiều định nghĩa tool (ví dụ: 50) làm tràn cửa sổ ngữ cảnh.\n+ Phương pháp: Hợp nhất các thao tác CRUD thành các giao diện đơn lẻ với các tham số dựa trên lệnh, sử dụng Just-In-Time Schemas để tìm nạp tài liệu chỉ khi cần.\nParallel Tool Calling: + Mục tiêu: Giảm 30–40% số lần khứ hồi năng lượng (power round trips) và giảm độ trễ 3–5 lần.\n+ Phương pháp: Sử dụng hướng dẫn rõ ràng để song song hóa các cuộc gọi tool và các bước lý luận, điều này là cần thiết vì các LLM hiện đại có thể song song hóa nhưng sẽ không làm nếu không có hướng dẫn rõ ràng.\nCross-Region Inference (Suy luận Xuyên Khu vực) Vấn đề: Các triển khai Đơn khu vực có thể gặp giới hạn tốc độ (rate limits) do 50–100 cuộc gọi tool cho mỗi tác vụ, tạo ra một điểm lỗi duy nhất. =\u0026gt; Giải pháp: Tự động định tuyến khối lượng công việc qua các khu vực (Mỹ, EU, APAC) để loại bỏ các nút thắt giới hạn tốc độ và cung cấp một hồ sơ toàn cầu cho độ trễ gần như bằng không và thông lượng được cải thiện.\nHệ thống đa agent tốt nhất sẽ tự nhận ra KHI NÀO KHÔNG nên sử dụng nhiều agents. CloudThinker Hack: Hands-On Workshop Ban tổ chức cung cấp cho người tham dự hướng dẫn CloudThinker và Free Standard Plan Code để sử dụng trong việc phân tích Tài khoản AWS Trải nghiệm Sự kiện Sự kiện này rất nhiều thông tin và củng cố sự hiểu biết của chúng tôi về Amazon Bedrocks và giới thiệu cho chúng tôi Diaflow và CloudThinker, hai AI Agents Tools vô cùng hữu ích\nTham gia CloudThinker Hack: Hands-On Workshop: Đã sử dụng CloudThinker để phân tích cơ sở hạ tầng Tài khoản AWS của chúng tôi =\u0026gt; Đã phân tích lượng lớn yêu cầu S3 Bucket GET requests bất thường của chúng tôi (3 triệu trong 2 tuần) và giải quyết bằng cách đề xuất chúng tôi sử dụng Data Firehose để hợp nhất logs trước khi lưu\n=\u0026gt; Nhóm chúng tôi đã nhận được một giải thưởng vì sử dụng CloudThinker để phân tích vấn đề của chúng tôi: CloudThinker T-Shirt và CloudThinker Keychain\nMột số hình ảnh sự kiện Hình ảnh tất cả người tham dự\nNhận giải thưởng từ CloudThinker\nNhận giải thưởng từ CloudThinker\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/1.7-week7/","title":"Nhật ký Công việc Tuần 7","tags":[],"description":"","content":"Mục tiêu Tuần 7: Kết nối và làm quen với các thành viên của First Cloud Journey. Hiểu các dịch vụ AWS cơ bản, cách sử dụng console \u0026amp; CLI. Các nhiệm vụ được thực hiện trong tuần này: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Học các kiến thức cơ bản về GuardDuty với \u0026ldquo;Getting Hands on with Amazon GuardDuty - AWS Virtual Workshop\u0026rdquo; - Làm quen với GuardDuty bằng cách sử dụng Amazon Q để tạo một lab cơ bản: + Tạo sample finding qua cài đặt + Học giao diện finding + Kiểm thử EC2 bằng cách quét cổng scanme.nmap.org + Mô phỏng DNS exfiltration trên EC2 + GuardDuty không cảnh báo findings từ VPC Flow Logs như mong đợi + Kích hoạt GuardDuty findings thông qua CloudTrail bằng cách truy cập API ListPolicies bằng thông tin xác thực root - Học thêm bằng cách làm các workshop GuardDuty - Họp nhóm trực tuyến: Phân công các thành viên nghiên cứu các dịch vụ sẽ được sử dụng trong workshop 20/10/2025 20/10/2025 Getting Hands on with Amazon GuardDuty - AWS Virtual Workshop GuardDuty Workshop 3 - Kích hoạt thành công các cảnh báo mẫu GuardDuty với nhiều mức độ nghiêm trọng và loại khác nhau qua CloudShell CLI =\u0026gt; Môi trường kiểm thử dễ dàng hơn - Tạo một danh sách mối đe dọa tùy chỉnh (custom threat list) gồm các IP và tên miền cho GuardDuty qua các lệnh CloudShell mặc dù nó không hoạt động 21/10/2025 21/10/2025 4 - Họp nhóm: + Ôn tập nhanh kiến thức AWS Services + Thảo luận về các thay đổi trong đề xuất - Cập nhật Kiến trúc AWS: Thêm AWS Detective - Sửa đổi đề xuất: + Thêm việc sử dụng AWS Detective + Thêm kế hoạch cho CDK sau khi hoàn thành workshop - Đề xuất của cố vấn: + Trực quan hóa dữ liệu nhưng không sử dụng QuickSight, thay vào đó tạo một custom-coded dashboard (Đang nghiên cứu) + Lưu GuardDuty findings trong S3 bucket để phân tích (Đang nghiên cứu) - Cấu hình thành công EventBridge để kích hoạt khi có các GuardDuty findings cụ thể và: + Gửi SNS emails đến tất cả các thành viên trong nhóm + Kích hoạt một Lambda script đơn giản - Xây dựng ý tưởng bổ sung cho workshop: Tạo một trang đồ thị dữ liệu đơn giản được host trong S3 và sử dụng API Gateway và Lambda để kéo dữ liệu forensics từ Amazon Athena (Đang nghiên cứu) 22/10/2025 22/10/2025 5 - Thử AWS Card Clash với các thành viên trong nhóm: Bất ngờ là công cụ tốt để học về các dịch vụ và chức năng của chúng, vị trí của chúng trong Kiến trúc - Ôn tập Kiến thức AWS Services cho Giữa kỳ: Sử dụng Google Gemini để tạo các bài quiz dựa trên các yêu cầu được cung cấp 23/10/2025 23/10/2025 AWS Card Clash 6 - Cấu hình thành công danh sách mối đe dọa (threat list) của GuardDuty để kích hoạt findings từ các hoạt động của EC2 Instance 24/10/2025 26/10/2025 - Môn học ở trường: + KS57: Hoàn thành Pháp luật và đạo đức trong công nghệ số Pháp luật và đạo đức trong công nghệ số Thành tựu Tuần 7: Thực hành GuardDuty: * Hoàn thành \u0026ldquo;Getting Hands on with Amazon GuardDuty - AWS Virtual Workshop\u0026rdquo; và một lab chuyên sâu được tạo bằng Amazon Q.\n* Tạo, kiểm thử và kích hoạt thành công nhiều GuardDuty findings khác nhau thông qua cài đặt console, hoạt động EC2 và truy cập API CloudTrail.\n* Thiết lập một môi trường kiểm thử dễ dàng hơn bằng cách kích hoạt thành công các cảnh báo mẫu với các mức độ nghiêm trọng và loại khác nhau qua CloudShell CLI.\n* Cấu hình thành công GuardDuty threat list để kích hoạt findings từ các hoạt động của EC2 Instance.\nPhát triển Đề xuất Workshop và Kiến trúc: * Cập nhật đề xuất và Kiến trúc AWS để tích hợp AWS Detective cho khả năng điều tra sâu hơn.\n* Thêm kế hoạch triển khai CDK sau khi hoàn thành workshop.\n* Bắt đầu nghiên cứu các đề xuất của cố vấn, bao gồm custom-coded data visualization và lưu GuardDuty findings vào S3 để phân tích.\n* Xây dựng một ý tưởng workshop mới về một trang data graphing đơn giản được host trong S3 sử dụng API Gateway và Lambda.\nTích hợp Dịch vụ và Tự động hóa: * Cấu hình thành công EventBridge để hành động dựa trên các GuardDuty findings cụ thể.\n* Tự động hóa thông báo bằng cách gửi SNS emails đến các thành viên trong nhóm và kích hoạt một Lambda script dựa trên cảnh báo GuardDuty.\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên FCJ luôn sẵn sàng giúp đỡ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc thoải mái giúp mình tập trung tốt hơn. Tuy nhiên, do số lượng sinh viên lớn, cơ hội làm việc tại văn phòng khá ít, nên phần lớn chúng mình làm việc từ xa.\n2. Sự hỗ trợ từ mentor / quản trị viên nhóm\nMentor rất nhiệt tình hỗ trợ dự án và các câu hỏi của chúng mình, tổ chức các Workshop và sự kiện để cung cấp kiến thức quan trọng.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nDịch vụ AWS và các dịch vụ Cloud khác gần như hoàn toàn mới với mình trước khi thực tập tại AWS FCJ, nhưng kỳ thực tập đã giúp mình học hỏi rất nhiều về Cloud và nhận ra tầm quan trọng của nó với chuyên ngành. Dự án của mình: Hệ thống Tự động Phản hồi Sự cố và Phân tích Forensics trên AWS phù hợp với lĩnh vực An toàn Thông tin-khác với ngành Công nghệ thông tin bình thường- nhưng vẫn là trải nghiệm học tập tuyệt vời về bảo mật tổng thể và thực hành với các dịch vụ AWS.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình đã học được nhiều kỹ năng mới như: Làm việc với AWS và các dịch vụ Cloud, lập trình Python cho dự án, nâng cao kỹ năng lãnh đạo khi dẫn dắt dự án và thành viên nhóm dù chủ yếu làm việc từ xa.\n5. Văn hóa công ty \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng nhau, làm việc nghiêm túc nhưng vẫn vui vẻ, nhiều mentor trẻ tuổi và thân thiện. Mình rất trân trọng các thành viên trong nhóm, ai cũng chủ động, ham học hỏi và hoàn thành nhiệm vụ tốt nhất có thể. Chúng mình cũng quan tâm đến nhau, không chỉ về công việc mà còn về sức khỏe, đặc biệt ở giai đoạn cuối dự án, ai cũng cố gắng hoàn thành đúng hạn.\n6. Chính sách / phúc lợi thực tập\nCông ty cho phép làm việc linh hoạt khi cần, cho phép làm việc từ xa. Ngoài ra, công ty giới thiệu về AWS Study Group và tổ chức các sự kiện về nội dung quan trọng trong lĩnh vực.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\nTrả lời: Tìm hiểu cách làm việc với các dịch vụ AWS và cấu hình chính sách đúng khi xây dựng dự án.\nĐiều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau?\nTrả lời: Có thêm không gian làm việc tại văn phòng sẽ tốt hơn, nhưng điều này khó thực hiện. Một điểm nữa là bài kiểm tra giữa kỳ, hầu hết chúng mình đánh giá thấp phạm vi đề thi, không biết nó sẽ giống định dạng bài thi SAA. Nếu biết trước phạm vi lớn như vậy, chúng mình sẽ chuẩn bị tốt hơn.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\nTrả lời: Có, nhưng chỉ khi bạn đã có nhóm tốt và đủ kỷ luật để làm việc từ xa. Mình thấy một số thực tập sinh OJT gặp khó khăn vì chọn nhóm ngẫu nhiên nên có ít sự hỗ trợ và trao đổi với nhau.\nĐề xuất \u0026amp; mong muốn - Bạn có muốn tiếp tục chương trình này trong tương lai? - Trả lời: Có, nhóm mình sẵn sàng tiếp tục nếu có cơ hội. "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.7-isolate-ec2/","title":"Mã Isolate EC2","tags":[],"description":"","content":" import json import boto3 import os from botocore.exceptions import ClientError ISOLATION_SG_ID = os.getenv(\u0026#39;ISOLATION_SG_ID\u0026#39;) def lambda_handler(event, context): print(\u0026#34;=== ISOLATE EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) instance_id = event.get(\u0026#39;InstanceId\u0026#39;) region = event.get(\u0026#39;Region\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) if not instance_id or not ISOLATION_SG_ID: print(\u0026#34;[ERROR] Missing InstanceId or IsolationSGId in input. Cannot isolate.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: \u0026#34;Missing input data\u0026#34;} try: ec2 = boto3.client(\u0026#39;ec2\u0026#39;, region_name=region) response = ec2.describe_instances(InstanceIds=[instance_id]) instance = response[\u0026#39;Reservations\u0026#39;][0][\u0026#39;Instances\u0026#39;][0] current_sgs = [sg[\u0026#39;GroupId\u0026#39;] for sg in instance.get(\u0026#39;SecurityGroups\u0026#39;, [])] if ISOLATION_SG_ID in current_sgs: print(f\u0026#34;[INFO] {instance_id} already has isolation SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;already_isolated\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: None } print(f\u0026#34;[ACTION] Isolating {instance_id} in {region} with SG {ISOLATION_SG_ID}\u0026#34;) ec2.modify_instance_attribute( InstanceId=instance_id, Groups=[ISOLATION_SG_ID] ) print(f\u0026#34;[SUCCESS] {instance_id} isolated with SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;isolation_complete\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: ISOLATION_SG_ID } except ClientError as e: error_code = e.response.get(\u0026#39;Error\u0026#39;, {}).get(\u0026#39;Code\u0026#39;) print(f\u0026#34;[ERROR] Isolation FAILED for {instance_id} ({error_code}): {str(e)}\u0026#34;) return { \u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: str(e) } except Exception as e: print(f\u0026#34;[ERROR] Isolation FAILED (General) for {instance_id}: {str(e)}\u0026#34;) raise e "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/","title":"Thiết lập Dashboard","tags":[],"description":"","content":"Hướng dẫn này sẽ chỉ cho bạn cách thiết lập security dashboard. Security dashboard sẽ sử dụng S3 để chứa các file và thư mục web, Lambda để truy vấn dữ liệu bằng Athena, API Gateway để định tuyến api tới Lambda và Cloudfront để caching và truy cập web bằng URL của nó.\nNội dung Thiết lập S3 Thiết lập Lambda Thiết lập API Gateway Thiết lập Cloudfront Thiết lập Cognito "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/1.8-week8/","title":"Nhật ký Công việc Tuần 8","tags":[],"description":"","content":"Mục tiêu Tuần 8: Ôn tập kiến thức AWS. Hoàn thành kỳ thi Giữa kỳ FCJ (FCJ Mid-Term exam). Các nhiệm vụ được thực hiện trong tuần này: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Xem lại các video học tập của FCJ Bootcamp - Hoàn thành AWS Cloud Essentials Quiz - Phân tích sâu các dịch vụ AWS đã học trước đây và so sánh các dịch vụ tương tự với nhau - Xem qua một số AWS Well-Architected Labs để hiểu rõ hơn về từng trụ cột chính - Export log streams thành công sang S3 - Tạo trail trên CloudTrail thành công để theo dõi các hoạt động của S3 và Lambda - Kiến trúc AWS: + Nghiên cứu cách tích hợp AWS Step Functions vào kiến trúc workshop, thay vì chỉ sử dụng một Lambda cho tất cả các hành động IR + Cân nhắc sử dụng AWS Kinesis Data Firehose để stream log liên tục đến S3 27/10/2025 27/10/2025 AWS Cloud Essentials Quiz AWS Well Architected Lab 3 - Tạo 500 AWS Flashcards cùng với các thành viên trong nhóm để học 28/10/2025 28/10/2025 4 - Học cho kỳ thi Giữa kỳ - Môn học ở trường: + ENW493c: Hoàn thành Introduction to Research for Essay Writing 29/10/2025 29/10/2025 Introduction to Research for Essay Writing 5 - Luyện tập sử dụng các ghi chú AWS Certified Cloud Practitioner của những người học khác trên mạng: Đã làm 5 bài kiểm tra thực hành - Luyện tập sử dụng các câu hỏi thực hành AWS Certified Solutions Architect Associate: Đã luyện tập 40 câu hỏi 30/10/2025 30/10/2025 AWS Certified Cloud Practitioner notes AWS Certified Solutions Architect Associate practice 6 - Tham gia FCJ Midterm Exam: Lọt vào top 10 của phiên thi thứ hai, đạt điểm 320/650 31/10/2025 31/10/2025 Thành tựu Tuần 8: Kỳ thi Giữa kỳ FCJ: * Hoàn thành luyện tập chuyên sâu bằng cách làm năm bài kiểm tra thực hành AWS Certified Cloud Practitioner và trả lời 40 câu hỏi thực hành AWS Certified Solutions Architect Associate. * Cộng tác với các thành viên trong nhóm để tạo 500 AWS Flashcards để học tập trung. * Hoàn thành AWS Cloud Essentials Quiz và xem lại các video học tập của FCJ Bootcamp. * Tham gia thành công FCJ Midterm Exam và đạt điểm 320/650. * Ôn tập các dịch vụ AWS chính và các AWS Well-Architected Labs để hiểu các trụ cột chính.\nNghiên cứu Kiến trúc Workshop: * Nghiên cứu tích hợp kiến trúc của AWS Step Functions để điều phối các hành động Ứng phó Sự cố (Incident Response), thay thế một hàm Lambda đơn lẻ. * Thực hiện thành công các tác vụ logging nền tảng bằng cách export log streams sang S3 và tạo CloudTrail để theo dõi các hoạt động của S3 và Lambda. * Khám phá việc sử dụng AWS Kinesis Data Firehose để stream log liên tục, đáng tin cậy đến S3. "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.8-verify-setup/","title":"Kiểm tra thiết lập","tags":[],"description":"","content":"Sau tất cả các giai đoạn thiết lập, vui lòng tham khảo checklist để đảm bảo việc tạo tài nguyên đã hoàn tất.\nXác minh thiết lập Checklist xác minh hoàn thành:\nIncident Response and Forensics:\n✅ S3 Buckets: Tất cả 5 buckets đã được tạo với versioning/encryption ✅ IAM Roles: Tất cả 17 roles với đúng policies ✅ CloudTrail: Logging đã được bật ✅ GuardDuty: Đã bật với S3 export ✅ VPC Flow Logs: Đang hoạt động (Active) ✅ Lambda Functions: Tất cả 9 functions đã deploy ✅ Firehose Streams: Tất cả 3 streams đang hoạt động ✅ Glue Tables: Tất cả 4 tables đã được tạo ✅ S3 Events: Tất cả 4 triggers đã được cấu hình ✅ SNS Topic: Đã tạo với subscription ✅ Step Functions: Đang hoạt động (Active) ✅ EventBridge Rule: Đã bật với 2 targets Security Dashboard:\n✅ S3 Buckets: Bucket đã được tạo với file dashboard được lưu trữ và bật hosting ✅ Query Lambda: Lambda đã được tạo với các roles thích hợp ✅ API Gateway: API Gateway đã được tạo với đúng API và tài nguyên ✅ CloudFront: Distribution đã được tạo với API và S3 origins đã cấu hình ✅ Cognito: Đã liên kết với CloudFront distribution và tạo user trong user pool Kiểm tra đầu cuối (End-to-End Test)\nTạo mẫu các phát hiện GuardDuty: 1.1 GuardDuty Console → Settings → Generate sample findings (200+ findings) hoặc 1.2 Kích hoạt một finding đơn lẻ qua CloudShell (Detector Id nằm trong GuardDuty Console → Settings ) aws guardduty create-sample-findings --detector-id [$dectector-id] --finding-types \u0026#34;Recon:EC2/PortProbeUnprotectedPort\u0026#34; Giám sát workflow: Kiểm tra EventBridge, SNS, Step Functions, Lambda logs Xác minh cảnh báo: Kiểm tra email và Slack Truy vấn dữ liệu trong Athena: "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.8-quarantine-iam/","title":"Mã Quarantine IAM","tags":[],"description":"","content":" import json import boto3 import os QUARANTINE_POLICY_ARN = os.environ.get(\u0026#34;QUARANTINE_POLICY_ARN\u0026#34;) def lambda_handler(event, context): print(\u0026#34;=== EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) try: finding = event.get(\u0026#39;detail\u0026#39;, {}) user_name = ( finding.get(\u0026#39;resource\u0026#39;, {}) .get(\u0026#39;accessKeyDetails\u0026#39;, {}) .get(\u0026#39;userName\u0026#39;) ) if not user_name: print(\u0026#34;[WARNING] No IAM user found in this finding. Skipping.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;no_user\u0026#34;} print(f\u0026#34;[ACTION] Quarantining IAM User \u0026#39;{user_name}\u0026#39;...\u0026#34;) iam = boto3.client(\u0026#39;iam\u0026#39;) # Kiểm tra nếu policy đã được gán (Check if policy is already attached) attached_policies = iam.list_attached_user_policies(UserName=user_name)[\u0026#39;AttachedPolicies\u0026#39;] policy_arns = [p[\u0026#39;PolicyArn\u0026#39;] for p in attached_policies] if QUARANTINE_POLICY_ARN in policy_arns: print(f\u0026#34;[INFO] Policy {QUARANTINE_POLICY_ARN} is already attached to user {user_name}.\u0026#34;) else: iam.attach_user_policy( UserName=user_name, PolicyArn=QUARANTINE_POLICY_ARN ) print(f\u0026#34;[SUCCESS] Policy attached. User {user_name} is now quarantined.\u0026#34;) except Exception as e: print(f\u0026#34;[ERROR] Failed to quarantine user: {str(e)}\u0026#34;) raise e return {\u0026#34;status\u0026#34;: \u0026#34;processed\u0026#34;, \u0026#34;action\u0026#34;: \u0026#34;iam_quarantined\u0026#34;} "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/1.9-week9/","title":"Nhật ký Công việc Tuần 9","tags":[],"description":"","content":"Mục tiêu Tuần 9: Tiếp tục thực hiện workshop Các nhiệm vụ được thực hiện trong tuần này: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Sửa đổi Kiến trúc AWS (AWS Architecture revised): + Loại bỏ AWS Detective + Cập nhật với Step Function Workflow thay vì một AWS Lambda Function đơn lẻ + Thêm Custom Dashboard (Dashboard Tùy chỉnh): Một trang web static custom dashboard được host bằng S3 và sử dụng Athena để truy vấn từ data lake - Môn học ở trường: + KS57: Hoàn thành Quản trị dự án và duy trì đổi mới trong chuyển đổi số 03/11/2025 03/11/2025 Quản trị dự án và duy trì đổi mới trong chuyển đổi số 3 - Export GuardDuty Findings thành công sang S3 Bucket - Thử nghiệm với AWS Glue Crawler: + Thất bại trên CloudWatch và CloudTrail logs, schema quá phức tạp đối với Crawler (Cần nghiên cứu cách thay thế) + Chạy thành công trên các GuardDuty Findings đã được export: Phải cập nhật KMS Policy để cho phép Crawler giải mã dữ liệu - Nghiên cứu ETL Pipeline cho logs 04/11/2025 04/11/2025 4 - Họp nhóm: Báo cáo tiến độ: + IR Workflow: Hoàn thành một nửa, chức năng cách ly EC2 (EC2 quarantine function) đã xong, chưa kiểm thử với findings + Giao nhiệm vụ thiết kế frontend dashboard + Giao nhiệm vụ nghiên cứu Glue ETL Pipeline + Đăng ký tham gia VPBank Cloud Day 2025 cùng các thành viên trong nhóm 05/11/2025 05/11/2025 5 - Họp nhóm - Nghiên cứu phương pháp tiếp cận ETL Pipeline: + Thay vì sử dụng Glue ETL Jobs, chúng tôi sử dụng một custom Lambda ETL pipeline cho CloudTrail và CloudWatch logs + Lưu raw logs vào một Raw Log S3 Bucket sau đó sử dụng ETL Lambda để xử lý dữ liệu và ghi nó vào một Processed Data S3 để sau đó được Crawl - Sửa đổi Kiến trúc AWS: Thêm một nhóm mới: nhóm DATA PREP chứa Raw Log S3 Bucket và ETL Lambda - Môn học ở trường: + ENW493c: Hoàn thành Advanced Writing 06/11/2025 06/11/2025 Advanced Writing 6 - Nghiên cứu Kinesis Data Firehose để thu thập logs: Tốt cho việc sử dụng trong tương lai, không phù hợp cho dự án hiện tại vì real-time streaming data không cần thiết, sử dụng batch processing tốt hơn - Xây dựng thành công ETL Pipeline cho CloudTrail logs: Được kích hoạt bởi việc tạo object trong CloudTrail Raw Log Bucket và định dạng lại raw logs thành JSONL và lưu nó vào Processed S3 - Crawl và truy vấn thành công log đã xử lý để hiển thị CloudTrail Events 07/11/2025 07/11/2025 Thành tựu Tuần 9: Tinh chỉnh Kiến trúc: * Cập nhật cơ chế Ứng phó Sự cố (IR) để sử dụng Step Functions Workflow thay vì một hàm Lambda đơn lẻ.\n* Giới thiệu Custom Dashboard (trang web tĩnh được host trên S3) sử dụng Athena để truy vấn data lake. * Tạo một nhóm DATA PREP mới trong kiến trúc, bao gồm Raw Log S3 Bucket và ETL Lambda để quản lý chuyển đổi log.\nCấu hình thành công pipeline để export GuardDuty Findings sang S3 Bucket.\nXây dựng và triển khai custom ETL Lambda pipeline để xử lý CloudTrail logs, được kích hoạt bởi các object mới trong Raw Log S3 Bucket.\nCrawl và truy vấn thành công CloudTrail logs đã xử lý bằng Glue/Athena để hiển thị CloudTrail Events.\nCác thành viên trong nhóm đã hoàn thành một nửa IR Step Functions Workflow, với chức năng cách ly EC2 (EC2 quarantine function) đã xong.\nGiao nhiệm vụ thiết kế frontend dashboard và nghiên cứu Glue ETL Pipeline.\nĐã đăng ký tham gia sự kiện VPBank Cloud Day 2025 cùng các thành viên trong nhóm.\n"},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.9-alert-dispatch/","title":"Mã Alert Dispatch","tags":[],"description":"","content":" import os import json import logging import urllib.request import boto3 from botocore.exceptions import ClientError import html # --- Telegram ENV --- # BOT_TOKEN = os.environ.get(\u0026#39;BOT_TOKEN\u0026#39;) # CHAT_ID = os.environ.get(\u0026#39;CHAT_ID\u0026#39;) # MESSAGE_THREAD_ID = os.environ.get(\u0026#39;MESSAGE_THREAD_ID\u0026#39;) # --- Slack ENV --- SLACK_WEBHOOK_URL = os.environ.get(\u0026#34;SLACK_WEBHOOK_URL\u0026#34;) # --- SES ENV --- SENDER_EMAIL = os.environ.get(\u0026#39;SENDER_EMAIL\u0026#39;) RECIPIENT_EMAIL = os.environ.get(\u0026#39;RECIPIENT_EMAIL\u0026#39;) # Can now be \u0026#34;a@b.com, c@d.com\u0026#34; AWS_REGION = os.environ.get(\u0026#39;AWS_REGION\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) # --- Setup --- # TELEGRAM_URL = f\u0026#34;https://api.telegram.org/bot{BOT_TOKEN}/sendMessage\u0026#34; if BOT_TOKEN else None logger = logging.getLogger() logger.setLevel(logging.INFO) # Initialize SES Client ses_client = boto3.client(\u0026#39;ses\u0026#39;, region_name=AWS_REGION) # ==================================================================== # SEND TO TELEGRAM # ==================================================================== # def send_to_telegram(finding, chat_id, thread_id): # logger.info(\u0026#34;Formatting message for Telegram...\u0026#34;) # ... (Code commented out, keeping as is or translating if needed, but it is commented out so skipping detailed translation for brevity unless enabled) # ==================================================================== # SEND TO SLACK # ==================================================================== def send_to_slack(finding): if not SLACK_WEBHOOK_URL: logger.warning(\u0026#34;Slack ENV missing. Skipping.\u0026#34;) return severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;🔴 CAO (HIGH)\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;🟠 TRUNG BÌNH (MEDIUM)\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;🔵 THẤP (LOW)\u0026#34; payload = { \u0026#34;text\u0026#34;: f\u0026#34;🚨 {sev} – {title}\u0026#34;, \u0026#34;attachments\u0026#34;: [{ \u0026#34;color\u0026#34;: color, \u0026#34;blocks\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;header\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;plain_text\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;🚨 GuardDuty Finding: {title}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;fields\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Mức độ (Severity):*\\n{sev}\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Khu vực (Region):*\\n{region}\u0026#34;} ]}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Mô tả (Description):*\\n{description}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;divider\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;context\u0026#34;, \u0026#34;elements\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Tài khoản (Account):* `{account_id}`\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Loại (Type):* `{finding_type}`\u0026#34;} ]} ] }] } try: req = urllib.request.Request( SLACK_WEBHOOK_URL, data=json.dumps(payload).encode(\u0026#34;utf-8\u0026#34;), headers={\u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;} ) with urllib.request.urlopen(req) as response: logger.info(\u0026#34;Slack response: \u0026#34; + response.read().decode(\u0026#34;utf-8\u0026#34;)) except Exception as e: logger.error(f\u0026#34;SLACK FAILED: {e}\u0026#34;) # ==================================================================== # SEND TO SES EMAIL (UPDATED FOR MULTIPLE RECIPIENTS) # ==================================================================== def send_to_ses(finding): if not SENDER_EMAIL or not RECIPIENT_EMAIL: logger.warning(\u0026#34;SES Env vars missing. Skipping Email.\u0026#34;) return logger.info(\u0026#34;Formatting message for SES Email...\u0026#34;) recipient_list = [email.strip() for email in RECIPIENT_EMAIL.split(\u0026#39;,\u0026#39;)] severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) finding_id = finding.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;HIGH (CAO)\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;MEDIUM (TRUNG BÌNH)\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;LOW (THẤP)\u0026#34; html_body = f\u0026#34;\u0026#34;\u0026#34; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;style\u0026gt; body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; }} .container {{ width: 100%; max-width: 600px; margin: 0 auto; border: 1px solid #ddd; border-radius: 8px; overflow: hidden; }} .header {{ background-color: {color}; color: white; padding: 15px; text-align: center; }} .content {{ padding: 20px; }} .footer {{ background-color: #f4f4f4; padding: 10px; text-align: center; font-size: 12px; color: #666; }} .label {{ font-weight: bold; color: #555; }} \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;🚨 Cảnh báo GuardDuty: {sev}\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;{title}\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;{description}\u0026lt;/p\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;ID Tài khoản:\u0026lt;/span\u0026gt; {account_id}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Khu vực:\u0026lt;/span\u0026gt; {region}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Loại:\u0026lt;/span\u0026gt; {finding_type}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;ID Phát hiện:\u0026lt;/span\u0026gt; {finding_id}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;footer\u0026#34;\u0026gt; Được tạo bởi AWS Lambda Alert Dispatch \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; \u0026#34;\u0026#34;\u0026#34; try: response = ses_client.send_email( Source=SENDER_EMAIL, Destination={\u0026#39;ToAddresses\u0026#39;: recipient_list}, # Uses the list now Message={ \u0026#39;Subject\u0026#39;: {\u0026#39;Data\u0026#39;: f\u0026#34;GuardDuty Alert [{sev}]: {title}\u0026#34;, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}, \u0026#39;Body\u0026#39;: {\u0026#39;Html\u0026#39;: {\u0026#39;Data\u0026#39;: html_body, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}} } ) logger.info(f\u0026#34;SES Email sent to {len(recipient_list)} recipients! MessageId: {response[\u0026#39;MessageId\u0026#39;]}\u0026#34;) except ClientError as e: logger.error(f\u0026#34;SES FAILED: {e.response[\u0026#39;Error\u0026#39;][\u0026#39;Message\u0026#39;]}\u0026#34;) # ==================================================================== # MAIN HANDLER # ==================================================================== def lambda_handler(event, context): logger.info(f\u0026#34;Event received: {json.dumps(event)}\u0026#34;) try: sns_message_raw = event[\u0026#34;Records\u0026#34;][0][\u0026#34;Sns\u0026#34;][\u0026#34;Message\u0026#34;] message_data = json.loads(sns_message_raw) # Normalization Logic finding = {} if \u0026#34;detail-type\u0026#34; in message_data and message_data[\u0026#34;detail-type\u0026#34;] == \u0026#34;GuardDuty Finding\u0026#34;: detail = message_data[\u0026#34;detail\u0026#34;] finding = { \u0026#34;severity\u0026#34;: detail.get(\u0026#34;severity\u0026#34;, 0), \u0026#34;title\u0026#34;: detail.get(\u0026#34;title\u0026#34;, \u0026#34;GuardDuty Finding\u0026#34;), \u0026#34;description\u0026#34;: detail.get(\u0026#34;description\u0026#34;, \u0026#34;No description provided\u0026#34;), \u0026#34;accountId\u0026#34;: detail.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: detail.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: detail.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;id\u0026#34;: detail.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) } elif \u0026#34;AlarmName\u0026#34; in message_data: state = message_data.get(\u0026#34;NewStateValue\u0026#34;) severity = 8 if state == \u0026#34;ALARM\u0026#34; else 0 finding = { \u0026#34;severity\u0026#34;: severity, \u0026#34;title\u0026#34;: f\u0026#34;CloudWatch Alarm: {message_data.get(\u0026#39;AlarmName\u0026#39;)}\u0026#34;, \u0026#34;description\u0026#34;: message_data.get(\u0026#34;NewStateReason\u0026#34;, \u0026#34;State change detected\u0026#34;), \u0026#34;accountId\u0026#34;: message_data.get(\u0026#34;AWSAccountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: message_data.get(\u0026#34;Region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: \u0026#34;CloudWatch Alarm\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } else: finding = { \u0026#34;severity\u0026#34;: 0, \u0026#34;title\u0026#34;: \u0026#34;Unknown Alert\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;Raw Payload: {json.dumps(message_data)}\u0026#34;, \u0026#34;accountId\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Unknown\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } except Exception as e: logger.error(f\u0026#34;FATAL: Could not parse incoming SNS event: {e}\u0026#34;) return {\u0026#34;statusCode\u0026#34;: 500} # --- Send Telegram --- # if BOT_TOKEN and CHAT_ID: # send_to_telegram(finding, CHAT_ID, MESSAGE_THREAD_ID) # --- Send Slack --- if SLACK_WEBHOOK_URL: send_to_slack(finding) # --- Send SES Email --- if SENDER_EMAIL and RECIPIENT_EMAIL: send_to_ses(finding) return {\u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;Dispatch complete\u0026#34;} "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.9-use-cdk/","title":"Sử dụng CDK","tags":[],"description":"","content":"Tổng quan Chúng tôi đã cung cấp CDK stack để tạo toàn bộ cơ sở hạ tầng cần thiết cho workshop này.\nĐể lấy các file, vui lòng truy cập Github Link và clone hoặc tải xuống tất cả các file về một thư mục.\nHướng dẫn cài đặt Trước khi triển khai CDK stack, bạn phải cấu hình môi trường cục bộ của mình để xác thực với tài khoản AWS bằng AWS Command Line Interface (CLI).\nCài đặt AWS CLI.\nLấy Credentials: Bạn cần một Access Key ID và một Secret Access Key từ một IAM user có quyền deployment.\nChạy lệnh cấu hình: Mở terminal và chạy lệnh aws configure.\n$ aws configure Khi được nhắc, nhập credentials và các cài đặt mong muốn. Default region name nên khớp với region nơi bạn định triển khai stack (ví dụ: ap-southeast-1):\nPrompt Example Value AWS Access Key ID AKIA... AWS Secret Access Key wJalr... Default region name ap-southeast-1 Default output format json Xác minh cấu hình: Kiểm tra thiết lập bằng cách lấy user identity. Kết quả thành công xác nhận bạn đã xác thực.\n$ aws sts get-caller-identity Điều kiện tiên quyết Đảm bảo các công cụ và dịch vụ sau đã được cài đặt và cấu hình trên hệ thống của bạn:\nPython 3.8+ và pip: Cần thiết để thực thi ứng dụng CDK và build Lambda function assets. Node.js và npm: Cần thiết để chạy AWS CDK CLI và build React dashboard. AWS CDK Toolkit: Cài đặt CDK CLI global: $ npm install -g aws-cdk Thiết lập môi trường Python Định nghĩa cơ sở hạ tầng được viết bằng Python. Một virtual environment chuyên dụng được sử dụng để quản lý các dependencies của dự án.\nTạo Virtual Environment:\n$ python -m venv .venv Kích hoạt Virtual Environment:\nOperating System Command macOS / Linux source .venv/bin/activate Windows (Command Prompt) .venv\\Scripts\\activate.bat Windows (PowerShell) .venv\\Scripts\\Activate.ps1 Cài đặt Python Dependencies:\n$ pip install -r requirements.txt Bước build dashboard Tại vị trí thư mục dự án, kiểm tra bên trong thư mục react. Nếu thư mục dist đã tồn tại, bạn không cần phải build. Nếu chưa, vui lòng làm theo các bước dưới đây. Nếu bạn đang dùng cmd sử dụng lệnh này để di chuyển vào thư mục react:\n$ cd react Và sử dụng lệnh này để liệt kê tất cả nội dung trong react:\n$ ls Điều kiện tiên quyết Đảm bảo bạn đã cài đặt Node.js và npm. Bạn có thể kiểm tra phiên bản hiện tại bằng cách chạy:\n$ npm --version Nếu lệnh không được nhận diện, vui lòng tải và cài đặt Node.js từ nodejs.org\nCài đặt dependencies Chạy lệnh sau để cài đặt tất cả các thư viện cần thiết:\n$ npm install Build Project Sau khi cài đặt hoàn tất, chạy lệnh build:\n$ npm run build Sau khi hoàn tất, một thư mục dist sẽ được tạo ra chứa index.html và thư mục assets.\nCấu hình Deployment Context Stack sử dụng các biến context (context variables). Các biến này được đọc từ cdk.context.json hoặc cung cấp qua cờ (flags) dòng lệnh.\nVariable Name Description Required if functionality is desired Default Value (in cdk.context.json) vpc_ids Danh sách các VPC IDs cho Flow Logs và DNS Query Logging. Có [] alert_email Danh sách các địa chỉ email cho thông báo cảnh báo (yêu cầu SES). Có [] sender_email Địa chỉ email người gửi SES đã xác thực. Có (nếu alert_email được thiết lập) \u0026quot;\u0026quot; slack_webhook_url Slack webhook URL để gửi cảnh báo. Không \u0026quot;\u0026quot; Ví dụ\n{ \u0026#34;vpc_ids\u0026#34;: [ \u0026#34;vpc-a1b2c3d4e5f6g7h8i\u0026#34; ], \u0026#34;alert_email\u0026#34;: [ \u0026#34;admin@example.com\u0026#34; ], \u0026#34;sender_email\u0026#34;: \u0026#34;alerts@your-domain.com\u0026#34;, \u0026#34;slack_webhook_url\u0026#34;: \u0026#34;\u0026#34; } Triển khai Stacks (Deploy) Trước khi xử lý tiếp, nếu đang ở trong thư mục /react, nhập lệnh này để quay lại thư mục chính:\n$ cd.. CDK Bootstrapping: Nếu bạn chưa từng sử dụng AWS CDK trong tài khoản AWS và region mục tiêu trước đây, chạy lệnh bootstrap một lần để cung cấp các tài nguyên cần thiết (ví dụ: S3 deployment bucket).\n$ cdk bootstrap (Tùy chọn) Synthesize và Diff: Xem lại các thay đổi CloudFormation được đề xuất trước khi deployment:\n$ cdk synth --all $ cdk diff --all Execute Deployment: Chạy lệnh deployment và phê duyệt bất kỳ thay đổi bảo mật IAM nào được yêu cầu khi được nhắc.\n$ cdk deploy --all Việc deployment hoàn tất khi CDK CLI báo cáo thành công cho stack: AwsIncidentResponseAutomationCdkStack và DashboardCdkStack\nLƯU Ý QUAN TRỌNG: Sau khi deployment hoàn tất, bạn nên xác minh email trong SES. Tạo một user trong Cognito để có thể đăng nhập vào Dashboard. Truy cập Security Group và xóa quy tắc outbound mặc định khỏi QuarantineSecurityGroup "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/1.10-week10/","title":"Nhật ký Công việc Tuần 10","tags":[],"description":"","content":"Mục tiêu Tuần 10: Nghiên cứu và kiểm thử đầy đủ tất cả các thành phần và sẵn sàng kết hợp để xây dựng workshop Các nhiệm vụ được thực hiện trong tuần này: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Hỗ trợ xây dựng ETL Pipeline cho CloudWatch logs cùng thành viên nhóm - Cập nhật đề xuất:\n+ Bao gồm Kiến trúc và Dịch vụ đã cập nhật + Tính toán lại chi phí 10/11/2025 10/11/2025 3 - Hoàn thành xây dựng ETL Pipeline cho CloudWatch logs - Sửa ETL Pipeline cho CloudTrail logs: Logs được xử lý từ các ngày khác nhau gây lỗi schema do thứ tự trường ngẫu nhiên trong kiểu dữ liệu struct - Sử dụng AWS SSM thành công để lấy EC2 system logs sau các Phản hồi IR - Tích hợp thành công các chatbot thông báo mối đe dọa trong Slack và Telegram - Hiển thị thành công các thông báo được định dạng dựa trên live threat findings Bị gửi hơn 1000 emails vì thành viên nhóm đã kích hoạt tất cả GuardDuty sample findings kết hợp với nhiều lần kiểm thử SNS - Thành viên nhóm đề xuất thêm SES (Simple Email Service) để định dạng và gửi emails 11/11/2025 11/11/2025 4 - Nghiên cứu CloudTrail Lake: Tốt cho việc sử dụng trong tương lai cụ thể là để phân tích CloudTrail log chuyên sâu, bị coi là không cần thiết cho dự án hiện tại do nó chỉ dành riêng cho CloudTrail - Cập nhật CloudTrail ETL Lambda: promote fields trong request parameters thành các cột để truy vấn tốt hơn và ít lỗi schema crawling hơn =\u0026gt; Crawl dữ liệu đã xử lý giữa các ngày một cách đáng tin cậy - Các thành viên nhóm bắt đầu thiết kế trang dashboard, đề xuất tích hợp Grafana - Thành viên nhóm hoàn thành Lambda IR Functions - Bắt đầu cập nhật đề xuất sang định dạng mới 12/11/2025 12/11/2025 5 - Kiểm thử thành công việc sử dụng Lambda để truy vấn với Athena nhằm chuẩn bị cho API Gateway cho Dashboard - Việc gia đình 13/11/2025 13/11/2025 Lambda Athena Query Guide 6 - Việc crawling raw GuardDuty exported logs cho thấy là một ý tưởng tồi, một số lượng lớn lỗi schema - Xây dựng một Lambda ETL Pipeline cho GuardDuty logs - Sửa đổi kiến trúc: + Định hướng log từ GuardDuty đến Raw Log S3 Bucket để trải qua ETL Pipeline Thêm SES theo đề xuất của thành viên nhóm - Nghiên cứu các kiến trúc thay thế: Chúng tôi có thể loại bỏ hoàn toàn Crawler, do custom Lambda ETL pipeline mà chúng tôi đã tạo, chúng tôi đã thực hiện hầu hết các dịch vụ của Crawler. Crawler chủ yếu được sử dụng cho số lượng lớn logs với nhiều loại dữ liệu khác nhau, ngoại trừ kiểu dữ liệu struct dường như, mà CloudWatch, CloudTrail và GuardDuty logs có rất nhiều. Sau khi định dạng logs thành Parquet bằng custom Lambda ETL, mục đích của Crawler bây giờ là biến nó thành một Catalog Table, mà thay vào đó có thể được thực hiện bằng Lambda. Sẽ kiểm thử phương pháp thay thế này. - Cập nhật thành công CloudTrail ETL Pipeline để trực tiếp gọi Glue API tạo table mà không cần sử dụng Crawler - Đưa việc sử dụng KMS vào dự án do tính chất nhạy cảm của các security logs - Tham gia AWS Cloud Mastery Series #1 - AI/ML/GenAI on AWS 14/11/2025 16/11/2025 Tóm tắt và Trải nghiệm Sự kiện Thành tựu Tuần 10: Phát triển và Tối ưu hóa ETL Pipeline Nâng cao * Hoàn thành thành công việc xây dựng ETL pipeline cho CloudWatch logs. * Đã giải quyết các lỗi schema nghiêm trọng trong CloudTrail ETL pipeline để đảm bảo xử lý dữ liệu đáng tin cậy giữa các ngày khác nhau. * Xây dựng một custom Lambda ETL pipeline cho GuardDuty logs để giải quyết các vấn đề schema gặp phải với việc export raw log. * Tinh chỉnh quy trình CloudTrail ETL để bỏ qua Glue Crawler bằng cách để hàm Lambda trực tiếp gọi Glue API tạo Catalog Table. Tích hợp Công cụ Bảo mật và Thông báo * Triển khai thành công AWS Systems Manager (SSM) để lấy EC2 system logs cho việc ứng phó sự cố (incident response). * Tích hợp và kiểm thử các chatbot thông báo mối đe dọa trong cả Slack và Telegram, hiển thị thành công các thông báo được định dạng dựa trên live threat findings. * Thêm Amazon Simple Email Service (SES) vào kiến trúc dự án để định dạng và phân phối email chuyên nghiệp. Kiến trúc Dự án, Tài liệu và Bảo mật * Cập nhật đề xuất dự án, bao gồm kiến trúc đã sửa đổi, danh sách dịch vụ và tính toán lại chi phí. * Tích hợp Key Management Service (KMS) vào dự án để bảo mật các security logs nhạy cảm. Phát triển Backend Dashboard * Kiểm thử thành công một hàm Lambda để truy vấn với Athena, chuẩn bị cho việc tích hợp API Gateway cho dashboard. * Đóng góp vào thiết kế dashboard, đề xuất tích hợp Grafana. Tham gia Sự kiện * Đã tham gia AWS Cloud Mastery Series #1 - AI/ML/GenAI on AWS "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.10-cleanup/","title":"Dọn dẹp","tags":[],"description":"","content":"Chúc mừng bạn đã hoàn thành workshop này! Trong workshop này, bạn đã tạo một Hệ thống Phản hồi Sự cố và Điều tra số Tự động và làm quen với Lambda, Step Functions, EventBridge, Glue, Athena, CloudFront, Cognito, S3 Buckets\nHướng dẫn dọn dẹp: Hướng dẫn dọn dẹp cho thiết lập thủ công Hướng dẫn dọn dẹp cho thiết lập CDK "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.10-step-functions-state-machine-definition/","title":"Mã Định nghĩa Step Functions ASL","tags":[],"description":"","content":" { \u0026#34;Comment\u0026#34;: \u0026#34;Guardduty Incident Response Automation\u0026#34;, \u0026#34;StartAt\u0026#34;: \u0026#34;CheckFindingType\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;CheckFindingType\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Comment\u0026#34;: \u0026#34;Check if EC2 (Kiểm tra nếu là EC2)\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Instance\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;ParseFindings\u0026#34; }, { \u0026#34;Comment\u0026#34;: \u0026#34;Check if IAM (Kiểm tra nếu là IAM)\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;AccessKey\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;Quarantine_IAM_User\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;NoActionNeeded\u0026#34; }, \u0026#34;ParseFindings\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34;, \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-parse-findings-lambda\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34;, \u0026#34;Lambda.TooManyRequestsException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 1, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2, \u0026#34;JitterStrategy\u0026#34;: \u0026#34;FULL\u0026#34; } ], \u0026#34;Next\u0026#34;: \u0026#34;Isolate_EC2_Instance\u0026#34; }, \u0026#34;Isolate_EC2_Instance\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-isolate-ec2-lambda\u0026#34;, \u0026#34;Payload\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceIds[0]\u0026#34;, \u0026#34;Region.$\u0026#34;: \u0026#34;$.Region\u0026#34; } }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;Next\u0026#34;: \u0026#34;CheckIsolationStatus\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34; }, \u0026#34;CheckIsolationStatus\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.IsolationSG\u0026#34;, \u0026#34;IsNull\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;AlreadyIsolated\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;EnableTerminationProtection\u0026#34; }, \u0026#34;AlreadyIsolated\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; }, \u0026#34;EnableTerminationProtection\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:modifyInstanceAttribute\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceId\u0026#34;, \u0026#34;DisableApiTermination\u0026#34;: { \u0026#34;Value\u0026#34;: true } }, \u0026#34;Next\u0026#34;: \u0026#34;CreateQuarantineTag\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;CreateQuarantineTag\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createTags\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Resources.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;Security Group\u0026#34;, \u0026#34;Value.$\u0026#34;: \u0026#34;$.IsolationSG\u0026#34; } ] }, \u0026#34;Next\u0026#34;: \u0026#34;DescribeInstanceASG\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;DescribeInstanceASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:describeAutoScalingInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.ASGInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CheckIfASGExists\u0026#34; }, \u0026#34;CheckIfASGExists\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0]\u0026#34;, \u0026#34;IsPresent\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;UpdateASGConfiguration\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;UpdateASGConfiguration\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:updateAutoScalingGroup\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;MinSize\u0026#34;: 0 }, \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;Wait for ASG\u0026#34; }, \u0026#34;Wait for ASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 10, \u0026#34;Next\u0026#34;: \u0026#34;DetachFromASG\u0026#34; }, \u0026#34;DetachFromASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:detachInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;ShouldDecrementDesiredCapacity\u0026#34;: false }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;AutoScaling.ValidationException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 15, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;DescribeVolumes\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:describeVolumes\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Filters\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;attachment.instance-id\u0026#34;, \u0026#34;Values.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; } ] }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.VolumeInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshots\u0026#34; }, \u0026#34;CreateSnapshots\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Map\u0026#34;, \u0026#34;ItemsPath\u0026#34;: \u0026#34;$.VolumeInfo.Volumes\u0026#34;, \u0026#34;MaxConcurrency\u0026#34;: 1, \u0026#34;Iterator\u0026#34;: { \u0026#34;StartAt\u0026#34;: \u0026#34;Wait before calling CreateSnapshot API\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;Wait before calling CreateSnapshot API\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 15, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshot\u0026#34; }, \u0026#34;CreateSnapshot\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createSnapshot\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;VolumeId.$\u0026#34;: \u0026#34;$.VolumeId\u0026#34;, \u0026#34;Description.$\u0026#34;: \u0026#34;States.Format(\u0026#39;IR Snapshot for {} - {}\u0026#39;, $.Attachments[0].InstanceId, $.VolumeId)\u0026#34;, \u0026#34;TagSpecifications\u0026#34;: [ { \u0026#34;ResourceType\u0026#34;: \u0026#34;snapshot\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; } ] } ] }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Ec2.RequestLimitExceeded\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 60, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true } } }, \u0026#34;End\u0026#34;: true }, \u0026#34;Quarantine_IAM_User\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.accessKeyDetails.userType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Root\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;RootUserDetected\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;ExecuteIAMQuarantine\u0026#34; }, \u0026#34;RootUserDetected\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34;, \u0026#34;Comment\u0026#34;: \u0026#34;Cannot quarantine root user\u0026#34; }, \u0026#34;ExecuteIAMQuarantine\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-quarantine-iam-lambda\u0026#34;, \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true }, \u0026#34;NoActionNeeded\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; } } } "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/1.11-week11/","title":"Nhật ký Công việc Tuần 11","tags":[],"description":"","content":"Mục tiêu Tuần 11: Tinh chỉnh dự án. Các nhiệm vụ được thực hiện trong tuần này: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Tham gia AWS Cloud Mastery Series #2 - DevOps on AWS: Thu được nhiều giá trị tốt về CDK và CloudFormation cho dự án, nhận được một số khuyến nghị từ cố vấn về chiến lược demo, viết về trải nghiệm sự kiện 17/11/2025 17/11/2025 Tóm tắt và Trải nghiệm Sự kiện 3 - Tổng quan Dashboard: Cập nhật thêm các trường hiển thị ban đầu - Sửa đổi Kiến trúc: + Loại bỏ Crawler khỏi kiến trúc + Thêm SQS giữa EventBridge và StepFunctions - Ghi nhận chi phí của các cuộc gọi S3 API, đặc biệt là S3 Bucket cho CloudTrail logs. Lambda được cấu hình để xử lý mọi CloudTrail log, dẫn đến số lượng lớn cuộc gọi S3 GET, vì vậy chúng tôi phải cập nhật chi phí tương ứng - Thành viên nhóm đã cách ly EC2 thành công trong môi trường kiểm thử - Nâng cấp thành công GuardDuty ETL Lambda để tạo table mà không cần Crawler và trả về các trường chi tiết hơn - Thành viên nhóm đã nâng cấp thành công CloudWatch ETL Lambda để tạo table mà không cần Crawler. Tôi đã giúp tạo trigger và cập nhật mã Lambda để xử lý tệp exported mới Sao lưu mã Lambda 18/11/2025 18/11/2025 4 - Tham gia Secure Your Applications: AWS Perimeter Protection Workshop: Học thêm về CloudFront và WAF và được giới thiệu về CloudFront pricing tier hoàn toàn mới, đã làm hai workshop về CloudFront và WAF - Học cách thiết lập API Gateway RestAPIs để chuẩn bị tích hợp với dashboard 19/11/2025 19/11/2025 Tóm tắt và Trải nghiệm Sự kiện 5 - Được mời về trường dự Ngày Nhà giáo - Việc gia đình 20/11/2025 20/11/2025 6 - Được mời tham dự Ngày Tốt nghiệp của FPT bởi các cử nhân tốt nghiệp - Nghiên cứu về CDK: Cách cài đặt, cách sử dụng, cách cấu hình stacks để chuẩn bị cho kế hoạch tuần tới 21/11/2025 23/11/2025 AWS CDK Github AWS CDK Document Thành tựu Tuần 11: Tinh chỉnh Kiến trúc và Tối ưu hóa Chi phí * Loại bỏ thành công dịch vụ Glue Crawler khỏi kiến trúc bằng cách nâng cấp các ETL Lambdas để trực tiếp tạo Glue Catalog Tables. * Đã nâng cấp GuardDuty ETL Lambda và hỗ trợ nâng cấp CloudWatch ETL Lambda để tạo table mà không cần Crawler. * Thêm SQS (Simple Queue Service) giữa EventBridge và Step Functions để cải thiện độ tin cậy và sự tách rời của quy trình làm việc. * Xác định chi phí tiềm năng cao liên quan đến các cuộc gọi S3 API GET do việc xử lý tất cả CloudTrail logs và ghi nhận để cập nhật chi phí tương ứng. Phát triển Ứng phó Sự cố (IR) và Dashboard * Thành viên nhóm đã đạt được việc cách ly EC2 (EC2 isolation) thành công trong môi trường kiểm thử, xác nhận một chức năng IR quan trọng. * Cập nhật dashboard overview để bao gồm nhiều trường chi tiết và hiển thị ban đầu hơn. * Học cách thiết lập API Gateway RestAPIs để chuẩn bị tích hợp với custom dashboard. Tham gia Sự kiện: * Đã tham gia AWS Cloud Mastery Series #2 - DevOps on AWS. * Đã tham gia Secure Your Applications: AWS Perimeter Protection Workshop, hoàn thành hai workshop về CloudFront và WAF. "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/","title":"Phụ lục","tags":[],"description":"","content":"Phụ lục Lambda Codes: CloudTrail ETL GuardDuty ETL CloudWatch ETL CloudWatch ENI ETL CloudWatch Auto Export Parse Findings Isolate EC2 Instance Quarantine IAM Alert Dispatch Step Functions ASL Code: Step Functions ASL Code "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/1.12-week12/","title":"Nhật ký Công việc Tuần 12","tags":[],"description":"","content":"Mục tiêu Tuần 12: Kết nối và làm quen với các thành viên của First Cloud Journey. Hiểu các dịch vụ AWS cơ bản, cách sử dụng console \u0026amp; CLI. Các nhiệm vụ được thực hiện trong tuần này: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Cài đặt AWS CDK thành công với AWS CLI Hoàn thành hướng dẫn tạo ứng dụng đầu tiên với CDK: + Triển khai stacks trên AWS Accounts + Sử dụng diff để so sánh các thay đổi + Destroy stack sau khi hoàn thành - Tạo Github Organization cho nhóm 24/11/2025 24/11/2025 CDK Tutorial 3 - Thêm vào IR Step Functions: Thêm Map State để lặp qua các Isolated Instances và kích hoạt SSM Lambda cho các Instances đó để thu thập logs từ chúng cho forensics - Hỗ trợ thành công việc tạo auto export CloudWatch logs: Sử dụng Lambda để phân tích subscription filter từ log stream đến Raw Log S3 bucket, sẽ phải sửa đổi CloudWatch ETL Lambda để hoạt động với auto export mới thay vì batch export job - Cập nhật CloudTrail ETL Lambda: Nhận thấy chi phí lưu trữ cao bất thường trong Processed CloudTrail Log bucket =\u0026gt; Lambda Function hiện tại lưu tệp dưới dạng .jsonl chưa unzip =\u0026gt; Cập nhật function để các tệp được nén bằng gzip trước khi lưu - CloudTrail ETL Lambda có một số lỗi và lần gọi đột biến khi nhiều người tương tác với tài khoản =\u0026gt; Tăng giới hạn timeout CDK: Di chuyển môi trường kiểm thử CDK sang một tài khoản mới - CDK: Tạo một Stack cho phép GuardDuty và CloudTrail cùng với Raw Log S3 Bucket 25/11/2025 25/11/2025 4 - CDK: Cập nhật Bucket và CloudTrail Policy để tái tạo cơ sở hạ tầng hiện tại: gặp phải circular dependencies nhưng đã được giải quyết CDK: Tái tạo thành công CloudTrail ETL pipeline với Raw và Processed log buckets, ETL Lambda và Glue table để được truy vấn bằng Athena và đặt các policies liên quan 26/11/2025 26/11/2025 5 - CDK: Cấu hình CloudWatch, Log Group, DNS Query logging, thêm cdk-context để người dùng nhập VPC ids nhằm thêm logging cho phân tích - Tối ưu hóa: CloudTrail logs đã quá nhiều, kiểm tra nhanh cho thấy nó cũng log S3 Put events từ các ETL Lambdas, gây ra một vòng lặp =\u0026gt; Tạo custom event exclusion trong tab CloudTrail Events để loại trừ các API được gọi bởi các ETL Lambdas - Loại trừ sự kiện theo Lambda\u0026rsquo;s ARN không đáng tin cậy =\u0026gt; Loại trừ API từ log buckets - CDK: Không thể cấu hình advanced event selectors trong CDK nên điều đó sẽ phải được loại bỏ - CDK: Cấu hình thành công CloudWatch Auto Export Lambda và Subscription Filter: Gặp nhiều lỗi quyền từ Subscription Filter permission để gọi Lambda =\u0026gt; Sử dụng L2 construct và explicit dependency cho _create_subscription_filter 27/11/2025 27/11/2025 6 - CDK: Thêm CloudWatch ETL và Glue Table liên quan cùng Processed Bucket -CDK: Thêm KMS Key để cho phép GuardDuty export findings sang S3 Bucket và thêm GuardDutyETL để xử lý các findings cho việc truy vấn =\u0026gt; Hoàn thành đầy đủ ETL Pipeline và Data Forensics - Họp nhóm: + Giao nhiệm vụ CDK cho các thành viên + Bắt đầu cập nhật đề xuất và sơ đồ kiến trúc - Sửa và cải thiện IR Step Functions: + Sửa EC2Isolate Lambda: Phương pháp parsing sai + Cải thiện state: Thêm Parsing Lambda và sắp xếp lại các chức năng + SSM Thất bại do thiếu IAM: Role sẽ được thêm vào SSM Forensics Function - Tham gia AWS Cloud Mastery Series #3: AWS Well-Architected – Security Pillar Workshop 28/11/2025 30/11/2025 Tóm tắt và Trải nghiệm Sự kiện Thành tựu Tuần 12: AWS CDK * Cài đặt và học các kiến thức cơ bản về AWS CDK thành công và hoàn thành hướng dẫn giới thiệu, bao gồm triển khai stack, so sánh thay đổi (diff), và hủy (destruction). * Tạo GitHub Organization cho nhóm. * Phát triển và triển khai cơ sở hạ tầng ETL nền tảng bằng CDK, bao gồm: * Stacks để kích hoạt GuardDuty và CloudTrail, cùng với Raw Log S3 Bucket cần thiết. * Tái tạo thành công CloudTrail ETL pipeline hoàn chỉnh (Raw/Processed buckets, ETL Lambda, Glue Table, và các policies liên quan). * Cấu hình các thành phần CloudWatch logging (Log Group, DNS Query logging) và CloudWatch Auto Export Lambda sử dụng L2 construct để giải quyết lỗi quyền subscription filter. * Hoàn thành đầy đủ ETL pipeline và Data Forensics bằng cách thêm CloudWatch ETL, GuardDuty ETL, các Glue Tables liên quan, và cấu hình KMS Key cho GuardDuty export. Tối ưu hóa ETL Pipeline và Giảm Chi phí * Cập nhật CloudTrail ETL Lambda để nén tệp bằng gzip trước khi lưu vào Processed S3 Bucket, giảm đáng kể chi phí lưu trữ. * Giải quyết các lỗi và lần gọi đột biến trong CloudTrail ETL Lambda bằng cách tăng giới hạn timeout. * Tối ưu hóa CloudTrail logging bằng cách tạo custom event exclusions để ngăn chặn việc log S3 Put events được kích hoạt bởi các ETL Lambdas, giải quyết một vòng lặp logging tiềm năng. Cải tiến Quy trình Ứng phó Sự cố (IR) Workflow * Cải tiến IR Step Functions Workflow bằng cách thêm Map State để lặp lại các isolated instances và kích hoạt SSM Lambda để thu thập logs cho forensics. * Sửa EC2 Isolate Lambda (phương pháp parsing không chính xác) và cải thiện state workflow tổng thể bằng cách thêm Parsing Lambda và sắp xếp lại các chức năng. * Xác định và ghi nhận nhu cầu thêm IAM role chính xác vào SSM Forensics Function để giải quyết các lỗi SSM. * Hỗ trợ tạo cơ chế CloudWatch log auto-export thông qua subscription filter và Lambda. Tham gia Sự kiện * Đã tham gia AWS Cloud Mastery Series #3: AWS Well-Architected – Security Pillar Workshop. "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/1-worklog/1.13-week13/","title":"Nhật ký Công việc Tuần 13","tags":[],"description":"","content":"Mục tiêu Tuần 13: Hoàn thành dự án và nộp\nCác nhiệm vụ được thực hiện trong tuần này: Ngày Nhiệm vụ Ngày Bắt đầu Ngày Hoàn thành Tài liệu Tham khảo 2 - Loại bỏ Map State để Cách ly EC2 Instance trong Steps Function - Tạo các Lambdas để thêm policies vào EC2 Instance cho SSM automation trong IR Step Functions - Cấu hình lại Quarantine SG: Thêm Outbound rule cho HTTPS để kết nối SSM - Thay thế Lambdas bằng các States do Step Functions cung cấp: Sử dụng DescribeIamInstanceProfileAssociation, AttachRolePolicy, DetachRolePolicy và StartAutomationExecution - CDK: Tạo EventBridge và Topics với subscription emails được lưu trữ trong cdk-context - Họp nhóm: Lập kế hoạch và phân công lại nhiệm vụ để đáp ứng thời hạn mới 01/12/2025 01/12/2025 3 - CDK: Thêm cảnh báo SES cho GuardDuty findings - CDK: Thêm ENI ETL vào ETL Pipeline - Hỗ trợ nâng cấp dashboard Cập nhật Event Participated và sửa lỗi, cải thiện Worklog tổng thể - Nghiên cứu thêm về cách tối ưu hóa pipeline, hiện tại S3 Get Request cao hơn dự kiến do truy vấn Athena kích thước thấp nhưng nhiều đối tượng 02/12/2025 02/12/2025 4 -CDK: Nâng cấp Cảnh báo với Slack - Kiến trúc: + Nghiên cứu và thất bại trong việc sử dụng SQS để pool logs trước khi gửi đến Lambda: Lambda vẫn dựa trên sự kiện và vẫn xử lý log riêng lẻ thay vì pooling + Nghiên cứu và thêm Data Firehose để hợp nhất logs trước khi ghi vào processed S3 =\u0026gt; Giảm số lượng đối tượng được ghi vào S3 - IR Step Function sửa đổi: Loại bỏ các hành động SSM do nó yêu cầu kết nối outbound sau khi cách ly EC2 =\u0026gt; Thay thế bằng tagging, loại bỏ nó khỏi ASG và tạo EBS Snapshot để phân tích và bảo tồn dữ liệu - Thành viên nhóm cập nhật CloudWatch ETL với Data Firehose thành công - CDK: Cập nhật tất cả ETL Pipeline với Kinesis Firehose + Đại tu CloudTrailELT 03/12/2025 03/12/2025 5 - Hoàn thành một phần việc viết Workshop về tạo ETL Pipeline CDK: Tạo và cập nhật Step Functions: Loại bỏ hoàn toàn SSM thay thế bằng tagging, bảo vệ chấm dứt (termination protection), tách khỏi ASG và tạo snapshot - Loại bỏ SQS giữa EventBridge và StepFunctions - Cập nhật Worklog: Events 04/12/2025 04/12/2025 6 - Tham gia BUILDING AGENTIC AI - Context Optimization with Amazon Bedrock Workshop: Giành được giải thưởng từ CloudThinker vì chiến thắng trong Workshop - Cập nhật GuardDuty ETL và table để tối ưu hóa truy vấn - Vẽ lại và cập nhật Architecture Diagram Cập nhật Proposal sang định dạng mới nhất - Cập nhật Step Functions States - Tối ưu hóa cơ sở hạ tầng tổng thể và sửa lỗi 05/12/2025 07/12/2025 Tóm tắt và Trải nghiệm Sự kiện Thành tựu Tuần 13: Tinh chỉnh và Tối ưu hóa Kiến trúc Cuối cùng * Tích hợp Kinesis Data Firehose vào các ETL pipelines (bao gồm CloudWatch và CloudTrail) để hợp nhất logs trước khi ghi vào S3. * Việc thiết kế lại này đã thành công giảm số lượng đối tượng được ghi vào S3, tối ưu hóa pipeline và giảm chi phí truy vấn Athena trong tương lai. * Đại tu CloudTrail ETL để hoạt động với cấu hình Firehose mới. * Thêm ENI (Elastic Network Interface) ETL vào core data processing pipeline. * Hoàn thiện tối ưu hóa cơ sở hạ tầng tổng thể và sửa lỗi trên toàn bộ dự án. Đại tu Quy trình Ứng phó Sự cố (IR) * Hoàn toàn sửa đổi IR Step Function để loại bỏ sự phụ thuộc vào các kết nối outbound (SSM), vốn bị chặn sau khi cách ly. * Workflow cách ly mới hiện tập trung vào bảo tồn dữ liệu mạnh mẽ và loại bỏ tài sản bằng cách: * Tagging instance. * Bật bảo vệ chấm dứt (termination protection). * Tách instance khỏi Auto Scaling Group (ASG) của nó. * Tạo EBS Snapshot để phân tích forensic. AWS CDK * Hoàn thiện CDK Stack cho IR workflow, triển khai logic Step Functions đã được sửa đổi hoàn toàn. * Hoàn thành CDK deployment của tất cả các cảnh báo, thêm cả thông báo SES và Slack cho GuardDuty findings. Tài liệu và Tài liệu Workshop * Vẽ lại và cập nhật Architecture Diagram để phản ánh tích hợp Kinesis Firehose cuối cùng và các thay đổi IR. * Cập nhật Proposal sang định dạng mới nhất và cuối cùng. * Hoàn thành một phần việc viết tài liệu Workshop. Tham gia Sự kiện * Đã tham gia BUILDING AGENTIC AI - Context Optimization with Amazon Bedrock Workshop. * Giành được giải thưởng từ CloudThinker trong workshop. "},{"uri":"https://veljg.github.io/AWS-Worklog/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://veljg.github.io/AWS-Worklog/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]